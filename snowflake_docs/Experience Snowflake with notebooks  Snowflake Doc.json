{
    "url": "https://docs.snowflake.com/en/user-guide/ui-snowsight/notebooks-use-with-snowflake#snowpark-pandas-in-notebooks",
    "title": "Experience Snowflake with notebooks | Snowflake Documentation",
    "paragraphs": [
        "Feature \u2014 Generally Available",
        "Generally available in Amazon Web Services (AWS), Microsoft Azure, and Google Cloud Platform (GCP) commercial regions.",
        "Snowflake Notebooks is a development environment that you can use with other Snowflake features. This topic shows how to leverage other\nSnowflake features within notebooks.",
        "The Snowpark library provides an intuitive API for querying and processing data in a data pipeline.\nUsing the Snowpark library, you can build applications that process data in Snowflake without moving data to the system where your\napplication code runs. You can also automate data transformation and processing by writing stored procedures and scheduling those\nprocedures as tasks in Snowflake.",
        "You can use Snowpark to query and process data at scale in Snowflake by writing Snowpark code in a Python cell of your notebook.",
        "Snowpark Python comes pre-installed in the Snowflake Notebooks environment.\nThe following example uses the Snowpark library in a notebook to read in a CSV file and a Snowflake table and display its contents as output.",
        "In your notebook, add a Python cell, either using a keyboard shortcut or by selecting\n+ Python.\nSnowflake Notebooks and Snowpark both support Python 3.9.",
        "Set up a Snowpark session.\nIn notebooks, the session context variable is preconfigured. You can use the get_active_session method to get the session context variable:",
        "Use Snowpark to load a CSV file into a Snowpark DataFrame from a stage location. This example uses a stage called tastybyte_stage.",
        "Load an existing Snowflake table, app_order, into the Snowpark DataFrame.",
        "Display the Snowpark DataFrame.",
        "Note",
        "Outside of the Snowflake Notebooks environment, you must call df.show() to print out the DataFrame. In Snowflake Notebooks,\nDataFrames are evaluated eagerly when df is printed out. The DataFrame is printed out as an interactive Streamlit DataFrame display\n(st.dataframe). DataFrames output is limited to 10,000 rows or 8 MB, whichever is lower.",
        "A Snowflake Notebook creates a Snowpark session, so you can use most of the methods available in a Snowpark session class.\nHowever, because a notebook runs inside Snowflake rather than in your local development environment, you cannot use the following methods:",
        "session.add_import",
        "session.add_packages",
        "session.add_requirements",
        "Some Snowpark Python operations don\u2019t work with SPROCs. For a complete list of operations, see Python stored procedure limitations.",
        "Tip",
        "View more examples of notebooks that use Snowpark:",
        "Data Engineering Pipelines with Snowpark Python",
        "Adding CSV files notebook",
        "Note",
        "These quickstarts are only shown as examples. Following along with the example may require additional rights to third-party data,\nproducts, or services that are not owned or provided by Snowflake. Snowflake does not guarantee the accuracy of these examples.",
        "Streamlit is an open-source Python library that makes it easy to create and share\ncustom web apps for machine learning and data science. You can build interactive data applications with Streamlit directly in your\nnotebook. You can test and develop your app directly in a notebook. Streamlit comes preinstalled in notebooks, so you can start quickly.",
        "Streamlit comes pre-installed with the Snowflake Notebooks environment. The example in this section creates an interactive data app using Streamlit.",
        "Import necessary libraries",
        "First create some sample data for the app.",
        "Set up your interactive slider from the Streamlit library.",
        "Finally, display a filtered table based on the slider value.",
        "You can interact with the app in real time from the notebook. See the filtered table change based on the value you set on the slider.",
        "Tip",
        "For the complete example, see the interactive data app section of the Visual Data Stories with Snowflake Notebooks notebook.",
        "When you use the st.map  or\nst.pydeck_chart\nStreamlit commands, Mapbox provides the map tiles when rendering map content.\nMapbox is a third-party application and is subject to Snowflake\u2019s\nExternal Offerings Terms.",
        "The following Streamlit elements are not supported in Notebooks:",
        "st.bokeh_chart",
        "st.camera_input",
        "st.feedback",
        "st.file_uploader",
        "st.set_page_config",
        "The page_title, page_icon, and menu_items properties of the\nst.set_page_config command are not supported.",
        "st.experimental_audio_input",
        "st.experimental_get_query_params",
        "st.experimental_set_query_params",
        "st.components.v1.iframe",
        "st.components.v1.declare_component",
        "Anchor links",
        "Material icons in Markdown",
        "Snowpark ML is the Python library that provides the APIs for\nSnowflake ML and for custom machine learning model development in\nSnowflake. Using Snowpark ML, you can develop custom models using APIs based on popular ML frameworks, define\nautomatically updated features to train them, and store them in a model registry for easy discovery and reuse.",
        "Container Runtime for ML provides software and hardware options to support advanced data science and machine learning workloads. For\ndetails on container runtime, see Notebooks on Container Runtime for ML.",
        "Important",
        "The snowflake-ml-python package and its dependencies must be allowed by your organization\u2019s\npackage policy.",
        "To use Snowpark ML, install the snowflake-ml-python library for your notebook:",
        "From the notebook, select Packages.",
        "Locate the snowflake-ml-python library and select the library to install it.",
        "Here is an example of how you can use the Snowpark ML library for preprocessing your data:",
        "Here is an example of how you can use the Snowpark ML library for model training and inference:",
        "Tip",
        "Telco Churn Data Analysis and Modeling",
        "End-to-End Machine Learning with Snowpark ML",
        "The Snowflake Model Registry allows you to securely manage models and your\nmetadata in Snowflake, regardless of origin. The model registry stores machine learning models as first-class schema-level objects in\nSnowflake so they can easily be found and used by others in your organization. You can create registries, and store models in them, using\nclasses in the Snowpark ML library. Models can have multiple versions, and you can designate a version as the default.",
        "To use the Snowflake ML registry, install the snowflake-ml-python library for your notebook:",
        "From your notebook, select Packages at the top.",
        "Search for the snowflake-ml-python package and select the library to install it.",
        "Here is an example of how you can use the Snowflake ML Registry to log a model:",
        "Tip",
        "View this end-to-end example  of how to use Snowflake ML Registry.",
        "pandas on Snowflake lets you run your pandas code in a distributed manner\ndirectly on your data in Snowflake. Just by changing the import statement and a few lines of code, you can get the same familiar pandas-native\nexperience with the scalability and security benefits of Snowflake.",
        "With pandas on Snowflake, you can work with much larger datasets and avoid the time and expense of porting your pandas pipelines to other\nbig data frameworks or provisioning large and expensive machines. It runs workloads natively in Snowflake through transpilation to SQL,\nenabling it to take advantage of parallelization and the data governance and security benefits of Snowflake.",
        "pandas on Snowflake is delivered through the Snowpark pandas API as part of the Snowpark Python library, which enables scalable data\nprocessing of Python code within the Snowflake platform.",
        "Snowpark pandas is available in Snowpark Python version 1.17 and later. Snowpark Python comes pre-installed with the Snowflake Notebooks environment.",
        "To install Modin, select modin from Packages and ensure that the version is 0.28.1 or later.",
        "To set the pandas version, select pandas from Packages and ensure that the version is 2.2.1.",
        "In a Python cell, import Snowpark Python and Modin:",
        "Create a Snowpark session:",
        "Start using the Snowpark Python API:",
        "Tip",
        "For more examples of how to use pandas on Snowflake, see\nGetting Started with pandas on Snowflake.",
        "The Snowflake Python API is a unified library that seamlessly\nconnects Python with Snowflake workloads. It is intended to provide comprehensive APIs for interacting with Snowflake resources across data\nengineering, Snowpark, Snowpark ML, and application workloads using a first-class Python API.",
        "You can use the Snowflake Python API to manage Snowflake resources by creating, deleting, or modifying them, and more. You can use Python\nto perform tasks you might otherwise perform with Snowflake SQL commands.",
        "In Notebooks, the session context variable is preconfigured. You can use the get_active_session method to get the session context variable:",
        "Create a Root object from which to use the Snowflake Python API:",
        "Here is an example of how you can create a database and schema using the Python API:",
        "Tip",
        "For a more detailed example of how to use Snowflake\u2019s Python API, see the Creating Snowflake object using Python API notebook example on Github.",
        "Was this page helpful?",
        "On this page"
    ]
}