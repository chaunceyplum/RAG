{
    "url": "https://docs.snowflake.com/en/user-guide/tutorials/data-load-internal-tutorial",
    "title": "Tutorial: Bulk loading from a local file system using COPY | Snowflake Documentation",
    "paragraphs": [
        "This tutorial describes how to load data from files in your local file system into a table.",
        "In this tutorial, you will learn how to:",
        "Create named file format objects that describe your data files.",
        "Create named stage objects.",
        "Upload your data to the internal stages.",
        "Load your data into tables.",
        "Resolve errors in your data files.",
        "The tutorial covers how to load both CSV and JSON data using SnowSQL.",
        "The tutorial assumes the following:",
        "You have a Snowflake account and a user with a role that grants the necessary\nprivileges to create a database, tables, and virtual warehouse objects.",
        "You have SnowSQL installed.",
        "The Snowflake in 20 minutes tutorial provides the related step-by-step instructions to meet these requirements.",
        "In addition, you need to do the following before you start the tutorial:",
        "Download sample files provided for this exercise.",
        "Create a database, tables, and a virtual warehouse for this tutorial.\nThese are the basic Snowflake objects needed for most Snowflake activities.",
        "For this tutorial you need to download the sample data files provided by Snowflake.",
        "To download and unzip the sample data files:",
        "Right-click the name of the\narchive file, data-load-internal.zip\nand save the link/file to your local file system.",
        "Unzip the sample files. The tutorial assumes you unpacked files in\nto the following directories:",
        "Linux/macOS: /tmp/load",
        "Windows: C:\\tempload",
        "These data files include sample contact data in the following formats:",
        "CSV files that contain a header row and five records. The field\ndelimiter is the pipe (|) character.\nThe following example shows a header row and one record:",
        "A single file in JSON format that contains one array and three objects.\nThe following is an example of an array that contains one of the objects:",
        "Execute the following statements to create a database, two tables\n(for csv and json data), and a virtual warehouse needed for this tutorial.\nAfter you complete the tutorial, you can drop these objects.",
        "The CREATE WAREHOUSE statement sets up the warehouse to be suspended initially.\nThe statement also sets AUTO_RESUME = true, which starts the warehouse automatically\nwhen you execute SQL statements that require compute resources.",
        "When you load data from a file into a table, you must describe the format of the file\nand specify how the data in the file should be interpreted and processed. For example,\nif you are loading pipe-delimited data from a CSV file, you must specify that the file\nuses the CSV format with pipe symbols as delimiters.",
        "When you execute the COPY INTO <table> command, you specify this format information. You can\neither specify this information as options in the command (e.g.\nTYPE = CSV, FIELD_DELIMITER = '|', etc.) or you can specify a\nfile format object that contains this format information. You can create a named file\nformat object using the CREATE FILE FORMAT command.",
        "In this step, you create file format objects describing the data format of the sample CSV and\nJSON data provided for this tutorial.",
        "Execute the CREATE FILE FORMAT command\nto create the mycsvformat file format.",
        "Where:",
        "TYPE = 'CSV' indicates the source file format type. CSV is the default file format type.",
        "FIELD_DELIMITER = '|' indicates the \u2018|\u2019 character is a field separator. The default value is \u2018,\u2019.",
        "SKIP_HEADER = 1 indicates the source file includes one header line. The COPY command skips these header lines when loading data. The default value is 0.",
        "Execute the CREATE FILE FORMAT command to create\nthe myjsonformat file format.",
        "Where:",
        "TYPE = 'JSON' indicates the source file format type.",
        "STRIP_OUTER_ARRAY = TRUE directs the COPY command to exclude the root brackets ([]) when loading data to the table.",
        "A stage specifies where data files are stored (i.e. \u201cstaged\u201d) so that the data\nin the files can be loaded into a table.\nA named internal stage\nis a cloud storage location managed by Snowflake.",
        "Creating a named stage is useful if you want multiple users or processes\nto upload files. If you plan to stage data files to load only\nby you, or to load only into a single table, then you may prefer\nto use your user stage or the table stage.  For information, see\nBulk loading from a local file system.",
        "In this step, you create named stages for the different types of sample data files.",
        "Execute CREATE STAGE to create the my_csv_stage stage:",
        "Note that if you specify the FILE_FORMAT option when creating\nthe stage, it is not necessary to specify the same FILE_FORMAT\noption in the COPY command used to load data from the stage.",
        "Execute CREATE STAGE to create the my_json_stage stage:",
        "Execute PUT to upload (stage) sample data files from your local\nfile system to the stages you created in Tutorial: Bulk loading from a local file system using COPY.",
        "Execute the PUT command to upload the CSV files from your local file system.",
        "Linux or macOS",
        "Windows",
        "Let us take a closer look at the command:",
        "file://<file-path>[/]contacts*.csv specifies the full directory path and names of the files on your local machine to stage. Note that file system wildcards are allowed.",
        "@my_csv_stage is the stage name where to stage the data.",
        "auto_compress=true; directs the command to compress the data when staging. This is also the default.",
        "The command returns the following result, showing the staged files:",
        "Execute the PUT command to upload the JSON file from your local file system to the named stage.",
        "Linux or macOS",
        "Windows",
        "The command returns the following result, showing the staged files:",
        "You can list the staged files by using the LIST command.",
        "Snowflake returns a list of your staged files.",
        "Snowflake returns a list of your staged files.",
        "Execute COPY INTO <table> to load staged data into the target tables.",
        "To load the data from the sample CSV files:",
        "Start by loading the data from one of the files (contacts1.csv.gz). Execute the following:",
        "Where:",
        "The FROM clause specifies the location of the staged data\nfile (stage name followed by the file name).",
        "The ON_ERROR clause specifies what to do when the COPY command\nencounters errors in the files. By default, the command stops\nloading data when the first error is encountered; however, we\u2019ve instructed it to skip any file containing an error and move on to loading the next file. Note that this is just for illustration purposes; none of the files in this tutorial contain errors.",
        "The COPY command returns a result showing the name of the file copied and related information:",
        "Load the rest of the staged files in the mycsvtable table.",
        "The following example uses pattern matching to load data from all files\nthat match the regular expression .*contacts[1-5].csv.gz into the mycsvtable table.",
        "Where the PATTERN clause specifies that the command should load data\nfrom the filenames matching this regular expression (.*employees0[1-5].csv.gz).",
        "The COPY command returns a result showing the name of the file copied and related information:",
        "Note the following highlights in the result:",
        "The data in contacts1.csv.gz is ignored because you already loaded\nthe data successfully.",
        "The data in these files was loaded successfully:\ncontacts2.csv.gz, contacts4.csv.gz, and\ncontacts5.csv.gz.",
        "The data in contacts3.csv.gz was skipped due to 2 data errors.\nThe next step in this tutorial addresses how to validate and fix\nthe errors.",
        "Load the contacts.json.gz staged data file into the myjsontable table.",
        "The COPY command returns a result showing the name of the file copied\nand related information:",
        "In the preceding step, the COPY INTO command skipped loading one of the files when\nit encountered the first error. You need to find all the errors and fix them.\nIn this step, you use the VALIDATE function\nto validate the previous execution of the COPY INTO command and returns all errors.",
        "You first need the query ID associated with the COPY INTO command\nthat you previously executed. You then call the VALIDATE function,\nspecifying the query ID.",
        "Retrieve the query ID.",
        "Sign in to Snowsight.",
        "Make sure the role in Snowsight is the same as the role you are using\nin SnowSQL to run SQL statements for this tutorial.",
        "Select Monitoring \u00bb Query History.",
        "Select the row for the specific COPY INTO command to open the query\ninformation pane.",
        "Copy the Query ID value.",
        "Validate the COPY INTO command execution, represented by the query ID,\nand save errors to a new table named save_copy_errors.",
        "In SnowSQL, execute the following command. Replace query_id with the Query ID value.",
        "Query the save_copy_errors table.",
        "The query returns the following results:",
        "The result shows two data errors in mycsvtable/contacts3.csv.gz:",
        "Number of columns in file (11) does not match that of the corresponding table (10)",
        "In Row 1, a hyphen was mistakenly replaced with the pipe (|) character, the data file delimiter, effectively creating an additional column in the record.",
        "Field delimiter '|' found while expecting record delimiter 'n'",
        "In Row 5, an additional pipe (|) character was introduced after a hyphen, breaking the record.",
        "Fix the errors in the records manually in the contacts3.csv file in your local environment.",
        "Use the PUT command to upload the modified data file to the stage. The modified file overwrites the existing staged file.",
        "Linux or macOS:",
        "Windows:",
        "Copy the data from the staged files into the tables.",
        "Snowflake returns the following results, indicating the data in contacts3.csv.gz was loaded successfully.",
        "Execute a SELECT query to verify that the data was loaded successfully.",
        "The query returns the following results:",
        "The query returns the following results:",
        "After you verify that you successfully copied data from your stage into the tables,\nyou can remove data files from the internal stage using the REMOVE\ncommand to save on data storage.",
        "Snowflake returns the following results:",
        "Snowflake returns the following results:",
        "Congratulations, you have successfully completed the tutorial.",
        "Execute the following DROP <object> commands to return your system to its state before you began the tutorial:",
        "Dropping the database automatically removes all child database objects such as tables.",
        "Snowflake in 20 minutes",
        "Tutorial: Bulk loading from Amazon S3 using COPY",
        "Was this page helpful?"
    ]
}