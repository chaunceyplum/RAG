{
    "url": "https://docs.snowflake.com/en/user-guide/snowflake-cortex/cortex-search/tutorials/cortex-search-tutorial-3-chat-advanced",
    "title": "Tutorial 3: Build a PDF chatbot with Cortex Search | Snowflake Documentation",
    "paragraphs": [
        "This tutorial describes how to build a chatbot from a dataset of PDF documents\nusing Cortex Search. In Tutorial 2,\nyou learned how to build a chatbot from text data that was already extracted from its source.\nThis tutorial walkts through an example of extracting that text from the PDFs using a basic Python\nUDF, then ingesting the extracted data into a Cortex Search Service.",
        "Extract text from a set of PDF files in a stage using a Python UDF.",
        "Create a Cortex Search Service from the extracted text.",
        "Create a Streamlit-in-Snowflake chat app that lets you ask questions about the\ndata extracted from the PDF documents.",
        "The following prerequisites are required to complete this tutorial:",
        "You have a Snowflake account and user with a role that grants the necessary\nprivileges to create a database, tables, virtual warehouse objects, Cortex Search Services, and Streamlit apps.",
        "Refer to the Snowflake in 20 minutes for instructions to meet these requirements.",
        "You will use a sample dataset of the Federal Open Market Committee (FOMC) meeting minutes for this tutorial.\nThis is a sample of twelve 10-page documents with meeting notes from FOMC meetings from 2023 and 2024.\nDownload the files directly from your browser by following this link:",
        "FOMC minutes sample",
        "The complete set of FOMC minutes can be found at the\nUS Federal Reserve\u2019s website.",
        "Note",
        "In a non-tutorial setting, you would bring your own data, possibly already in a Snowflake stage.",
        "Execute the following statements to create a database and a virtual warehouse needed for this tutorial.\nAfter you complete the tutorial, you can drop these objects.",
        "Note",
        "The CREATE DATABASE statement creates a database. The database automatically includes a schema named PUBLIC.",
        "The CREATE WAREHOUSE statement creates an initially suspended warehouse.",
        "First create a Snowflake stage to store the files that contain the data. This stage will hold the meeting minutes PDF files.",
        "Note",
        "The directory and encryption are configured for generating presigned_url for a file. If you don\u2019t need to generate presigned_url,\nyou can skip these configurations.",
        "Now upload the dataset. You can upload the dataset in Snowsight or using SQL. To upload in Snowsight:",
        "Sign in to Snowsight.",
        "Select Data in the left-side navigation menu.",
        "Select your database cortex_search_tutorial_db.",
        "Select your schema public.",
        "Select Stages and select fomc.",
        "On the top right, Select the + Files button.",
        "Drag and drop files into the UI or select Browse to choose a file from the dialog window.",
        "Select Upload to upload your file.",
        "Create a preprocessing function to do the following:",
        "Parse the PDF files and extract the text.",
        "Chunk the text into smaller pieces for indexing.",
        "Then create a table to hold the parsed data from the PDF files.",
        "Create a search service over your new table by running the following SQL command:",
        "This command specifies the attributes, which are the columns that you\u2019ll be able to filter search results on, as well as the\nwarehouse and target lag. The search column is designated as chunk, which is generated in the source query as a\nconcatenation of several text columns in the base table. The other columns in the source query can be included in response to a search request.",
        "You can query the service with Python SDK (using the snowflake Python package). This tutorial\ndemonstrates using the Python SDK in a Streamlit in Snowflake application.",
        "First, ensure your global Snowsight UI role is the same as the role used to create\nthe service in the service creation step.",
        "Sign in to Snowsight.",
        "Select Projects \u00bb Streamlit in the left-side navigation menu.",
        "Select + Streamlit App.",
        "Important: Select the cortex_search_tutorial_db database and the public schema for the app location.",
        "In the left pane of the Streamlit in Snowflake editor, select Packages and add snowflake (version >= 0.8.0) and snowflake-ml-python to install the required packages in your\napplication.",
        "Replace the example application code with the following Streamlit app:",
        "In the right pane of the Streamlit in Snowflake editor window, you\u2019ll see a preview of your Streamlit app. It should look similar to the following\nscreenshot:",
        "Enter a query in the text box to try out your new app. Some sample queries you can try are:",
        "How was gpd growth in q4 23?",
        "How was unemployment in the same quarter?",
        "How has the fed's view of the market change over the course of 2024?",
        "What was janet yellen's opinion about 2024 q1?",
        "Execute the following DROP <object> commands to return your system to its state before you began the tutorial:",
        "Dropping the database automatically removes all child database objects such as tables.",
        "Congratulations! You have successfully built a search app from a set of PDF files in Snowflake.",
        "You can continue learning using the following resources:",
        "Cortex Search overview",
        "Query a Cortex Search Service",
        "Was this page helpful?"
    ]
}