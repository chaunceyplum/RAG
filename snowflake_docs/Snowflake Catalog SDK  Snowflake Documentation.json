{
    "url": "https://docs.snowflake.com/en/user-guide/tables-iceberg-catalog",
    "title": "Snowflake Catalog SDK | Snowflake Documentation",
    "paragraphs": [
        "The Snowflake Catalog SDK is available for Apache Iceberg\u2122 versions 1.2.0 or later.",
        "With the Snowflake Catalog SDK, you can query Iceberg tables using a third-party engine\nsuch as Apache Spark\u2122 or Trino.",
        "The SDK supports the following commands for browsing Iceberg metadata in Snowflake:",
        "SHOW NAMESPACES",
        "USE NAMESPACE",
        "SHOW TABLES",
        "USE DATABASE",
        "USE SCHEMA",
        "The SDK currently supports read operations (SELECT statements) only.",
        "To install the Snowflake Catalog SDK,\ndownload the latest version of the Iceberg libraries.",
        "Before you can use the Snowflake Catalog SDK, you need a Snowflake database\nwith one or more Iceberg tables.\nTo create an Iceberg table, see Create an Apache Iceberg\u2122 table in Snowflake.",
        "After you establish a connection and the SDK confirms that Iceberg metadata is present,\nSnowflake accesses your Parquet data using the external volume that is associated with your Iceberg table(s).",
        "Note",
        "To learn about using Trino with the Snowflake Catalog SDK, see the\nTrino documentation.",
        "To read table data with the SDK, start by configuring the following properties for your Spark cluster:",
        "Note",
        "You can use any Snowflake-supported JDBC driver connection parameter\nin your configuration by using the following syntax: --conf spark.sql.catalog.snowflake_catalog.jdbc.property-name=property-value",
        "After you configure your Spark cluster, you can check which tables are available to query. For example:",
        "Then you can select a table to query.",
        "You can use the DataFrame structure with languages like Python and Scala to query data.",
        "Note",
        "If you receive vectorized read errors while running queries, you can disable the vectorized reads for your session\nby configuring: spark.sql.iceberg.vectorization.enabled=false. To keep using vectorized reads,\nyou can set the STORAGE_SERIALIZATION_POLICY parameter.",
        "When you issue a query, Snowflake caches the result within a certain time frame (90 seconds by default).\nYou might experience latency up to that duration. If you plan to access data programmatically for comparison purposes,\nyou can set the spark.sql.catalog..cache-enabled property to false to disable caching.",
        "If your application is designed to tolerate a specific amount of latency, you can use the following property\nto specify the latency period: spark.sql.catalog..cache.expiration-interval-ms.",
        "The following limitations apply to the Snowflake Catalog SDK and are subject to change:",
        "The SDK currently supports read operations (SELECT statements) only.",
        "Only Apache Spark and Trino are supported for reading Iceberg tables.",
        "You cannot use the SDK to access non-Iceberg Snowflake tables.",
        "Was this page helpful?",
        "On this page",
        "Related content"
    ]
}