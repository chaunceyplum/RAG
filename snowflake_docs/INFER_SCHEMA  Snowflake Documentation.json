{
    "url": "https://docs.snowflake.com/en/sql-reference/functions/infer_schema",
    "title": "INFER_SCHEMA | Snowflake Documentation",
    "paragraphs": [
        "Table functions",
        "Automatically detects the file metadata schema in a set of staged data files that contain semi-structured data and retrieves the column\ndefinitions.",
        "The GENERATE_COLUMN_DESCRIPTION function builds on the INFER_SCHEMA function output to simplify the\ncreation of new tables, external tables, or views (using the appropriate CREATE <object> command) based on the column\ndefinitions of the staged files.",
        "The CREATE TABLE or CREATE EXTERNAL TABLE command with the USING TEMPLATE clause can be executed to create a new table or external table with the column\ndefinitions derived from the INFER_SCHEMA function output.",
        "Note",
        "This function supports Apache Parquet, Apache Avro, ORC, JSON, and CSV files.",
        "Where:",
        "Name of the internal or external stage where the files are stored. Optionally include a path to one or more files in the cloud storage\nlocation; otherwise, the INFER_SCHEMA function scans files in all subdirectories in the stage:",
        "@[namespace.]int_stage_name[/path][/filename]",
        "Files are in the specified named internal stage.",
        "@[namespace.]ext_stage_name[/path][/filename]",
        "Files are in the specified named external stage.",
        "@~[/path][/filename]",
        "Files are in the stage for the current user.",
        "Note",
        "This SQL function supports named stages (internal or external) and user stages only. It does not support table stages.",
        "Specifies a list of one or more files (separated by commas) in a set of staged files that contain semi-structured data.  The files must already have been staged in either the Snowflake internal location or external location specified in the command. If any of the specified files cannot be found, the query will be aborted.",
        "The maximum number of files names that can be specified is 1000.",
        "Note",
        "For external stages only (Amazon S3, Google Cloud Storage, or Microsoft Azure), the file path is set by concatenating the URL in the stage definition and the list of resolved file names.",
        "However, Snowflake doesn\u2019t insert a separator implicitly between the path and file names. You must explicitly include a separator (/) either at the end of the URL in the stage\ndefinition or at the beginning of each file name specified in this parameter.",
        "Name of the file format object that describes the data contained in the staged files. For more information, see\nCREATE FILE FORMAT.",
        "Specifies whether column names detected from stage files are treated as case sensitive. By default, the value is FALSE, which means that Snowflake preserves the case of alphabetic characters when retrieving column names. If you specify the value as TRUE, column names are treated as case-insensitive and all column names are retrieved as uppercase letters.",
        "Specifies the maximum number of files scanned from stage. This option is recommended for large number of files that have identical schema across files. Note that this option cannot determine which files are scanned. If you want to scan specific files, use the FILES option instead.",
        "Specifies the maximum number of records scanned per file. This option only applies to CSV and JSON files. It is recommended to use this option for large files. But note that this option may affect the accuracy of schema detection.",
        "The function returns the following columns:",
        "Column Name",
        "Data Type",
        "Description",
        "COLUMN_NAME",
        "TEXT",
        "Name of a column in the staged files.",
        "TYPE",
        "TEXT",
        "Data type of the column.",
        "NULLABLE",
        "BOOLEAN",
        "Specifies whether rows in the column can store NULL instead of a value. Currently, the inferred nullability of a column can apply to one data file but not others in the scanned set.",
        "EXPRESSION",
        "TEXT",
        "Expression of the column in the format $1:COLUMN_NAME::TYPE (primarily for external tables). If IGNORE_CASE is specified as TRUE, the expression of the column will be in the format GET_IGNORE_CASE ($1, COLUMN_NAME)::TYPE.",
        "FILENAMES",
        "TEXT",
        "Names of the files that contain the column.",
        "ORDER_ID",
        "NUMBER",
        "Column order in the staged files.",
        "For CSV files, you can define column names by using the file format option PARSE_HEADER = [ TRUE | FALSE ].",
        "If the option is set to TRUE, the first row headers will be used to determine column names.",
        "The default value FALSE will return column names as c*, where * is the position of the column. Note that the SKIP_HEADER option is not supported with PARSE_HEADER = TRUE.",
        "The PARSE_HEADER option isn\u2019t supported for external tables.",
        "For both CSV and JSON files, the following file format options are currently not supported: DATE_FORMAT, TIME_FORMAT, and TIMESTAMP_FORMAT.",
        "The JSON TRIM_SPACE file format option is not supported.",
        "The scientific annotations (e.g. 1E2) in JSON files are retrieved as REAL data type.",
        "All the variations of timestamp data types are retrieved as TIMESTAMP_NTZ without any time zone information.",
        "For both CSV and JSON files, all columns are identified as NULLABLE.",
        "Creating an Iceberg table with the USING TEMPLATE clause (and\ncolumn definitions derived from INFER_SCHEMA output) isn\u2019t supported.",
        "Retrieve the column definitions for Parquet files in the mystage stage:",
        "Similar to the previous example, but specify a single Parquet file in the mystage stage:",
        "Retrieve the column definitions for Parquet files in the mystage stage with IGNORE_CASE specified as TRUE. In the returned output, all column names are retrieved as uppercase letters.",
        "Retrieve the column definitions for JSON files in the mystage stage:",
        "Creates a table using the detected schema from staged JSON files.",
        "Note",
        "Using * for ARRAY_AGG(OBJECT_CONSTRUCT()) may result in an error if the returned result is larger than 16MB. It is recommended to avoid using * for larger result sets, and only use the required columns, COLUMN NAME, TYPE, and NULLABLE, for the query. Optional column ORDER_ID can be included when using WITHIN GROUP (ORDER BY order_id).",
        "Retrieve the column definitions for CSV files in the mystage stage and load the CSV files using MATCH_BY_COLUMN_NAME:",
        "Was this page helpful?",
        "On this page",
        "Related content"
    ]
}