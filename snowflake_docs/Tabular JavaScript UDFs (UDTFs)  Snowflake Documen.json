{
    "url": "https://docs.snowflake.com/en/developer-guide/udf/javascript/udf-javascript-tabular-functions",
    "title": "Tabular JavaScript UDFs (UDTFs) | Snowflake Documentation",
    "paragraphs": [
        "You can write the handler for a user-defined table function (UDTF) in JavaScript.",
        "Your handler code processes rows received in the UDTF call and returns a tabular result. The received rows are partitioned,\neither implicitly by Snowflake or explicitly in the syntax of the function call. You use callback functions you write to\nprocess individual rows as well as the partitions into which they\u2019re grouped.",
        "The JavaScript code must meet the following requirements for the UDTF to be valid:",
        "The code must define a single literal JavaScript object.",
        "The defined object must include a callback function named processRow(). For more information, see\nObject callback functions.",
        "Important",
        "If the JavaScript code does not meet these requirements, the UDTF will still be created; however, it will fail when called in a query.",
        "Note",
        "Tabular functions (UDTFs) have a limit of 500 input arguments and 500 output columns.",
        "Through the JavaScript code, Snowflake interacts with the UDTF by invoking callback functions during the execution of the query. The\nfollowing skeleton outlines all available callback functions and their expected signatures:",
        "Note that only processRow() is required; the other functions are optional.",
        "This callback function is invoked once for each row in the input relation. The arguments to processRow() are passed in\nthe row object. For each of the arguments defined in the CREATE FUNCTION statement used to\ncreate the UDTF, there is a property on the row object with the same name in all uppercase. The value of this property\nis the value of the argument for the current row. (The value is converted to a JavaScript value.)",
        "The rowWriter argument is used by the user-supplied code to produce output rows. The rowWriter object defines a\nsingle function, writeRow(). The writeRow() function takes one argument,\nthe row object, which is a single row in the output table represented as a JavaScript object. For each column defined in the RETURNS\nclause of the CREATE FUNCTION command, a corresponding property can be defined on the row object. The value\nof that property on the row object becomes the value for the corresponding column in the output relation. Any output columns without\na corresponding property on the row object will have the value NULL in the result table.",
        "The finalize() callback function is invoked once, after all rows have been passed to processRow(). (If the data is\ngrouped into partitions, then finalize() is invoked once for each partition,\nafter all rows in that partition have been passed to processRow().)",
        "This callback function can be used to output any state that might have been aggregated in processRow() using the same row\nrowWriter as is passed to processRow().",
        "Note",
        "While Snowflake supports large partitions with timeouts tuned to process them successfully, especially large partitions can cause\nprocessing to time out (such as when finalize takes too long to complete). Please contact Snowflake Support if you need the\ntimeout threshold adjusted for specific usage scenarios.",
        "This callback function is invoked once for each partition prior to any invocations of processRow().",
        "Use initialize() to set up any state needed during the result computation.",
        "The initialize() function\u2019s argumentInfo parameter contains metadata about the arguments to the user-defined\nfunction. For example, if the UDF is defined as:",
        "then argumentInfo contains information about argument_1 and argument_2.",
        "argumentInfo has a property for each of those arguments. Each property is an object with the following values:",
        "type: String. The type of this argument.",
        "isConst: Boolean. If true, the value of this argument is constant (i.e. is the same for every row).",
        "constValue: If isConst (as defined above) is true, this entry contains the constant value of the argument; otherwise,\nthis field is undefined.",
        "The initialize() function cannot produce output rows.",
        "All three callback functions take a context object; this is reserved for future use and currently is empty.",
        "Caution",
        "Modifying the context object can yield undefined behavior.",
        "Additional functions and properties can be defined, as needed, on the object for use in the UDTF.",
        "The arguments to the callback functions are positional and can be named anything; however, for the purposes of this topic, the above\nnames are used for the remaining discussion and examples.",
        "In many situations, you might want to group rows into partitions. Partitioning has two main benefits:",
        "It allows you to group rows based on a common characteristic. This allows you to process all rows within the group together,\nand process each group independently.",
        "It allows Snowflake to divide up the workload to improve parallelization and thus performance.",
        "For example, you might partition stock price data into one group per stock. All stock prices for an individual company can be\nprocessed together, and the groups for different companies are processed independently.",
        "The following statement calls the UDTF named js_udtf() on individual partitions. Each partition contains all rows for which\nthe PARTITION BY expression evaluates to the same value (e.g. the same stock symbol).",
        "When you specify a partition expression to use with a UDTF, Snowflake calls:",
        "initialize() once for each partition.",
        "processRow() once for each individual row in that partition.",
        "finalize() once for each partition (after processing the last row in that partition).",
        "You might also want to process each partition\u2019s rows in a specified order. For example, if you want to calculate the moving average\nof a stock price over time, then order the stock prices by timestamp (as well as partitioning by stock or company). The following\nexample shows how to do this:",
        "When you specify an ORDER BY clause, the rows are processed in the order defined by the ORDER BY expression. Specifically,\nthe rows are passed to processRow() in the order defined by the ORDER BY expression.",
        "In most cases, partitioning data almost automatically improves opportunities for parallelization and thus higher performance.\nSnowflake usually executes several UDTF instances in parallel. (For this discussion, an instance of a JavaScript UDTF is defined\nas one instance of the JavaScript object used to represent the function in Snowflake.) Each partition of rows is passed to a single\ninstance of the UDTF.",
        "Note, however, that there is not necessarily a one-to-one relationship between partitions and UDTF instances. Although each\npartition is processed by only one UDTF instance, the converse is not necessarily true \u2014 a single UDTF instance can process\nmultiple partitions. It is therefore important to use initialize() and finalize() to specifically set up and tear\ndown each partition, for example, to avoid \u201ccarrying over\u201d accumulated values from the processing of one partition to the\nprocessing of another partition.",
        "When a table is joined to a table function, as in the partitioning examples above, the result set can contain the following, depending\non what is selected:",
        "The columns defined in the RETURNS clause of the CREATE FUNCTION command.",
        "The columns from the table, including both columns used to partition the data and other columns, whether or not they are used as input\nparameters to the UDTF.",
        "Note that rows produced in the processRow callback and rows produced by finalize differ in the following ways:",
        "When a row is produced in processRow, Snowflake can correlate it to an input row, namely the one passed into the function\nas the row argument. Note that if a given processRow invocation produces more than one row, the input attributes are\ncorrelated with each output row.",
        "For rows produced in processRow, all input columns can be joined to the output relation.",
        "In the finalize callback, Snowflake is unable to correlate it to any single row because there is no current row to correlate to.",
        "For rows produced in the finalize callback, only the columns used in the PARTITION BY clause are available (as these are the\nsame for any row in the current partition); all other attributes are NULL. If no PARTITION BY clause is specified, all those attributes\nare NULL.",
        "When calling a UDTF in the FROM clause of a query, specify the UDTF\u2019s name and arguments inside the parentheses that follow the TABLE\nkeyword.",
        "In other words, use a form such as the following for the TABLE keyword when calling a UDTF:",
        "Note",
        "For more about calling UDFs and UDTFs, see Calling a UDF.",
        "This simple example shows how to call a UDTF. This example passes literal values.\nThe UDTF merely returns the parameters in the reverse of the order in which they were passed.\nThis example does not use partitioning.",
        "This example calls a UDTF and passes it values from another table. In this example, the\nUDTF named js_udtf is called once for each row in the table named tab1. Each time that the function is called,\nit is passed values from columns c1 and c2 of the current row.\nAs above, the UDTF is called without a PARTITION BY clause.",
        "When no partitioning is used, the Snowflake execution engine partitions the input itself according to multiple factors, such as the\nsize of the warehouse processing the function and the cardinality of the input relation. When running in this mode, the user code\ncan make no assumptions about partitions. This is most useful when the function only needs to look at rows in isolation to produce\nits output and no state is aggregated across rows.",
        "JavaScript UDTFs can also be called using a partition. For example:",
        "An empty OVER clause means that every row belongs to the same partition (i.e. the entire input relation is one partition).",
        "Note",
        "You should exercise caution when calling a JavaScript UDTF with an empty OVER clause because this limits Snowflake to\ncreating one instance of the function and, therefore, Snowflake is unable to parallelize the computation.",
        "This section contains several sample JavaScript UDTFs.",
        "The following JavaScript UDTF takes no parameters and always returns the same values. It is provided primarily for illustration purposes:",
        "Output:",
        "The following JavaScript UDTF is also for illustration purposes, but uses an input parameter. Note that JavaScript is case-sensitive,\nbut SQL forces identifiers to uppercase, so when the JavaScript code references a SQL parameter name, the JavaScript code must use\nuppercase.",
        "Note also that function parameters are accessed through the parameter named row in the get_params() function:",
        "Output:",
        "The following JavaScript UDTF illustrates all the API callback functions and various output columns. It simply returns all rows as-is\nand provides a count of the number of characters seen in each partition. It also illustrates how to share state across a partition\nusing a THIS reference. Note that the example uses an initialize() callback to initialize the counter to zero; this\nis needed because a given function instance can be used to process multiple partitions:",
        "The following query illustrates calling the CHAR_SUM UDTF on the parts table with no partitioning:",
        "Output:",
        "When no partitioning is specified, Snowflake automatically defines partitions. In this example, due to the small number of rows,\nonly one partition is created (i.e. only one invocation of finalize() is executed). Note that the final row has NULL values\nin the input columns.",
        "Same query, but with explicit partitioning:",
        "Output:",
        "This example partitions over the p column, yielding two partitions. For each partition, a single row is returned in the\nfinalize() callback, yielding a total of two rows, distinguished by the NULL value in the s column. Because\np is the PARTITION BY column, the rows created in finalize() have the value of p that defines the current partition.",
        "This basic UDTF converts a \u201crange\u201d of IP addresses to a complete list of IP addresses. The input consists of the first 3 segments\nof the IP address (e.g. '192.168.1') and then the start and end of the range used to generate the last segment (e.g. 42 and\n45):",
        "Output:",
        "Building on the previous example, you might want to calculate individual IP addresses for more than one range. This next statement\ncreates a table of ranges that can be used to expand to individual IP addresses. The query then inputs the rows from the table into\nthe range_to_values() UDTF to return the individual IP addresses:",
        "Output:",
        "Attention",
        "In this example, the syntax used in the FROM clause is identical to the syntax of an inner join (i.e. FROM t1, t2); however,\nthe operation performed is not a true inner join. The actual behavior is the range_to_values() function is called with the values\nfrom each row in the ip_address changes table. In other words, it would be equivalent to writing:",
        "The concept of passing values to a UDTF can be extended to multiple UDTFs. The next example creates a UDTF named fake_ipv4_to_ipv6()\nthat \u201cconverts\u201d IPV4 address to IPV6 addresses. The query then calls the function as part of a more complex statement involving another UDTF:",
        "Output:",
        "The following query uses the fake_ipv4_to_ipv6 and range_to_values() UDTFs created earlier, with input from the\nip_address changes table. In other words, it starts with a set of IP address ranges, converts them to individual IPV4 addresses, and\nthen takes each IPV4 address and \u201cconverts\u201d it to a range of IPV6 addresses:",
        "Output:",
        "Note that this example used join syntax twice, but neither of the operations was a true join; both were calls to a UDTF using the\noutput of a table or another UDTF as input.",
        "A true inner join is order-insensitive. For example, the following statements are identical:",
        "Inputting values to a UDTF is not a true join, and the operations are not order-insensitive. For example, the\nfollowing query is identical to the previous example, except it reverses the order of the UDTFs in the FROM clause:",
        "The query fails with the following error message:",
        "SQL compilation error: error line 3 at position 35 invalid identifier 'RTV.IP_ADDRESS'",
        "The rtv.ip_address identifier is invalid because it was not defined before it was used. In a true join, this wouldn\u2019t happen, but\nwhen processing UDTFs using join syntax, this error might occur.",
        "Next, try a statement that mixes inputting to a UDTF with a true join; however, remember that inputting to a UDTF and doing an inner join\nboth use the same syntax, which might be confusing:",
        "Output:",
        "Attention",
        "The preceding example works as described; however, you should take care when combining UDTFs with true joins because this might result in non-deterministic and/or unexpected behavior.",
        "Also, note that this behavior might change in the future.",
        "Was this page helpful?",
        "On this page",
        "Related content"
    ]
}