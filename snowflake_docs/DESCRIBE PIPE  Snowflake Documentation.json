{
    "url": "https://docs.snowflake.com/en/sql-reference/sql/desc-pipe",
    "title": "DESCRIBE PIPE | Snowflake Documentation",
    "paragraphs": [
        "Describes the properties specified for a pipe, as well as the default values of the properties.",
        "DESCRIBE can be abbreviated to DESC.",
        "DROP PIPE , ALTER PIPE , CREATE PIPE , SHOW PIPES",
        "Specifies the identifier for the pipe to describe. If the identifier contains spaces or special characters, the entire string must be\nenclosed in double quotes. Identifiers enclosed in double quotes are also case-sensitive.",
        "Returns results only for the pipe owner (i.e. the role with the OWNERSHIP privilege on the pipe), a role with the MONITOR or OPERATE\nprivilege on the pipe, or a role with the global MONITOR EXECUTION privilege.",
        "To determine the current status of a pipe, query the SYSTEM$PIPE_STATUS function.",
        "To post-process the output of this command, you can use the RESULT_SCAN function, which treats the output as a table that can be queried.",
        "The command output provides pipe properties and metadata in the following columns:",
        "Column",
        "Description",
        "created_on",
        "Date and time when the pipe was created.",
        "name",
        "Name of the pipe.",
        "database_name",
        "Database in which the pipe is stored.",
        "schema_name",
        "Schema in which the pipe is stored.",
        "definition",
        "COPY statement used to load data from queued files into a Snowflake table.",
        "owner",
        "Name of the role that owns the pipe (i.e. that has the OWNERSHIP privilege on the pipe).",
        "notification_channel",
        "Amazon Resource Name of the Amazon SQS queue for the stage named in the DEFINITION column.",
        "comment",
        "Comment for this pipe.",
        "integration",
        "Name of the notification integration for pipes that rely on notification events to trigger data loads from Google Cloud Storage or Microsoft Azure cloud storage.",
        "pattern",
        "PATTERN copy option value in the COPY INTO <table> statement in the pipe definition, if the copy option was specified.",
        "error_integration",
        "Notification integration name for pipes that rely on error events in Amazon S3 cloud storage to trigger notifications.",
        "invalid_reason",
        "Displays some detailed information for your pipes that may have issues.\nYou can use the provided information to troubleshoot your pipes more effectively along\nwith SYSTEM$PIPE_STATUS.\nIf there is no issue with the pipe, the value is NULL.",
        "kind",
        "The kind of the pipe, either KAFKA or STAGE.",
        "Kafka-related columns",
        "Column",
        "Description",
        "broker_integration",
        "Name of the external access integration used with Kafka.",
        "broker_secret",
        "Name of the secret used with Kafka.",
        "row_format",
        "Row format of records: JSON or AVRO.",
        "schema",
        "Schema of records represented as variant.",
        "topic",
        "Name of a synchronized topic.",
        "Describe the mypipe pipe created in the examples in CREATE PIPE:",
        "Was this page helpful?",
        "On this page"
    ]
}