{
    "url": "https://docs.snowflake.com/en/developer-guide/snowpark/reference/python/1.26.0/snowpark/api/snowflake.snowpark.DataFrame",
    "title": "snowflake.snowpark.DataFrame | Snowflake Documentation",
    "paragraphs": [
        "Bases: object",
        "Represents a lazily-evaluated relational dataset that contains a collection\nof Row objects with columns defined by a schema (column name and type).",
        "A DataFrame is considered lazy because it encapsulates the computation or query\nrequired to produce a relational dataset. The computation is not performed until\nyou call a method that performs an action (e.g. collect()).",
        "Creating a DataFrame",
        "You can create a DataFrame in a number of different ways, as shown in the examples\nbelow.",
        "Creating a DataFrame by reading a table in Snowflake:",
        "Creating a DataFrame by reading files from a stage:",
        "Creating a DataFrame by specifying a sequence or a range:",
        "Create a new DataFrame by applying transformations to other existing DataFrames:",
        "Performing operations on a DataFrame",
        "Broadly, the operations on DataFrame can be divided into two types:",
        "Transformations produce a new DataFrame from one or more existing DataFrames. Note that transformations are lazy and don\u2019t cause the DataFrame to be evaluated. If the API does not provide a method to express the SQL that you want to use, you can use functions.sqlExpr() as a workaround.",
        "Actions cause the DataFrame to be evaluated. When you call a method that performs an action, Snowpark sends the SQL query for the DataFrame to the server for evaluation.",
        "Transforming a DataFrame",
        "The following examples demonstrate how you can transform a DataFrame.",
        "Using the select() method to select the columns that should be in the\nDataFrame (similar to adding a SELECT clause):",
        "Using the Column.as_() method to rename a column in a DataFrame (similar\nto using SELECT col AS alias):",
        "Using the filter() method to filter data (similar to adding a WHERE clause):",
        "Using the sort() method to specify the sort order of the data (similar to adding an ORDER BY clause):",
        "Using agg() method to aggregate results.",
        "Using the group_by() method to return a\nRelationalGroupedDataFrame that you can use to group and aggregate\nresults (similar to adding a GROUP BY clause).",
        "RelationalGroupedDataFrame provides methods for aggregating results, including:",
        "RelationalGroupedDataFrame.avg() (equivalent to AVG(column))",
        "RelationalGroupedDataFrame.count() (equivalent to COUNT())",
        "RelationalGroupedDataFrame.max() (equivalent to MAX(column))",
        "RelationalGroupedDataFrame.median() (equivalent to MEDIAN(column))",
        "RelationalGroupedDataFrame.min() (equivalent to MIN(column))",
        "RelationalGroupedDataFrame.sum() (equivalent to SUM(column))",
        "Using windowing functions. Refer to Window for more details.",
        "Handling missing values. Refer to DataFrameNaFunctions for more details.",
        "Performing an action on a DataFrame",
        "The following examples demonstrate how you can perform an action on a DataFrame.",
        "Performing a query and returning an array of Rows:",
        "Performing a query and print the results:",
        "Calculating statistics values. Refer to DataFrameStatFunctions for more details.",
        "Performing a query asynchronously and returning a list of Row objects:",
        "Performing a query and transforming it into pandas.DataFrame asynchronously:",
        "Methods",
        "agg(*exprs)",
        "Aggregate the data in the DataFrame.",
        "alias(name)",
        "Returns an aliased dataframe in which the columns can now be referenced to using col(<df alias>, <column name>).",
        "approxQuantile(col,\u00a0percentile,\u00a0*[,\u00a0...])",
        "For a specified numeric column and a list of desired quantiles, returns an approximate value for the column at each of the desired quantiles.",
        "approx_quantile(col,\u00a0percentile,\u00a0*[,\u00a0...])",
        "For a specified numeric column and a list of desired quantiles, returns an approximate value for the column at each of the desired quantiles.",
        "cache_result(*[,\u00a0statement_params])",
        "Caches the content of this DataFrame to create a new cached Table DataFrame.",
        "col(col_name)",
        "Returns a reference to a column in the DataFrame.",
        "collect()",
        "Executes the query representing this DataFrame and returns the result as a list of Row objects.",
        "collect_nowait(*[,\u00a0statement_params,\u00a0...])",
        "Executes the query representing this DataFrame asynchronously and returns: class:AsyncJob.",
        "copy_into_table(table_name,\u00a0*[,\u00a0files,\u00a0...])",
        "Executes a COPY INTO <table> command to load data from files in a stage location into a specified table.",
        "corr(col1,\u00a0col2,\u00a0*[,\u00a0statement_params])",
        "Calculates the correlation coefficient for non-null pairs in two numeric columns.",
        "count()",
        "Executes the query representing this DataFrame and returns the number of rows in the result (similar to the COUNT function in SQL).",
        "cov(col1,\u00a0col2,\u00a0*[,\u00a0statement_params])",
        "Calculates the sample covariance for non-null pairs in two numeric columns.",
        "createOrReplaceTempView(name,\u00a0*[,\u00a0comment,\u00a0...])",
        "Creates a temporary view that returns the same results as this DataFrame.",
        "createOrReplaceView(name,\u00a0*[,\u00a0comment,\u00a0...])",
        "Creates a view that captures the computation expressed by this DataFrame.",
        "create_or_replace_dynamic_table(name,\u00a0*,\u00a0...)",
        "Creates a dynamic table that captures the computation expressed by this DataFrame.",
        "create_or_replace_temp_view(name,\u00a0*[,\u00a0...])",
        "Creates a temporary view that returns the same results as this DataFrame.",
        "create_or_replace_view(name,\u00a0*[,\u00a0comment,\u00a0...])",
        "Creates a view that captures the computation expressed by this DataFrame.",
        "crossJoin(right,\u00a0*[,\u00a0lsuffix,\u00a0rsuffix])",
        "Performs a cross join, which returns the Cartesian product of the current DataFrame and another DataFrame (right).",
        "cross_join(right,\u00a0*[,\u00a0lsuffix,\u00a0rsuffix])",
        "Performs a cross join, which returns the Cartesian product of the current DataFrame and another DataFrame (right).",
        "crosstab(col1,\u00a0col2,\u00a0*[,\u00a0statement_params])",
        "Computes a pair-wise frequency table (a contingency table) for the specified columns.",
        "cube(*cols)",
        "Performs a SQL GROUP BY CUBE.",
        "describe(*cols)",
        "Computes basic statistics for numeric columns, which includes count, mean, stddev, min, and max.",
        "distinct()",
        "Returns a new DataFrame that contains only the rows with distinct values from the current DataFrame.",
        "drop(*cols)",
        "Returns a new DataFrame that excludes the columns with the specified names from the output.",
        "dropDuplicates(*subset)",
        "Creates a new DataFrame by removing duplicated rows on given subset of columns.",
        "drop_duplicates(*subset)",
        "Creates a new DataFrame by removing duplicated rows on given subset of columns.",
        "dropna([how,\u00a0thresh,\u00a0subset])",
        "Returns a new DataFrame that excludes all rows containing fewer than a specified number of non-null and non-NaN values in the specified columns.",
        "except_(other)",
        "Returns a new DataFrame that contains all the rows from the current DataFrame except for the rows that also appear in the other DataFrame.",
        "explain()",
        "Prints the list of queries that will be executed to evaluate this DataFrame.",
        "fillna(value[,\u00a0subset])",
        "Returns a new DataFrame that replaces all null and NaN values in the specified columns with the values provided.",
        "filter(expr)",
        "Filters rows based on the specified conditional expression (similar to WHERE in SQL).",
        "first()",
        "Executes the query representing this DataFrame and returns the first n rows of the results.",
        "flatten(input[,\u00a0path,\u00a0outer,\u00a0recursive,\u00a0mode])",
        "Flattens (explodes) compound values into multiple rows.",
        "groupBy(*cols)",
        "Groups rows by the columns specified by expressions (similar to GROUP BY in SQL).",
        "group_by(*cols)",
        "Groups rows by the columns specified by expressions (similar to GROUP BY in SQL).",
        "group_by_grouping_sets(*grouping_sets)",
        "Performs a SQL GROUP BY GROUPING SETS.",
        "intersect(other)",
        "Returns a new DataFrame that contains the intersection of rows from the current DataFrame and another DataFrame (other).",
        "join(right[,\u00a0on,\u00a0how,\u00a0lsuffix,\u00a0rsuffix,\u00a0...])",
        "Performs a join of the specified type (how) with the current DataFrame and another DataFrame (right) on a list of columns (on).",
        "join_table_function(func,\u00a0*func_arguments,\u00a0...)",
        "Lateral joins the current DataFrame with the output of the specified table function.",
        "limit(n[,\u00a0offset])",
        "Returns a new DataFrame that contains at most n rows from the current DataFrame, skipping offset rows from the beginning (similar to LIMIT and OFFSET in SQL).",
        "minus(other)",
        "Returns a new DataFrame that contains all the rows from the current DataFrame except for the rows that also appear in the other DataFrame.",
        "natural_join(right[,\u00a0how])",
        "Performs a natural join of the specified type (how) with the current DataFrame and another DataFrame (right).",
        "orderBy(*cols[,\u00a0ascending])",
        "Sorts a DataFrame by the specified expressions (similar to ORDER BY in SQL).",
        "order_by(*cols[,\u00a0ascending])",
        "Sorts a DataFrame by the specified expressions (similar to ORDER BY in SQL).",
        "pivot(pivot_col[,\u00a0values,\u00a0default_on_null])",
        "Rotates this DataFrame by turning the unique values from one column in the input expression into multiple columns and aggregating results where required on any remaining column values.",
        "printSchema([level])",
        "Prints the schema of a dataframe in tree format.",
        "print_schema([level])",
        "Prints the schema of a dataframe in tree format.",
        "randomSplit(weights[,\u00a0seed,\u00a0statement_params])",
        "Randomly splits the current DataFrame into separate DataFrames, using the specified weights.",
        "random_split(weights[,\u00a0seed,\u00a0statement_params])",
        "Randomly splits the current DataFrame into separate DataFrames, using the specified weights.",
        "rename(col_or_mapper[,\u00a0new_column])",
        "Returns a DataFrame with the specified column col_or_mapper renamed as new_column.",
        "replace(to_replace[,\u00a0value,\u00a0subset])",
        "Returns a new DataFrame that replaces values in the specified columns.",
        "rollup(*cols)",
        "Performs a SQL GROUP BY ROLLUP.",
        "sample([frac,\u00a0n])",
        "Samples rows based on either the number of rows to be returned or a percentage of rows to be returned.",
        "sampleBy(col,\u00a0fractions)",
        "Returns a DataFrame containing a stratified sample without replacement, based on a dict that specifies the fraction for each stratum.",
        "sample_by(col,\u00a0fractions)",
        "Returns a DataFrame containing a stratified sample without replacement, based on a dict that specifies the fraction for each stratum.",
        "select(*cols)",
        "Returns a new DataFrame with the specified Column expressions as output (similar to SELECT in SQL).",
        "selectExpr(*exprs)",
        "Projects a set of SQL expressions and returns a new DataFrame.",
        "select_expr(*exprs)",
        "Projects a set of SQL expressions and returns a new DataFrame.",
        "show([n,\u00a0max_width,\u00a0statement_params])",
        "Evaluates this DataFrame and prints out the first n rows with the specified maximum number of characters per column.",
        "sort(*cols[,\u00a0ascending])",
        "Sorts a DataFrame by the specified expressions (similar to ORDER BY in SQL).",
        "subtract(other)",
        "Returns a new DataFrame that contains all the rows from the current DataFrame except for the rows that also appear in the other DataFrame.",
        "take([n,\u00a0statement_params,\u00a0block])",
        "Executes the query representing this DataFrame and returns the first n rows of the results.",
        "toDF(*names)",
        "Creates a new DataFrame containing columns with the specified names.",
        "toLocalIterator(*[,\u00a0statement_params,\u00a0...])",
        "Executes the query representing this DataFrame and returns an iterator of Row objects that you can use to retrieve the results.",
        "toPandas(*[,\u00a0statement_params,\u00a0block])",
        "Executes the query representing this DataFrame and returns the result as a pandas DataFrame.",
        "to_df(*names)",
        "Creates a new DataFrame containing columns with the specified names.",
        "to_local_iterator()",
        "Executes the query representing this DataFrame and returns an iterator of Row objects that you can use to retrieve the results.",
        "to_pandas()",
        "",
        "Executes the query representing this DataFrame and returns the result as a pandas DataFrame.",
        "",
        "to_pandas_batches()",
        "Executes the query representing this DataFrame and returns an iterator of pandas dataframes (containing a subset of rows) that you can use to retrieve the results.",
        "to_snowpark_pandas([index_col,\u00a0columns])",
        "Convert the Snowpark DataFrame to Snowpark pandas DataFrame.",
        "union(other)",
        "Returns a new DataFrame that contains all the rows in the current DataFrame and another DataFrame (other), excluding any duplicate rows.",
        "unionAll(other)",
        "Returns a new DataFrame that contains all the rows in the current DataFrame and another DataFrame (other), including any duplicate rows.",
        "unionAllByName(other)",
        "Returns a new DataFrame that contains all the rows in the current DataFrame and another DataFrame (other), including any duplicate rows.",
        "unionByName(other)",
        "Returns a new DataFrame that contains all the rows in the current DataFrame and another DataFrame (other), excluding any duplicate rows.",
        "union_all(other)",
        "Returns a new DataFrame that contains all the rows in the current DataFrame and another DataFrame (other), including any duplicate rows.",
        "union_all_by_name(other)",
        "Returns a new DataFrame that contains all the rows in the current DataFrame and another DataFrame (other), including any duplicate rows.",
        "union_by_name(other)",
        "Returns a new DataFrame that contains all the rows in the current DataFrame and another DataFrame (other), excluding any duplicate rows.",
        "unpivot(value_column,\u00a0name_column,\u00a0column_list)",
        "Rotates a table by transforming columns into rows.",
        "where(expr)",
        "Filters rows based on the specified conditional expression (similar to WHERE in SQL).",
        "withColumn(col_name,\u00a0col[,\u00a0ast_stmt])",
        "Returns a DataFrame with an additional column with the specified name col_name.",
        "withColumnRenamed(existing,\u00a0new)",
        "Returns a DataFrame with the specified column existing renamed as new.",
        "with_column(col_name,\u00a0col[,\u00a0ast_stmt])",
        "Returns a DataFrame with an additional column with the specified name col_name.",
        "with_column_renamed(existing,\u00a0new)",
        "Returns a DataFrame with the specified column existing renamed as new.",
        "with_columns(col_names,\u00a0values)",
        "Returns a DataFrame with additional columns with the specified names col_names.",
        "Attributes",
        "analytics",
        "",
        "columns",
        "Returns all column names as a list.",
        "dtypes",
        "",
        "na",
        "Returns a DataFrameNaFunctions object that provides functions for handling missing values in the DataFrame.",
        "queries",
        "Returns a dict that contains a list of queries that will be executed to evaluate this DataFrame with the key queries, and a list of post-execution actions (e.g., queries to clean up temporary objects) with the key post_actions.",
        "schema",
        "The definition of the columns in this DataFrame (the \"relational schema\" for the DataFrame).",
        "session",
        "Returns a snowflake.snowpark.Session object that provides access to the session the current DataFrame is relying on.",
        "stat",
        "",
        "write",
        "Returns a new DataFrameWriter object that you can use to write the data in the DataFrame to a Snowflake database or a stage location",
        "is_cached",
        "Whether the dataframe is cached.",
        "Was this page helpful?"
    ]
}