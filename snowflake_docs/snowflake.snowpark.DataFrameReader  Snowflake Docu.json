{
    "url": "https://docs.snowflake.com/en/developer-guide/snowpark/reference/python/1.26.0/snowpark/api/snowflake.snowpark.DataFrameReader",
    "title": "snowflake.snowpark.DataFrameReader | Snowflake Documentation",
    "paragraphs": [
        "Bases: object",
        "Provides methods to load data in various supported formats from a Snowflake\nstage to a DataFrame. The paths provided to the DataFrameReader must refer\nto Snowflake stages.",
        "To use this object:",
        "1. Access an instance of a DataFrameReader by using the\nSession.read property.",
        "2. Specify any format-specific options and copy options\nby calling the option() or options() method. These methods return a\nDataFrameReader that is configured with these options. (Note that although\nspecifying copy options can make error handling more robust during the reading\nprocess, it may have an effect on performance.)",
        "3. Specify the schema of the data that you plan to load by constructing a\ntypes.StructType object and passing it to the schema() method if the file format is CSV. Other file\nformats such as JSON, XML, Parquet, ORC, and AVRO don\u2019t accept a schema.\nThis method returns a DataFrameReader that is configured to read data that uses the specified schema.\nCurrently, inferring schema is also supported for CSV and JSON formats as a preview feature open to all accounts.",
        "4. Specify the format of the data by calling the method named after the format\n(e.g. csv(), json(), etc.). These methods return a DataFrame\nthat is configured to load data in the specified format.",
        "5. Call a DataFrame method that performs an action (e.g.\nDataFrame.collect()) to load the data from the file.",
        "Loading the first two columns of a CSV file and skipping the first header line:",
        "Loading a gzip compressed json file:",
        "In addition, if you want to load only a subset of files from the stage, you can use the\npattern\noption to specify a regular expression that matches the files that you want to load.",
        "Loading only the CSV files from a stage location:",
        "To load Parquet, ORC and AVRO files, no schema is accepted because the schema will be automatically inferred.\nInferring the schema can be disabled by setting option \u201cinfer_schema\u201d to False. Then you can use $1 to access\nthe column data as an OBJECT.",
        "Loading JSON and XML files doesn\u2019t support schema either. You also need to use $1 to access the column data as an OBJECT.",
        "Methods",
        "avro(path)",
        "Specify the path of the AVRO file(s) to load.",
        "csv(path)",
        "Specify the path of the CSV file(s) to load.",
        "format(format)",
        "Specify the format of the file(s) to load.",
        "json(path)",
        "Specify the path of the JSON file(s) to load.",
        "load(path)",
        "Specify the path of the file(s) to load.",
        "option(key,\u00a0value)",
        "Sets the specified option in the DataFrameReader.",
        "options([configs])",
        "Sets multiple specified options in the DataFrameReader.",
        "orc(path)",
        "Specify the path of the ORC file(s) to load.",
        "parquet(path)",
        "Specify the path of the PARQUET file(s) to load.",
        "schema(schema)",
        "Define the schema for CSV files that you want to read.",
        "table(name)",
        "Returns a Table that points to the specified table.",
        "with_metadata(*metadata_cols)",
        "Define the metadata columns that need to be selected from stage files.",
        "xml(path)",
        "Specify the path of the XML file(s) to load.",
        "Was this page helpful?"
    ]
}