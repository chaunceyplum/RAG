{
    "url": "https://docs.snowflake.com/en/developer-guide/snowpark/reference/python/1.26.0/modin/pandas_api/modin.pandas.read_xml",
    "title": "modin.pandas.read_xml | Snowflake Documentation",
    "paragraphs": [
        "Read XML document into a DataFrame object.",
        "path_or_buffer (str, path object, or file-like object) \u2013 String, path object (implementing os.PathLike[str]), or file-like object implementing a read() function. The string can be a path. The string can further be a URL. Valid URL schemes include http, ftp, s3, and file.",
        "xpath (str, optional, default \u2018./*\u2019) \u2013 The XPath to parse required set of nodes for migration to DataFrame.``XPath`` should return a collection of elements and not a single element. Note: The etree parser supports limited XPath expressions. For more complex XPath, use lxml which requires installation.",
        "namespaces (dict, optional) \u2013 The namespaces defined in XML document as dicts with key being namespace prefix and value the URI. There is no need to include all namespaces in XML, only the ones used in xpath expression. Note: if XML document uses default namespace denoted as xmlns=\u2019<URI>\u2019 without a prefix, you must assign any temporary namespace prefix such as \u2018doc\u2019 to the URI in order to parse underlying nodes and/or attributes.",
        "elems_only (bool, optional, default False) \u2013 Parse only the child elements at the specified xpath. By default, all child elements and non-empty text nodes are returned.",
        "attrs_only (bool, optional, default False) \u2013 Parse only the attributes at the specified xpath. By default, all attributes are returned.",
        "names (list-like, optional) \u2013 Column names for DataFrame of parsed XML data. Use this parameter to rename original element names and distinguish same named elements and attributes.",
        "dtype (Type name or dict of column -> type, optional) \u2013 Data type for data or columns. E.g. {\u2018a\u2019: np.float64, \u2018b\u2019: np.int32, \u2018c\u2019: \u2018Int64\u2019} Use str or object together with suitable na_values settings to preserve and not interpret dtype. If converters are specified, they will be applied INSTEAD of dtype conversion.",
        "converters (dict, optional) \u2013 Dict of functions for converting values in certain columns. Keys can either be integers or column labels.",
        "parse_dates (bool or list of int or names or list of lists or dict, default False) \u2013 Identifiers to parse index or columns to datetime. The behavior is as follows:\n- boolean. If True -> try parsing the index.\n- list of int or names. e.g. If [1, 2, 3] -> try parsing columns 1, 2, 3 each as a separate date column.\n- list of lists. e.g. If [[1, 3]] -> combine columns 1 and 3 and parse as a single date column.\n- dict, e.g. {\u2018foo\u2019 : [1, 3]} -> parse columns 1, 3 as date and call result \u2018foo\u2019",
        "encoding (str, optional, default \u2018utf-8\u2019) \u2013 Encoding of XML document.",
        "parser ({\u2018lxml\u2019,\u2019etree\u2019}, default \u2018lxml\u2019) \u2013 Parser module to use for retrieval of data. Only \u2018lxml\u2019 and \u2018etree\u2019 are supported. With \u2018lxml\u2019 more complex XPath searches and ability to use XSLT stylesheet are supported.",
        "stylesheet (str, path object or file-like object) \u2013 A URL, file-like object, or a string path containing an XSLT script. This stylesheet should flatten complex, deeply nested XML documents for easier parsing. To use this feature you must have lxml module installed and specify \u2018lxml\u2019 as parser. The xpath must reference nodes of transformed XML document generated after XSLT transformation and not the original XML document. Only XSLT 1.0 scripts and not later versions is currently supported.",
        "iterparse (dict, optional) \u2013 The nodes or attributes to retrieve in iterparsing of XML document as a dict with key being the name of repeating element and value being list of elements or attribute names that are descendants of the repeated element. Note: If this option is used, it will replace xpath parsing and unlike xpath, descendants do not need to relate to each other but can exist any where in document under the repeating element. This memory- efficient method should be used for very large XML files (500MB, 1GB, or 5GB+). For example, {\u201crow_element\u201d: [\u201cchild_elem\u201d, \u201cattr\u201d, \u201cgrandchild_elem\u201d]}.",
        "compression (str or dict, default \u2018infer\u2019) \u2013 For on-the-fly decompression of on-disk data. If \u2018infer\u2019 and \u2018path_or_buffer\u2019 is path-like, then detect compression from the following extensions: \u2018.gz\u2019, \u2018.bz2\u2019, \u2018.zip\u2019, \u2018.xz\u2019, \u2018.zst\u2019, \u2018.tar\u2019, \u2018.tar.gz\u2019, \u2018.tar.xz\u2019 or \u2018.tar.bz2\u2019 (otherwise no compression). If using \u2018zip\u2019 or \u2018tar\u2019, the ZIP file must contain only one data file to be read in. Set to None for no decompression. Can also be a dict with key \u2018method\u2019 set to one of {\u2018zip\u2019, \u2018gzip\u2019, \u2018bz2\u2019, \u2018zstd\u2019, \u2018xz\u2019, \u2018tar\u2019} and other key-value pairs are forwarded to zipfile.ZipFile, gzip.GzipFile, bz2.BZ2File, zstandard.ZstdDecompressor, lzma.LZMAFile or tarfile.TarFile, respectively. As an example, the following could be passed for Zstandard decompression using a custom compression dictionary: compression={\u2018method\u2019: \u2018zstd\u2019, \u2018dict_data\u2019: my_compression_dict}.",
        "storage_options (dict, optional) \u2013 Extra options that make sense for a particular storage connection, e.g. host, port, username, password, etc. For HTTP(S) URLs the key-value pairs are forwarded to urllib.request.Request as header options. For other URLs (e.g. starting with \u201cs3://\u201d, and \u201cgcs://\u201d) the key-value pairs are forwarded to fsspec.open. Please see fsspec and urllib for more details, and for more examples on storage options refer here.",
        "dtype_backend ({\u2018numpy_nullable\u2019, \u2018pyarrow\u2019}) \u2013 Back-end data type applied to the resultant DataFrame (still experimental). If not specified, the default behavior is to not use nullable data types. If specified, the behavior is as follows:\n- \u201cnumpy_nullable\u201d: returns nullable-dtype-backed DataFrame\n- \u201cpyarrow\u201d: returns pyarrow-backed nullable ArrowDtype DataFrame",
        "A DataFrame.",
        "df",
        "See also",
        "Convert a JSON string to pandas object.",
        "Read HTML tables into a list of DataFrame objects.",
        "Notes",
        "This method is best designed to import shallow XML documents in following format which is the ideal fit for the two-dimensions of a DataFrame (row by column).",
        "As a file format, XML documents can be designed any way including layout of elements and attributes as long as it conforms to W3C specifications. Therefore, this method is a convenience handler for a specific flatter design and not all possible XML structures.",
        "However, for more complex XML documents, stylesheet allows you to temporarily redesign original document with XSLT (a special purpose language) for a flatter version for migration to a DataFrame.",
        "This function will always return a single DataFrame or raise exceptions due to issues with XML document, xpath, or other parameters.",
        "See the read_xml documentation in the IO section of the docs for more information in using this method to parse XML files to DataFrames.",
        "Examples",
        "Was this page helpful?"
    ]
}