{
    "url": "https://docs.snowflake.com/en/user-guide/tutorials/snowflake-in-20minutes",
    "title": "Snowflake in 20 minutes | Snowflake Documentation",
    "paragraphs": [
        "This tutorial uses the Snowflake command line client, SnowSQL, to introduce key concepts and tasks, including:",
        "Creating Snowflake objects\u2014You create a database and a table for storing data.",
        "Loading data\u2014We provide small sample CSV data files for you to load into the table.",
        "Querying\u2014You explore sample queries.",
        "Note",
        "Snowflake bills a minimal amount for the on-disk storage used for the sample data in\nthis tutorial. The tutorial provides steps to drop the database and minimize storage\ncost.",
        "Snowflake requires a virtual warehouse to load the\ndata and execute queries. A running virtual warehouse consumes Snowflake credits.\nIn this tutorial, you will be using a 30-day trial account,\nwhich provides free credits, so you won\u2019t incur any costs.",
        "In this tutorial you\u2019ll learn how to:",
        "Create Snowflake objects\u2014You create a database and a table for storing data.",
        "Install SnowSQL\u2014You install and use SnowSQL, the Snowflake command line query tool.",
        "Users of Visual Studio Code might consider using the Snowflake Extension for Visual Studio Code instead of SnowSQL.",
        "Load CSV data files\u2014You use various mechanisms to load data into tables from CSV files.",
        "Write and execute sample queries\u2014You write and execute a variety of queries against newly loaded data.",
        "This tutorial requires a database, table, and virtual warehouse to load and query data.\nCreating these Snowflake objects requires a Snowflake user with a role with the\nnecessary access control privileges. In addition, SnowSQL\nis required to execute the SQL statements in the tutorial. Lastly, the tutorial requires CSV files that contain sample data to load.",
        "You can complete this tutorial using an existing Snowflake warehouse, database, and table, and your own local data files, but we recommend using the Snowflake objects and the set of\nprovided data.",
        "To set up Snowflake for this tutorial, complete the following before continuing:",
        "Create a user",
        "To create the database, table, and virtual warehouse, you must be logged in as a\nSnowflake user with a role that grants you the privileges to create these objects.",
        "If you\u2019re using a 30-day trial account, you can log in as the user that was created for the account.\nThis user has the role with the privileges needed to create the objects.",
        "If you don\u2019t have a Snowflake user, you can\u2019t perform this tutorial.\nIf you don\u2019t have a role that lets you create a user, ask someone who does to perform this step for you.\nUsers with the ACCOUNTADMIN or SECURITYADMIN role can create users.",
        "Install SnowSQL",
        "To install SnowSQL, see Installing SnowSQL.",
        "Download sample data files",
        "For this tutorial you download sample employee data files in CSV format that Snowflake provides.",
        "To download and unzip the sample data files:",
        "Download the set of sample data files. Right-click the name of the archive\nfile, getting-started.zip, and save the link/file to your local file system.",
        "Unzip the sample files. The tutorial assumes you unpacked files into one of the following directories:",
        "Linux/macOS: /tmp",
        "Windows: C:\\\\temp",
        "Each file has five data records. The data uses a comma (,) character as field\ndelimiter. The following is an example record:",
        "There are no blank spaces before or after the commas separating the\nfields in each record. This is the default that Snowflake expects when loading CSV data.",
        "After you have SnowSQL, start SnowSQL to connect to Snowflake:",
        "Open a command line window.",
        "Start SnowSQL:",
        "Where:",
        "The preferred format of the account identifier is as follows:",
        "Names of your Snowflake organization and account. For more information, see Format 1 (preferred): Account name in your organization.",
        "<user_name> is the login name for your Snowflake user.",
        "Note",
        "If your account has an identity provider (IdP) that has been defined for your account, you can use a web browser to authenticate instead of a password, as the following example demonstrates:",
        "For more information, see Using a web browser for federated authentication/SSO.",
        "When SnowSQL prompts you, enter the password for your Snowflake user.",
        "If you log in successfully, SnowSQL displays a command prompt that includes\nyour current warehouse, database, and schema.",
        "Note",
        "If you get locked out of the account and can\u2019t obtain the account identifier, you can find it in the Welcome email that Snowflake sent to\nyou when you signed up for the trial account, or you can work with your\nORGADMIN to get the account details.\nYou can also find the values for locator, cloud, and region\nin the Welcome email.",
        "If your Snowflake user doesn\u2019t have a default warehouse, database, and schema, or if\nyou didn\u2019t configure SnowSQL to specify a default warehouse, database, and schema,\nthe prompt displays no warehouse, no database, and no schema. For example:",
        "This prompt indicates that there is no warehouse, database, and schema\nselected for the current session. You create these objects\nin the next step. As you follow the next steps in this tutorial to create\nthese objects, the prompt automatically updates to include the names of these objects.",
        "For more information, see Connecting through SnowSQL.",
        "During this step you create the following Snowflake objects:",
        "A database (sf_tuts) and a table (emp_basic). You load sample data into this table.",
        "A virtual warehouse (sf_tuts_wh).\nThis warehouse provides the compute resources needed to load data into\nthe table and query the table. For this tutorial, you create an X-Small warehouse.",
        "At the completion of this tutorial, you will remove these objects.",
        "Create the sf_tuts database using the CREATE DATABASE command:",
        "In this tutorial, you use the default schema (public) available for each database, rather than creating a new schema.",
        "Note that the database and schema you just created are now in use for your current\nsession, as reflected in the SnowSQL command prompt. You can also use the context\nfunctions to get this information.",
        "The following is an example result:",
        "Create a table named emp_basic in sf_tuts.public using the CREATE TABLE command:",
        "Note that the number of columns in the table, their positions, and their data types correspond to the fields in the sample CSV data files that you stage in the next step in this tutorial.",
        "Create an X-Small warehouse named sf_tuts_wh using the CREATE WAREHOUSE command:",
        "The sf_tuts_wh warehouse is initially suspended, but the DML statement also sets\nAUTO_RESUME = true. The AUTO_RESUME setting causes a warehouse to automatically start\nwhen SQL statements that require compute resources are executed.",
        "After you create the warehouse, it\u2019s now in use for your current session.\nThis information is displayed in your SnowSQL command prompt. You can also retrieve\nthe name of the warehouse by using the following context function:",
        "The following is an example result:",
        "A Snowflake stage is a location in cloud storage that you use to load and\nunload data from a table. Snowflake supports the following types of stages:",
        "Internal stages\u2014Used to store data files internally within Snowflake. Each user and table in Snowflake gets an internal stage by default for staging data files.",
        "External stages\u2014Used to store data files externally in Amazon S3, Google Cloud Storage, or Microsoft Azure.\nIf your data is already stored in these cloud storage services, you can use an external stage to load data in Snowflake tables.",
        "In this tutorial, we upload the sample data files\n(downloaded in Prerequisites)\nto the internal stage for the emp_basic table that you created earlier. You use the PUT command\nto upload the sample data files to that stage.",
        "Execute the PUT command in SnowSQL to upload local data files to the table stage\nprovided for the emp_basic table you created.",
        "For example:",
        "Linux or macOS",
        "Windows",
        "Let\u2019s take a closer look at the command:",
        "file://<file-path>[/]employees0*.csv specifies the full directory path and\nnames of the files on your local machine to stage. Note that file system wildcards are allowed, and if multiple files fit the pattern they are all displayed.",
        "@<namespace>.%<table_name> indicates to use the stage for the specified table, in this case the emp_basic table.",
        "The command returns the following result, showing the staged files:",
        "The PUT command compresses files by default using gzip, as indicated in the TARGET_COMPRESSION column.",
        "You can list the staged files using the LIST command.",
        "The following is an example result:",
        "To load your staged data into the target table, execute COPY INTO <table>.",
        "The COPY INTO <table> command uses the virtual warehouse you created\nin Create Snowflake objects to copy files.",
        "Where:",
        "The FROM clause specifies the location containing the data files (the internal stage for the table).",
        "The FILE_FORMAT clause specifies the file type as CSV, and specifies the double-quote\ncharacter (\") as the character used to enclose strings. Snowflake supports\ndiverse file types and options. These are described\nin CREATE FILE FORMAT.",
        "The PATTERN clause specifies that the command should load data from the filenames matching\nthis regular expression (.*employees0[1-5].csv.gz).",
        "The ON_ERROR clause specifies what to do when the COPY command encounters errors in the files. By default, the command stops loading data\nwhen the first error is encountered. This example skips any file containing an error and moves on to loading\nthe next file. (None of the files in this tutorial contain errors; this is included for illustration purposes.)",
        "The COPY command also provides an option for validating files before they are loaded. For more information about additional error checking and validation instructions, see the COPY INTO <table> topic and the other data loading tutorials.",
        "The COPY command returns a result showing the list of files copied and related information:",
        "You can query the data loaded in the emp_basic table using standard SQL and any supported\nfunctions and\noperators.",
        "You can also manipulate the data, such as updating the loaded data or inserting more data, using standard DML commands.",
        "Return all rows and columns from the table:",
        "The following is a partial result:",
        "In addition to loading data from staged files into a table, you can insert rows directly into a table using the INSERT DML command.",
        "For example, to insert two additional rows into the table:",
        "Return a list of email addresses with United Kingdom top-level domains using the [ NOT ] LIKE function:",
        "The following is an example result:",
        "For example, to calculate when certain employee benefits might start, add 90 days to employee start\ndates using the DATEADD function. Filter the list by employees whose start date occurred earlier than January 1, 2017:",
        "The following is an example result:",
        "Congratulations! You\u2019ve successfully completed this introductory tutorial.",
        "Take a few minutes to review a short summary and the key points covered in the tutorial.\nYou might also want to consider cleaning up by dropping any objects you created in the tutorial.\nLearn more by reviewing other topics in the Snowflake Documentation.",
        "In summary, data loading is performed in two steps:",
        "Stage the data files to load. The files can be staged internally (in Snowflake) or in an external location. In this tutorial, you stage files internally.",
        "Copy data from the staged files into an existing target table. A running\nwarehouse is required for this step.",
        "Remember the following key points about loading CSV files:",
        "A CSV file consists of 1 or more records, with 1 or more fields in each record, and sometimes a header record.",
        "Records and fields in each file are separated by delimiters. The default delimiters are:",
        "newline characters",
        "commas",
        "In other words, Snowflake expects each record in a CSV file to be separated by new lines and the fields (i.e. individual values) in each record to be separated by commas. If different\ncharacters are used as record and field delimiters, you must explicitly specify this as part of the file format when loading.",
        "There is a direct correlation between the fields in the files and the columns in the table you will be loading, in terms of:",
        "Number of fields (in the file) and columns (in the target table).",
        "Positions of the fields and columns within their respective file/table.",
        "Data types, such as string, number, or date, for fields and columns.",
        "The records will not be loaded if the numbers, positions, and data types don\u2019t align with the data.",
        "Note",
        "Snowflake supports loading files in which the fields don\u2019t exactly align with the columns in the target table;\nhowever, this is a more advanced data loading topic (covered in\nTransforming data during a load).",
        "If the objects you created in this tutorial are no longer needed,\nyou can remove them from the system with DROP <object> statements.",
        "To exit a connection, use the !exit command for SnowSQL (or its alias, !disconnect).",
        "Exit drops the current connection and quits SnowSQL if it is the last connection.",
        "Continue learning about Snowflake using the following resources:",
        "Complete the other tutorials provided by Snowflake:",
        "Snowflake Tutorials",
        "Familiarize yourself with key Snowflake concepts and features, as well as the SQL commands to perform queries and insert/update data:",
        "Introduction to Snowflake",
        "Query syntax",
        "Data Manipulation Language (DML) commands",
        "Was this page helpful?"
    ]
}