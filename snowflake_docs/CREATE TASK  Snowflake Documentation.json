{
    "url": "https://docs.snowflake.com/en/sql-reference/sql/create-task",
    "title": "CREATE TASK | Snowflake Documentation",
    "paragraphs": [
        "Creates a new task in the current/specified schema or replaces an existing task.",
        "This command supports the following variants:",
        "CREATE OR ALTER TASK: Creates a task if it doesn\u2019t exist or alters an existing task.",
        "CREATE TASK \u2026 CLONE: Creates a clone of an existing task.",
        "For information about tasks, see Introduction to tasks.",
        "ALTER TASK , DROP TASK , SHOW TASKS , DESCRIBE TASK",
        "CREATE OR ALTER <object>",
        "Important",
        "Newly created or cloned tasks are created suspended. For information about running suspended tasks, see ALTER TASK \u2026 RESUME or EXECUTE TASK.",
        "Preview Feature \u2014 Open",
        "Available to all accounts.",
        "Creates a new task if it doesn\u2019t already exist, or transforms an existing task into the task defined in the statement.\nA CREATE OR ALTER TASK statement follows the syntax rules of a CREATE TASK statement and has the same limitations as an\nALTER TASK statement.",
        "Supported task alterations include:",
        "Change task properties and parameters. For example, SCHEDULE, USER_TASK_TIMEOUT_MS, or COMMENT.",
        "Set, unset, or change task predecessors.",
        "Set, unset, or change task condition (WHEN clause).",
        "Change the task definition (AS clause).",
        "For more information, see CREATE OR ALTER TASK usage notes.",
        "Creates a new task with the same parameter values:",
        "For more details, see CREATE <object> \u2026 CLONE.",
        "Note",
        "Cloning tasks using CREATE TASK <name> CLONE, or cloning a schema containing tasks,\ncopies all underlying task properties unless explicitly overridden.",
        "String that specifies the identifier for the task; must be unique for the schema in which the task is created.",
        "In addition, the identifier must start with an alphabetic character and cannot contain spaces or special characters unless the\nentire identifier string is enclosed in double quotes, such as \"My object\". Identifiers enclosed in double quotes are also\ncase-sensitive.",
        "For more details, see Identifier requirements.",
        "Any one of the following:",
        "Single SQL statement",
        "Call to a stored procedure",
        "Procedural logic using Snowflake Scripting",
        "Snowsight doesn\u2019t support creating or modifying tasks to use Snowflake Scripting. Instead, use SnowSQL or another command-line\nclient.",
        "The SQL code is executed when the task runs. Verify that the {sql} executes as expected before using it in a task.",
        "Note",
        "Serverless tasks support the use of Java or Python external functions. However,\na serverless task can\u2019t invoke the following object types and functions developed inside of Snowflake:",
        "UDFs (user-defined functions) that contain Java or Python code.",
        "Stored procedures written in Scala (using Snowpark), or which call UDFs that contain Java or Python code.",
        "WAREHOUSE = string or . USER_TASK_MANAGED_INITIAL_WAREHOUSE_SIZE = string",
        "Specifies the virtual warehouse that provides compute resources for task runs.",
        "Omit this parameter to use serverless compute resources for runs of this task. Snowflake automatically resizes and scales serverless\ncompute resources as required for each workload. When a schedule is specified for a task, Snowflake adjusts the resource size to\ncomplete future runs of the task within the specified time frame. To specify the initial warehouse size for the task, set the\nUSER_TASK_MANAGED_INITIAL_WAREHOUSE_SIZE = string parameter.",
        "Applied only to serverless tasks.",
        "Specifies the size of the compute resources to provision for the first run of the task, before a task history is available for\nSnowflake to determine an ideal size. Once a task has successfully completed a few runs, Snowflake ignores this parameter setting.",
        "Note that if the task history is unavailable for a given task, the compute resources revert to this initial size.",
        "Note",
        "If a WAREHOUSE = string parameter value is specified, then setting this parameter produces a user error.",
        "The size is equivalent to the compute resources available when creating a warehouse (using\nCREATE WAREHOUSE), such as SMALL, MEDIUM, or LARGE. The largest size supported by the parameter\nis XXLARGE. If the parameter is omitted, the first runs of the task are executed using a medium-sized (MEDIUM) warehouse.",
        "You can change the initial size (using ALTER TASK) after the task is created but\nbefore it has run successfully once. Changing the parameter after the first run of this task starts has no effect on the\ncompute resources for current or future task runs.",
        "Note that suspending and resuming a task doesn\u2019t remove the task history used to size the compute resources. The task history is\nonly removed if the task is recreated (using the CREATE OR REPLACE TASK syntax).",
        "For more information about this parameter, see USER_TASK_MANAGED_INITIAL_WAREHOUSE_SIZE.",
        "Specifies the schedule for periodically running the task:",
        "Note",
        "For Triggered Tasks, a schedule is not required. For other tasks, a schedule must be defined for a standalone task or the root task in a task graph;\notherwise, the task only runs if manually executed using EXECUTE TASK.",
        "A schedule cannot be specified for child tasks in a task graph.",
        "Specifies a cron expression and time zone for periodically running the task. Supports a subset of standard cron utility syntax.",
        "For a list of time zones, see the list of tz database time zones\n(in Wikipedia).",
        "The cron expression consists of the following fields:",
        "The following special characters are supported:",
        "Wildcard. Specifies any occurrence of the field.",
        "Stands for \u201clast\u201d. When used in the day-of-week field, it allows you to specify constructs such as \u201cthe last Friday\u201d (\u201c5L\u201d) of\na given month. In the day-of-month field, it specifies the last day of the month.",
        "Indicates the nth instance of a given unit of time. Each quanta of time is computed independently. For example, if 4/3 is\nspecified in the month field, then the task is scheduled for April, July, and October, which is every 3 months, starting with the\n4th month of the year. The same schedule is maintained in subsequent years. That is, the task is not scheduled to run in\nJanuary (3 months after the October run).",
        "Note",
        "The cron expression currently evaluates against the specified time zone only. Altering the TIMEZONE parameter value\nfor the account (or setting the value at the user or session level) does not change the time zone for the task.",
        "The cron expression defines all valid run times for the task. Snowflake attempts to run a task based on this schedule;\nhowever, any valid run time is skipped if a previous run hasn\u2019t completed before the next valid run time starts.",
        "When both a specific day of month and day of week are included in the cron expression, then the task is scheduled on days\nsatisfying either the day of month or day of week. For example, SCHEDULE = 'USING CRON 0 0 10-20 * TUE,THU UTC'\nschedules a task at 0AM on any 10th to 20th day of the month and also on any Tuesday or Thursday outside of those dates.",
        "The shortest granularity of time in cron is minutes. If a task is resumed during the minute defined in its cron expression,\nthe first scheduled run of the task is the next occurrence of the instance of the cron expression. For example, if task\nscheduled to run daily at midnight (USING CRON 0 0 * * *) is resumed at midnight plus 5 seconds (00:00:05), the\nfirst task run is scheduled for the following midnight.",
        "Specifies an interval (in minutes) of wait time inserted between runs of the task. Accepts positive integers only.",
        "Also supports num M syntax.",
        "To avoid ambiguity, a base interval time is set when:",
        "When the task is resumed (using ALTER TASK \u2026 RESUME) or",
        "When a different interval is set (using ALTER TASK \u2026 SET SCHEDULE)",
        "The base interval time starts the interval counter from the current clock time. For example, if an INTERVAL value of 10 is set\nand the task is enabled at 9:03 AM, then the task runs at 9:13 AM, 9:23 AM, and so on. Note that we make a best effort to ensure\nabsolute precision, but only guarantee that tasks don\u2019t execute before their set interval occurs. For instance, in the\ncurrent example, the task could first run at 9:14 AM, but won\u2019t run at 9:12 AM.",
        "Note",
        "The maximum supported value is 11520 (8 days). Tasks that have a greater num MINUTE value never run.",
        "Specifies a string representation of key value pairs that can be accessed by all tasks in the task graph. Must be in JSON format. For more information about getting the configuration string for the task that is currently running, see SYSTEM$GET_TASK_GRAPH_CONFIG.",
        "Note",
        "This parameter can only be set on a root task. The setting applies to all tasks in the task graph.",
        "The parameter can be set on standalone tasks but doesn\u2019t affect the task behavior. Snowflake ensures only one instance of a\nstandalone task is running at a given time.",
        "Specifies whether to allow multiple instances of the task graph to run concurrently.",
        "Note",
        "This parameter can only be set on a root task. The setting applies to all tasks in the task graph.",
        "The parameter can be set on standalone tasks but doesn\u2019t affect the task behavior. Snowflake ensures only one instance of a\nstandalone task is running at a given time.",
        "TRUE If the next scheduled run of the root task occurs while the current run of any child task is still in operation, another\ninstance of the task graph begins. If a root task is still running when the next scheduled run time occurs, then that scheduled time is\nskipped.",
        "FALSE The next run of a root task is scheduled only after all child tasks in the task graph have finished running. This means\nthat if the cumulative time required to run all tasks in the task graph exceeds the explicit scheduled time set in the definition of\nthe root task, at least one run of the Task Graph is skipped.",
        "Default: FALSE",
        "Specifies a comma-separated list of session parameters to set for the session when the task runs. A task supports all session\nparameters. For the complete list, see Session parameters.",
        "Specifies the time limit on a single run of the task before it times out (in milliseconds).",
        "Note",
        "Before you increase the time limit on a task significantly, consider whether the SQL statement initiated by the task could be\noptimized (either by rewriting the statement or using a stored procedure) or the warehouse size should be increased.",
        "In some situations, the parameter STATEMENT_TIMEOUT_IN_SECONDS has higher precedence than USER_TASK_TIMEOUT_MS. For\ndetails, see STATEMENT_TIMEOUT_IN_SECONDS.",
        "For more information about this parameter, see USER_TASK_TIMEOUT_MS.",
        "Values: 0 - 604800000 (7 days). A value of 0 specifies that the maximum timeout value is enforced.",
        "Default: 3600000 (1 hour)",
        "Specifies the number of consecutive failed task runs after which the current task is suspended automatically. Failed task runs\ninclude runs in which the SQL code in the task body either produces a user error or times out. Task runs that are skipped,\ncanceled, or that fail due to a system error are considered indeterminate and aren\u2019t included in the count of failed task runs.",
        "Set the parameter on a standalone task or the root task in a task graph. When the parameter is set to a value greater than 0, the\nfollowing behavior applies to runs of the standalone task or task graph:",
        "Standalone tasks are automatically suspended after the specified number of consecutive task runs either fail or time out.",
        "The root task is automatically suspended after the run of any single task in a task graph fails or times out the specified\nnumber of times in consecutive runs.",
        "When the parameter is set to 0, failed tasks aren\u2019t automatically suspended.",
        "The setting applies to tasks that rely on either serverless compute resources or virtual warehouse compute resources.",
        "For more information about this parameter, see SUSPEND_TASK_AFTER_NUM_FAILURES.",
        "Values: 0 - No upper limit.",
        "Default: 10",
        "Required only when configuring a task to send error notifications using Amazon Simple Notification Service (SNS), Microsoft Azure Event Grid, or Google Pub/Sub.",
        "Specifies the name of the notification integration used to communicate with Amazon SNS, MS Azure Event Grid, or Google Pub/Sub. For more information, see\nEnabling notifications for tasks.",
        "Required only when configuring a task to send success notifications using Amazon Simple Notification Service (SNS), Microsoft Azure Event Grid, or Google Pub/Sub.",
        "Specifies the name of the notification integration used to communicate with Amazon SNS, MS Azure Event Grid, or Google Pub/Sub. For more information, see\nEnabling notifications for tasks.",
        "Specifies a comment for the task.",
        "Default: No value",
        "Specifies one or more predecessor tasks for the current task. Use this option to create a task graph or\nadd this task to an existing task graph. A task graph is a series of tasks that starts with a scheduled root task and is linked together\nby dependencies.",
        "Note that the structure of a task graph can be defined after all of its component tasks are created. Execute\nALTER TASK \u2026 ADD AFTER statements to specify the predecessors for each task in the planned task graph.",
        "A task runs after all of its predecessor tasks have finished their own runs successfully (after a brief lag).",
        "Note",
        "The root task should have a defined schedule. Each child task must have one or more defined predecessor tasks, specified\nusing the AFTER parameter, to link the tasks together.",
        "A single task is limited to 100 predecessor tasks and 100 child tasks. In addition, a task graph is limited to a maximum of 1000 tasks\ntotal (including the root task) in either a resumed or suspended state.",
        "Accounts are currently limited to a maximum of 30000 resumed tasks.",
        "All tasks in a task graph must have the same task owner. A single role must have the OWNERSHIP privilege on all of the tasks in\nthe task graph.",
        "All tasks in a task graph must exist in the same schema.",
        "The root task must be suspended before any task is recreated (using the CREATE OR REPLACE TASK syntax) or a child task\nis added (using CREATE TASK \u2026 AFTER or ALTER TASK \u2026 ADD AFTER) or removed (using ALTER TASK \u2026 REMOVE AFTER).",
        "If any task in a task graph is cloned, the role that clones the task becomes the owner of the clone by default.",
        "If the owner of the original task creates the clone, then the task clone retains the link between the task and the predecessor\ntask. This means the same predecessor task triggers both the original task and the task clone.",
        "If another role creates the clone, then the task clone can have a schedule but not a predecessor.",
        "Current limitations:",
        "Snowflake guarantees that at most one instance of a task with a defined schedule is running at a given time; however, we cannot\nprovide the same guarantee for tasks with a defined predecessor task.",
        "Specifies a Boolean SQL expression; multiple conditions joined with AND/OR are supported. When a task is triggered (based on its\nSCHEDULE or AFTER setting), it validates the conditions of the expression to determine whether to execute. If the\nconditions of the expression are not met, then the task skips the current run. Any tasks that identify this task as a\npredecessor also don\u2019t run.",
        "The following are supported in a task WHEN clause:",
        "SYSTEM$STREAM_HAS_DATA is supported for evaluation in the SQL expression.",
        "This function indicates whether a specified stream contains change tracking data. You can use this function to evaluate whether the specified stream contains\nchange data before starting the current run. If the result is FALSE, then the task doesn\u2019t run.",
        "Note",
        "SYSTEM$STREAM_HAS_DATA is designed to avoid returning a FALSE value even when the stream contains\nchange data. However, this function isn\u2019t guaranteed to avoid returning a TRUE value when the stream contains no change data.",
        "SYSTEM$GET_PREDECESSOR_RETURN_VALUE is supported for evaluation in the SQL expression.",
        "This function retrieves the return value for the predecessor task in a task graph.  The return value can be used as part of\na boolean expression.  When using SYSTEM$GET_PREDECESSOR_RETURN_VALUE, you can cast the returned value to\nthe appropriate numeric, string, or boolean type if required.",
        "Simple examples include:",
        "Note",
        "Use of PARSE_JSON in TASK \u2026 WHEN expressions isn\u2019t supported as it requires warehouse based compute resources.",
        "Boolean operators such as AND, OR, NOT, and others.",
        "Simple example that runs whenever data changes in either of two streams:",
        "Simple example that runs only after data changes in two separate streams:",
        "Casts between numeric, string, and boolean types.",
        "Comparison operators such as equal, not equal, greater than, less than, and others.",
        "Validating the conditions of the WHEN expression does not require compute resources. The validation is instead processed in the cloud\nservices layer. A nominal charge accrues each time a task evaluates its WHEN condition and doesn\u2019t run. The charges accumulate each time\nthe task is triggered until it runs. At that time, the charge is converted to Snowflake credits and added to the compute resource usage\nfor the task run.",
        "Generally the compute time to validate the condition is insignificant compared to task execution time. As a best practice, align\nscheduled and actual task runs as closely as possible. Avoid task schedules that don\u2019t align with task runs. For\nexample, if data is inserted into a table with a stream roughly every 24 hours, don\u2019t schedule a task that checks for stream data\nevery minute. The charge to validate the WHEN expression with each run is generally insignificant, but the charges are cumulative.",
        "Note that daily consumption of cloud services that falls below the\n10% quota of the daily usage of the compute resources accumulates no cloud services charges.",
        "Specifies the tag name and the tag string value.",
        "The tag value is always a string, and the maximum number of characters for the tag value is 256.",
        "For information about specifying tags in a statement, see Tag quotas for objects and columns.",
        "This parameter is not supported by the CREATE OR ALTER variant syntax.",
        "Specifies the name of a root task that the finalizer task is associated with. Finalizer tasks run after all other tasks in the task graph run to completion. You can define the SQL of a finalizer task to handle notifications and the release and cleanup of resources that a task graph uses. For more information, see Release and cleanup of task graphs.",
        "A root task can only have one finalizer task. If you create multiple finalizer tasks for a root task, the task creation will fail.",
        "A finalizer task cannot have any child tasks. Any command attempting to make the finalizer task a predecessor will fail.",
        "A finalizer task cannot have a schedule. Creating a finalizer task with a schedule will fail.",
        "Default: No value",
        "Specifies the number of automatic task graph retry attempts. If any task graphs complete in a FAILED state, Snowflake can automatically\nretry the task graphs from the last task in the graph that failed.",
        "The automatic task graph retry is disabled by default. To enable this feature, set TASK_AUTO_RETRY_ATTEMPTS to a value greater than 0\non the root task of a task graph.",
        "Note that this parameter must be set to the root task of a task graph. If it\u2019s set to a child task, an error will be returned.",
        "Values: 0 - 30.",
        "Default: 0",
        "Defines how frequently a task can execute in seconds. If data changes occur more often than the specified minimum, changes will be\ngrouped and processed together.",
        "The task will run every 12 hours even if this value is set to more than 12 hours.",
        "Values: Minimum 10, maximum 604800.",
        "Default: 30",
        "Specifies the desired task completion time. This parameter only applies to serverless tasks. This property is only set on a Task.",
        "Default: No value\nValues: Minimum of 1 minute, maximum of 24 hours.",
        "Specifies the minimum allowed warehouse size for the serverless task. This parameter only applies to serverless tasks. This parameter can be specified on the Task, Schema, Database, or Account. Precedence follows the standard parameter hierarchy.",
        "Default: No value\nValues: Minimum XSMALL, Maximum XXLARGE. Values are consistent with WAREHOUSE_SIZE values.",
        "Note that if both SERVERLESS_TASK_MIN_STATEMENT_SIZE and USER_TASK_MANAGED_INITIAL_WAREHOUSE_SIZE are specified, SERVERLESS_TASK_MIN_STATEMENT_SIZE must be equal to or smaller than USER_TASK_MANAGED_INITIAL_WAREHOUSE_SIZE.",
        "Specifies the maximum allowed warehouse size for the serverless task. This parameter only applies to serverless tasks. This parameter can be specified on the Task, Schema, Database, or Account. Precedence follows the standard parameter hierarchy.",
        "Default: No value\nValues: Minimum XSMALL, Maximum XXLARGE.",
        "Note that if both SERVERLESS_TASK_MIN_STATEMENT_SIZE and SERVERLESS_TASK_MAX_STATEMENT_SIZE are specified, SERVERLESS_TASK_MIN_STATEMENT_SIZE must be less than or equal to SERVERLESS_TASK_MAX_STATEMENT_SIZE. SERVERLESS_TASK_MAX_STATEMENT_SIZE must be equal to or greater than USER_TASK_MANAGED_INITIAL_WAREHOUSE_SIZE",
        "A role used to execute this SQL command must have the following\nprivileges at a minimum:",
        "Privilege",
        "Object",
        "Notes",
        "EXECUTE MANAGED TASK",
        "Account",
        "Required only for tasks that rely on serverless compute resources for runs.",
        "CREATE TASK",
        "Schema",
        "USAGE",
        "Warehouse",
        "Required only for tasks that rely on user-managed warehouses for runs.",
        "OWNERSHIP",
        "Task",
        "Required only when executing a CREATE OR ALTER TASK statement for an existing task.",
        "OWNERSHIP is a special privilege on an object that is automatically granted to the role that created the object, but can also be transferred using the GRANT OWNERSHIP command to a different role by the owning role (or any role with the MANAGE GRANTS privilege).",
        "The USAGE privilege on the parent database and schema are required to perform operations on any object in a schema.",
        "For instructions on creating a custom role with a specified set of privileges, see Creating custom roles.",
        "For general information about roles and privilege grants for performing SQL actions on\nsecurable objects, see Overview of Access Control.",
        "Tasks run using the task owner\u2019s privileges. For the list of minimum required privileges to run tasks, see\nTask security.",
        "Run the SQL statement or call the stored procedure, as the task owner role, before you include it in a task definition to ensure\nthe role has the required privileges on objects referenced by the SQL or stored procedure.",
        "For serverless tasks:",
        "Serverless compute resources for a task can range from the equivalent of XSMALL to XXLARGE in warehouse sizes. To request a\nsize increase, contact Snowflake Support.",
        "Individual tasks in a task graph can use serverless or user-managed compute resources. Using the serverless compute for\nall tasks in the task graph isn\u2019t required.",
        "If a task fails with an unexpected error, you can receive a notification about the error.\nFor more information on configuring task error notifications, see Enabling notifications for tasks.",
        "By default, a DML statement executed without explicitly starting a transaction is automatically committed on success or rolled back on\nfailure at the end of the statement. This behavior is called autocommit and is controlled with the AUTOCOMMIT parameter.\nThis parameter must be set to TRUE. If the AUTOCOMMIT parameter is set to FALSE at the account level, then set the parameter to\nTRUE for the individual task (using ALTER TASK \u2026 SET AUTOCOMMIT = TRUE); otherwise, any DML statement executed by the task fails.",
        "Only one task should consume data from a stream. Create multiple streams for the same table to be consumed by more than one task. When a\ntask consumes the data in a stream using a DML statement, the stream advances the offset and change data is no longer available for the\nnext task to consume.",
        "When you use the CREATE OR REPLACE syntax, Snowflake drops the existing task and recreates it using the specified definition.\nConsider the following behaviors when you replace a task:",
        "The recreated task is suspended by default.",
        "Any ongoing task run is completed. To stop a task run, use the\nSYSTEM$USER_TASK_CANCEL_ONGOING_EXECUTIONS function.",
        "If a standalone or root task is recreated, the next scheduled run of the task is cancelled.",
        "CREATE OR REPLACE <object> statements are atomic. That is, when an object is replaced, the old object is deleted and the new object is created in a single transaction.",
        "Tasks with large definitions can cause errors. If you experience an error due to task size, try using stored procedure or making your task definition less complex.",
        "Regarding metadata:",
        "Attention",
        "Customers should ensure that no personal data (other than for a User object), sensitive data, export-controlled data, or other regulated data is entered as metadata when using the Snowflake service. For more information, see Metadata fields in Snowflake.",
        "Preview Feature \u2014 Open",
        "Available to all accounts.",
        "All limitations of the ALTER TASK command apply.",
        "A task cannot be resumed or suspended using the CREATE OR ALTER TASK command. To resume or suspend a task, use the ALTER TASK command.",
        "Setting or unsetting a tag is not supported; however existing tags are not altered by a CREATE OR ALTER statement and remain unchanged.",
        "Create a serverless task that queries the current timestamp every hour starting at 9 AM and ending at 5 PM on Sundays\n(America/Los_Angeles time zone).",
        "The initial warehouse size is XSMALL:",
        "Same as the previous example, but the task relies on a user-managed warehouse to provide the compute resources for runs:",
        "Additional timing examples:",
        "SCHEDULE Value",
        "Description",
        "* * * * * UTC",
        "Every minute. UTC time zone.",
        "5 * * * * UTC",
        "Every 5 minutes. UTC time zone.",
        "0 2 * * * UTC",
        "Every night at 2 AM. UTC time zone.",
        "0 5,17 * * * UTC",
        "Twice daily, at 5 AM and 5 PM (at the top of the hour). UTC time zone.",
        "30 2 L 6 * UTC",
        "In June, on the last day of the month, at 2:30 AM. UTC time zone.",
        "Create a serverless task that inserts the current timestamp into a table every hour. The task sets the TIMESTAMP_INPUT_FORMAT\nparameter for the session in which the task runs. This session parameter specifies the format of the inserted timestamp:",
        "Create a task that inserts the current timestamp into a table every 5 minutes:",
        "Create a task that inserts change tracking data for INSERT operations from a stream into a table every 5 minutes. The task polls the\nstream using the SYSTEM$STREAM_HAS_DATA function to determine whether change data exists and, if the result is FALSE, skips the\ncurrent run:",
        "Create a serverless child task in a task graph and add multiple predecessor tasks. The child task runs only after all specified predecessor\ntasks have successfully completed their own runs.",
        "Suppose that the root task for a task graph is task1 and that task2, task3, and task4\nare child tasks of task1. This example adds child task task5 to the task graph and specifies\ntask2, task3, and task4 as predecessor tasks:",
        "Create a task named my_copy_task that calls a stored procedure to unload data from the mytable table to the named mystage\nstage (using COPY INTO <location>) every hour:",
        "Create a task that executes multiple SQL statements. In this example, the task modifies the TIMESTAMP_OUTPUT_FORMAT for the session and\nthen queries the CURRENT_TIMESTAMP function.",
        "Note",
        "The SQL code in the task definition includes multiple statements. To execute the CREATE TASK statement, you must temporarily set a\ncharacter other than a semicolon as the delimiter for SQL statements; otherwise, the CREATE TASK statement would return a user\nerror. The command to change the SQL delimiter in SnowSQL is !set sql_delimiter = '<character>'.",
        "Create a task that declares a variable, uses the variable, and returns the value of the variable every 2 minutes:",
        "Create a task that specifies configuration, and then reads that configuration.",
        "Create a finalizer task, associated with the root task of a task graph, that sends an email alert after task completion. For more\ninformation about finalizer tasks, see Release and cleanup of task graphs.",
        "Create a triggered task, associated with a stream, that inserts data from the specified stream into the table every time there is new data in the stream. For more information, see Triggered Tasks.",
        "Preview Feature \u2014 Open",
        "Available to all accounts.",
        "Create a task my_task to execute every hour in warehouse my_warehouse:",
        "Alter task my_task to execute after task my_other_task and update the task definition:",
        "Was this page helpful?",
        "On this page"
    ]
}