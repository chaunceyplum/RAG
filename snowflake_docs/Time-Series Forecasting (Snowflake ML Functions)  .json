{
    "url": "https://docs.snowflake.com/en/user-guide/ml-functions/forecasting",
    "title": "Time-Series Forecasting (Snowflake ML Functions) | Snowflake Documentation",
    "paragraphs": [
        "Forecasting employs a machine learning algorithm to predict future numeric data based on historical time series data.\nA common use case is to forecast sales by item for the next two weeks.",
        "This section gives the quickest way to get started with forecasting.",
        "To get started you must do the following:",
        "Select a database, schema and virtual warehouse.",
        "Confirm that you own your schema or have CREATE SNOWFLAKE.ML.FORECAST privileges in the schema you\u2019ve chosen.",
        "Have a table or view with at least two columns: one timestamp column and one numeric column. Be sure your timestamp column has\ntimestamps at a fixed interval and isn\u2019t missing too many timestamps. The following example shows a dataset with timestamp intervals\nof one day:",
        "Once you have the prerequisites, you can use the AI & ML Studio in Snowsight to guide you through setup or you can use the\nfollowing SQL commands to train a model and start creating forecasts:",
        "For more details on syntax and available methods, see the FORECAST (SNOWFLAKE.ML) reference.",
        "The forecasting function is built to predict any numeric time series data into the future. In addition to the simple case presented in the\nQuickstart to forecasting section, you can do the following:",
        "Predict for multiple series at once. For example, you can predict the sales of multiple items for the next two weeks.",
        "Train and predict using features. Features are additional factors that you believe influence the metric you want to forecast.",
        "Assess your model\u2019s accuracy.",
        "Understand the relative importance of the features the model was trained on.",
        "Debug training errors.",
        "The following sections provide examples of these scenarios and additional details on how forecasting works.",
        "This section provide examples of how to set up your data for forecasting and how to create a forecasting model based on your time-series\ndata.",
        "Note",
        "Ideally, the training data for a Forecasting model has time steps at equally spaced intervals (for example, daily).\nHowever, model training can handle real-world data that has missing, duplicate, or misaligned time steps. For more\ninformation, see Dealing with real-world data in Time-Series Forecasting.",
        "The example below creates two tables. Views of these tables are included in the examples later in this topic.",
        "The sales_data table contains sales data. Each sale includes a store ID, an item identifier, a timestamp, and\nthe sales amount. Additional columns, which are additional features (temperature, humidity, and holiday) are also included.",
        "The future_features table contains future values of the feature columns, which are necessary when forecasting\nusing features as part of your prediction process.",
        "This example uses a single time series (that is, all the rows are part of a single series) that has two columns, a\ntimestamp column and a target value column, without additional features.",
        "First, prepare the example dataset to train the model:",
        "The SELECT statement returns:",
        "Now, train a forecasting model using this view:",
        "The following message appears after the model is trained:",
        "Next, use the forecasting model to forecast the next three timestamps:",
        "Output",
        "Note that the model has inferred the interval between timestamps from the training data.",
        "In this example, because the forecast yields a perfectly linear prediction that has zero errors compared to the actual\nvalues, the prediction interval (LOWER_BOUND, UPPER_BOUND) is the same as the FORECAST value.",
        "To customize the size of the prediction interval, pass prediction_interval as part of a configuration object:",
        "To save your results directly to a table, use CREATE TABLE \u2026 AS SELECT \u2026 and\ncall the FORECAST method in the FROM clause:",
        "As shown in the example above, when calling the method, omit the CALL command. Instead, put the call\nin parentheses, preceded by the TABLE keyword.",
        "To create a forecasting model for multiple series at once, use the series_colname parameter.",
        "In this example, the data contains store_id and item columns. To forecast sales separately for every store/item\ncombination in the dataset, create a new column that combines these values, and specify that as the series\ncolumn.",
        "The following query creates a new view combining store_id and item into a new column named\nstore_item:",
        "Output",
        "The first five rows for each series for the resulting dataset are:",
        "Now use the forecasting function to train a model for each series, all in one step. Note that the series_colname parameter is set\nto store_item:",
        "Next, use that model to forecast the next two timestamps for all series:",
        "Output",
        "You can also forecast a specific series with:",
        "Output",
        "The result shows only the next two steps for store 2\u2019s sales of umbrellas.",
        "Tip",
        "Specifying one series with the FORECAST method is more efficient than filtering the results of a multi-series\nforecast to include only the series you\u2019re interested in, because only one series\u2019 forecast is generated.",
        "If you want additional features (for example, holidays or weather) to influence your forecasts, you must include these features\nin your training data. Here you create a view containing those fields from the sales_data table:",
        "Output",
        "This is the first five rows of the result of the SELECT query.",
        "Now you can use this view to train a model. You are only required to specify the timestamp and target column names;\nadditional columns in the input data are assumed to be features for use in training.",
        "To generate forecasts with this model, you must provide future values for the features to the model: in this case, TEMPERATURE,\nHUMIDITY and HOLIDAY. This allows the model to adjust its sales forecasts based on temperature, humidity, and holiday\nforecasts.",
        "Now create a view from the future_features table containing this data for future timestamps:",
        "Output",
        "Now you can generate a forecast using this data:",
        "In this variation of the FORECAST method, you do not specify the number of timestamps to predict. Instead, the timestamps\nof the forecast come from the v2_forecast view.",
        "You can use the following helper functions to assess your model performance, understand which features are most impactful to your model,\nand to help you debug the training process if any error occurred:",
        "model!SHOW_EVALUATION_METRICS();",
        "model!EXPLAIN_FEATURE_IMPORTANCE();",
        "model!SHOW_TRAINING_LOGS();",
        "To get the evaluation metrics for your model, call the <model_name>!SHOW_EVALUATION_METRICS method.\nBy default, the forecasting function evaluates all models it trains using a method called\ncross-validation. This means that under the hood,\nin addition to training the final model on all of the training data you provide, the function also trains models on subsets of your\ntraining data. Those models are then used to predict your target metric on the withheld data, allowing the function to compare those\npredictions to actual values in your historical data.",
        "If you don\u2019t need these evaluation metrics, you can set evaluate to FALSE. If you want to control the way cross-validation is run,\nyou can use the following parameters:",
        "n_splits: Represents the number of splits in your data for cross validation. Default is 1.",
        "max_train_size: Represents the maximum number of rows for a single training set.",
        "test_size: Limits number of rows included in each test set.",
        "gap: Represents the gap between the end of each training set and the start of the test set.",
        "For complete details on evaluation parameters, see Evaluation configuration.",
        "Note",
        "Small datasets may not have enough data to perform evaluation. The total number of training rows must be equal to or greater\nthan (n_splits * test_size) + gap. If not enough data is available to train an evaluation model, no evaluation metrics are available\neven when evaluate is set to TRUE.",
        "When n_splits is 1 (the default), the standard deviation for evaluation metric values is NULL, as only a validation dataset is used.",
        "Output",
        "To understand the relative importance of the features used in your model, use the <model_name>!EXPLAIN_FEATURE_IMPORTANCE\nmethod.",
        "When you train a forecasting model, your model uses provided data, such as timestamps, your target metric, additional columns\nyou provide (features), and features that are automatically generated to improve the performance of your forecasts, to learn patterns\nin your data. Training detects how important each of these is to making accurate predictions than others. Understanding the\nrelative importance of these features on a scale of 0 to 1 is the purpose of this helper function.",
        "Under the hood, this helper function counts the number of times the model used each feature to make a decision. These feature importance\nscores are then normalized to values between 0 and 1 so that their sum is 1. The resulting scores represent an approximate ranking of the\nfeatures in your trained model.",
        "Features that are close in score have similar importance.",
        "For extremely simple series (for example, when the target column has a constant value), all feature importance scores may be zero.",
        "Using multiple features that are very similar to each other may result in reduced importance scores for those features. For example,\nif two features are exactly identical, the model may treat them as interchangeable when making decisions, resulting in feature\nimportance scores that are half of what those scores would be if only one of the identical features were included.",
        "This example uses the data from the evaluation example and calls the feature\nimportance method. You can see that the exog_a variable that was created is the second most important feature - behind all rolling\naverages, which are aggregated under the aggregated_endogenous_trend_features feature name.",
        "Execute the following statements to get the importance of the features:",
        "Output",
        "When you train multiple series with CONFIG_OBJECT => 'ON_ERROR': 'SKIP', individual time series models can\nfail to train without the overall training process failing. To understand which time series failed and why, call the\n<model_name>!SHOW_TRAINING_LOGS method.",
        "Output",
        "To view a list of your models, use the SHOW SNOWFLAKE.ML.FORECAST command:",
        "To delete a model, use the DROP SNOWFLAKE.ML.FORECAST command:",
        "Models are immutable and cannot be updated in place. Train a new model instead.",
        "A Snowflake virtual warehouse provides the compute resources for training and using the\nmachine learning models for this feature. This section provides general guidance on selecting the best type and size of\nwarehouse for this purpose, focusing on the training step, the most time-consuming and memory-intensive part of\nthe process.",
        "There are two key factors to keep in mind when choosing a warehouse:",
        "The number of rows and columns your data contains.",
        "The number of distinct series your data contains.",
        "You can use the following rules of thumb to choose your warehouse:",
        "If you are training on a longer time series (> 5 million rows) or on many columns (many features), consider upgrading to\nSnowpark-optimized warehouses.",
        "If you are training on many series, size up. The forecasting function distributes model training across all available nodes in your\nwarehouse when you are training for multiple series at once.",
        "The following table provides this same guidance:",
        "Series type",
        "< 5 million rows",
        "> 5 million rows and \u2264 100 million rows",
        "> 100 million rows",
        "One series",
        "Standard warehouse; XS",
        "Snowpark optimized warehouse; XS",
        "Consider aggregating to a less frequent timestamp interval (e.g., hourly to daily)",
        "Multiple series",
        "Standard warehouse; Size up",
        "Snowpark optimized warehouse; Size up",
        "Consider batching training by series into multiple jobs",
        "As a rough estimate, training time is proportional to the number of rows in your time series. For example, on a XS standard warehouse,\nwith evaluation turned off (CONFIG_OBJECT => {'evaluate': False}), training on a 100,000-row dataset takes about\n400 seconds. Training on a 1,000,000-row dataset takes about 850 seconds. With\nevaluation turned on, training time increases roughly linearly by the number of splits used.",
        "The forecasting algorithm used is specified by the (CONFIG_OBJECT => {'method': '<method>'}) config object\nparameter. This parameter defaults to ('method': 'best'). When the method is set to 'best', the\nalgorithm used is an ensemble of multiple models, including Prophet,\nARIMA ,\nExponential Smoothing , and a\ngradient boosting machine (described further below).",
        "When the method is set to fast, the algorithm used is a gradient boosting machine (GBM). Like an ARIMA model,\nit uses a differencing transformation to model data with a non-stationary trend and uses auto-regressive lags of the\nhistorical target data as model variables. Additionally, the algorithm uses rolling averages of historical target data\nto help predict trends, and automatically produces cyclic calendar variables (such as day of week and week of year) from\ntimestamp data.",
        "You can fit models with only historical target and timestamp data, or you may include features (extra columns) that\nmight have influenced the target value. Exogenous variables can be numerical or categorical and may be NULL (rows\ncontaining NULLs for exogenous variables are not dropped).",
        "The algorithm does not rely on one-hot encoding when training on categorical variables, so you can use categorical data\nwith many dimensions (high cardinality).",
        "If your model incorporates features, when generating a forecast you must provide values for those features\nat every timestamp of the full forecast horizon. Appropriate features could include weather data\n(temperature, rainfall), company-specific information (historic and planned company holidays, advertisement campaigns,\nevent schedules), or any other external factors you believe may help predict your target variable.",
        "The algorithm also generates prediction intervals, in addition to forecasts. A prediction interval is an estimated range\nof values within an upper bound and a lower bound in which a certain percentage of data is likely to fall. For example,\na 0.95 value means that 95% of the data likely appears within the interval. You may specify a prediction interval\npercentage, or use the default, which is 0.95. Lower and upper bounds of the prediction interval are returned as part of\nthe forecast output.",
        "Important",
        "From time to time, Snowflake may refine the forecasting algorithm. Such improvements roll out through\nthe regular Snowflake release process. You cannot revert to a previous version of the feature, but models you\ncreated with a previous version continue to use that version for predictions until deprecation through the Behavior Change Release process.",
        "The current release has the following limitations:",
        "You cannot choose or adjust the forecasting algorithm.",
        "The minimum number of rows for the main forecasting algorithm is 12 per time series. For time series with between 2 and 11\nobservations, forecasting produces a \u201cnaive\u201d forecast where all forecasted values are equal to the last observed target\nvalue.",
        "The forecasting function does not provide parameters to override trend, seasonality, or seasonal amplitudes; these are\ninferred from the data.",
        "The minimum acceptable granularity of data is one second. (Timestamps must not be less than one second apart.)",
        "The minimum granularity of seasonal components is one minute. (The function cannot detect cyclic patterns at\nsmaller time deltas.)",
        "The \u201cseason length\u201d of autoregressive features is tied to the input frequency (24 for hourly data, 7 for daily data,\nand so on).",
        "Forecast models, once trained, are immutable. You cannot update existing models with new data; you must train an\nentirely new model.",
        "Models do not support versioning. Snowflake recommends retraining a model on a regular cadence,\nperhaps daily, weekly, or monthly, depending on how frequently you receive new data, allowing the model to adjust\nto changing patterns and trends.",
        "You cannot clone models or share models across roles or accounts.  When cloning a schema or database, model objects are skipped.",
        "You cannot replicate an instance of the FORECAST class.",
        "Training a forecasting model results in a schema-level object. Therefore, the role you use to create models must\nhave the CREATE SNOWFLAKE.ML.FORECAST privilege on the schema where the model is created, allowing the\nmodel to be stored there. This privilege is similar to other schema privileges like CREATE TABLE or CREATE VIEW.",
        "Snowflake recommends that you create a role named analyst to be used by people who need to create forecasts.",
        "In the following example, the admin role is the owner of the schema admin_db.admin_schema. The\nanalyst role needs to create models in this schema.",
        "To use this schema, a user assumes the role analyst:",
        "If the analyst role has CREATE SCHEMA privileges in database analyst_db, the role can create a new schema\nanalyst_db.analyst_schema and create forecast models in that schema:",
        "To revoke a role\u2019s forecast model creation privilege on the schema, use REVOKE <privileges>:",
        "For details on costs for using ML functions, see Cost Considerations in the ML functions overview.",
        "Important",
        "Legal notice. This Snowflake ML function is powered by machine learning technology. Machine\nlearning technology and results provided may be inaccurate, inappropriate, or biased. Decisions based on machine\nlearning outputs, including those built into automatic pipelines, should have human oversight and review processes\nto ensure model-generated content is accurate. Snowflake Cortex ML function queries will be treated as any\nother SQL query and may be considered metadata.",
        "Metadata. When you use Snowflake Cortex ML functions, Snowflake logs generic error messages returned by an ML\nfunction. These error logs help us troubleshoot issues that arise and improve these functions to serve you better.",
        "For further information, see Snowflake AI Trust and Safety FAQ.",
        "Was this page helpful?",
        "On this page",
        "Related content"
    ]
}