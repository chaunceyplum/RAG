{
    "url": "https://docs.snowflake.com/en/sql-reference/parameters#user-task-timeout-ms",
    "title": "Parameters | Snowflake Documentation",
    "paragraphs": [
        "Snowflake provides parameters that let you control the behavior of your account, individual user sessions, and objects. All the parameters have default values, which can be set and then overridden at\ndifferent levels depending on the parameter type (Account, Session, or Object).",
        "This section describes the different types of parameters (Account, Session, and Object) and the levels at which each type can be set.",
        "The following diagram illustrates the hierarchical relationship between the different parameter types and how individual parameters can be overridden at each level:",
        "Account parameters can be set only at the account level by users with the appropriate administrator role. Account parameters are set using the ALTER ACCOUNT command.",
        "Snowflake provides the following account parameters:",
        "Parameter",
        "Notes",
        "ALLOW_CLIENT_MFA_CACHING",
        "ALLOW_ID_TOKEN",
        "Used to enable connection caching in browser-based single sign-on (SSO) for Snowflake-provided clients",
        "CLIENT_ENCRYPTION_KEY_SIZE",
        "Used for encryption of files staged for data loading or unloading; might require additional installation and configuration (see description for details).",
        "CORTEX_ENABLED_CROSS_REGION",
        "Used to enable cross-region processing of Snowflake Cortex calls in a different region if the call cannot be processed in your account region.",
        "ENABLE_IDENTIFIER_FIRST_LOGIN",
        "ENABLE_INTERNAL_STAGES_PRIVATELINK",
        "Allows the SYSTEM$GET_PRIVATELINK_CONFIG function to return the private-internal-stages key in the query result.",
        "ENABLE_TRI_SECRET_AND_REKEY_OPT_OUT_FOR_IMAGE_REPOSITORY",
        "Used to specify an image Repository\u2019s choice to opt out of Tri-Secret Secure and Periodic rekeying.",
        "ENABLE_TRI_SECRET_AND_REKEY_OPT_OUT_FOR_SPCS_BLOCK_STORAGE",
        "Used to specify a block storage volume\u2019s choice to opt out of Tri-Secret Secure and Periodic rekeying.",
        "EVENT_TABLE",
        "Used to set an event table as the active event table for the account.",
        "ENFORCE_NETWORK_RULES_FOR_INTERNAL_STAGES",
        "EXTERNAL_OAUTH_ADD_PRIVILEGED_ROLES_TO_BLOCKED_LIST",
        "INITIAL_REPLICATION_SIZE_LIMIT_IN_TB",
        "MIN_DATA_RETENTION_TIME_IN_DAYS",
        "Used to set the minimum data retention period for retaining historical data for Time Travel operations.",
        "NETWORK_POLICY",
        "This is the only account parameter that can be set by either account administrators (i.e users with the ACCOUNTADMIN system role) or security administrators (i.e users with the SECURITYADMIN system role). . For more information, see Object parameters.",
        "OAUTH_ADD_PRIVILEGED_ROLES_TO_BLOCKED_LIST",
        "PERIODIC_DATA_REKEYING",
        "PREVENT_UNLOAD_TO_INLINE_URL",
        "REQUIRE_STORAGE_INTEGRATION_FOR_STAGE_CREATION",
        "REQUIRE_STORAGE_INTEGRATION_FOR_STAGE_OPERATION",
        "SSO_LOGIN_PAGE",
        "Note",
        "By default, account parameters are not displayed in the output of SHOW PARAMETERS. For more information\nabout viewing account parameters, see Viewing the Parameters and Their Values (in this topic).",
        "Most parameters are session parameters, which can be set at the following levels:",
        "Account administrators can use the ALTER ACCOUNT command to set session parameters for the account. The values set for the account default to individual users and\ntheir sessions.",
        "Administrators with the appropriate privileges (typically SECURITYADMIN role) can use the ALTER USER command to override session parameters for individual users. The values set for a user default to\nany sessions started by the user. In addition, users can override default sessions parameters for themselves using ALTER USER.",
        "Users can use the ALTER SESSION to explicitly set session parameters within their sessions.",
        "Note",
        "By default, only session parameters are displayed in the output of SHOW PARAMETERS. For more information about\nviewing account and object parameters, see Viewing the Parameters and Their Values (in this topic).",
        "Object parameters can be set at the following levels:",
        "Account administrators can use the ALTER ACCOUNT command to set object parameters for the account. The values set for the account default to the objects created in\nthe account.",
        "Users with the appropriate privileges can use the corresponding CREATE <object> or ALTER <object> commands to override object parameters for an individual\nobject.",
        "Snowflake provides the following object parameters:",
        "Parameter",
        "Object Type",
        "Notes",
        "AUTO_EVENT_LOGGING",
        "Snowflake Scripting stored procedure",
        "CATALOG",
        "Database, Schema, Apache Iceberg\u2122 table",
        "DATA_METRIC_SCHEDULE",
        "Table",
        "Specifies the schedule to run the data metric functions associated to the table. All data metric functions on the table or view\nfollow the same schedule.",
        "DATA_RETENTION_TIME_IN_DAYS",
        "Database, Schema, Table",
        "DEFAULT_DDL_COLLATION",
        "Database, Schema, Table",
        "ENABLE_PERSONAL_DATABASE",
        "User",
        "ENABLE_UNREDACTED_QUERY_SYNTAX_ERROR",
        "User",
        "Affects the query history for queries that fail due to syntax or parsing errors.",
        "EXTERNAL_VOLUME",
        "Database, Schema, Apache Iceberg\u2122 table",
        "LOG_LEVEL",
        "Database, Schema, Stored Procedure, Function",
        "MAX_CONCURRENCY_LEVEL",
        "Warehouse",
        "MAX_DATA_EXTENSION_TIME_IN_DAYS",
        "Database, Schema, Table",
        "NETWORK_POLICY",
        "User",
        "This is the only user parameter that can be set by either account administrators (users with the ACCOUNTADMIN system role) or\nsecurity administrators (users with the SECURITYADMIN system role).",
        "If this parameter is set on the account and a user in the same account, the user-level network policy overrides the account-level\nnetwork policy.",
        "PIPE_EXECUTION_PAUSED",
        "Schema, Pipe",
        "PREVENT_UNLOAD_TO_INTERNAL_STAGES",
        "User",
        "REPLACE_INVALID_CHARACTERS",
        "Database, Schema, file format, Apache Iceberg\u2122 table",
        "Can only be set for Iceberg tables that use an external Iceberg catalog.",
        "STATEMENT_QUEUED_TIMEOUT_IN_SECONDS",
        "Warehouse",
        "Also a session parameter (i.e. can be set at both the object and session levels). For inheritance and override details, see the parameter description.",
        "STATEMENT_TIMEOUT_IN_SECONDS",
        "Warehouse",
        "Also a session parameter (i.e. can be set at both the object and session levels). For inheritance and override details, see the parameter description.",
        "STORAGE_SERIALIZATION_POLICY",
        "Database, Schema, Apache Iceberg\u2122 table",
        "This parameter is only supported for Iceberg tables that use Snowflake as the catalog.",
        "SUSPEND_TASK_AFTER_NUM_FAILURES",
        "Database, Schema, Task",
        "TASK_AUTO_RETRY_ATTEMPTS",
        "Database, Schema, Task",
        "TRACE_LEVEL",
        "Database, Schema, Stored Procedure, Function",
        "USER_TASK_MANAGED_INITIAL_WAREHOUSE_SIZE",
        "Database, Schema, Task",
        "USER_TASK_MINIMUM_TRIGGER_INTERVAL_IN_SECONDS",
        "Database, Schema, Task",
        "USER_TASK_TIMEOUT_MS",
        "Database, Schema, Task",
        "Note",
        "By default, object parameters are not displayed in the output of SHOW PARAMETERS. For more information\nabout viewing object parameters, see Viewing the Parameters and Their Values (in this topic).",
        "Snowflake provides the SHOW PARAMETERS command, which displays a list of the parameters, along with the current and default values for each parameter. The command can be\ncalled with different options to determine the type of parameter displayed.",
        "By default, the command displays only session parameters:",
        "To display the object parameters for a specific object, include an IN clause with the object type and name. For example:",
        "To display all parameters, including account and object parameters, include an IN ACCOUNT clause:",
        "The command also supports using a LIKE clause to limit the list of parameters by name. For example:",
        "To display the session parameters whose names contain \u201ctime\u201d:",
        "To display all the parameters whose names start with \u201ctime\u201d:",
        "Note",
        "The LIKE clause must come before the IN clause.",
        "Session \u2014 Can be set for Account \u00bb User \u00bb Session",
        "Boolean",
        "Specifies the action that Snowflake performs for in-progress queries if connectivity is lost due to abrupt termination of a session (e.g. network outage, browser termination, service\ninterruption).",
        "TRUE: In-progress queries are aborted 5 minutes after connectivity is lost.",
        "FALSE: In-progress queries are completed.",
        "FALSE",
        "Note",
        "If the user explicitly closes the connection:",
        "All in-progress synchronous queries are aborted immediately regardless of the parameter value.",
        "When the value is set to FALSE, asynchronous queries continue to run until they complete,\nuntil they are canceled, or until the time limit specified for the STATEMENT_TIMEOUT_IN_SECONDS\nparameter expires. The default for the STATEMENT_TIMEOUT_IN_SECONDS parameter is two days.",
        "Most queries require compute resources to execute. These resources are provided by virtual warehouses, which consume credits while\nrunning. With a value of FALSE, if the session terminates, warehouses might continue running and consuming credits to\ncomplete any queries that were in progress at the time the session terminated.",
        "Preview Feature \u2014 Open",
        "The Python profiler is in preview and is available to all accounts.",
        "Session \u2014 Can be set only for Session",
        "String (Constant)",
        "Sets the profiler to use for the session when profiling Python handler code.",
        "'LINE': To have the profile focus on line use activity.",
        "'MEMORY': To have the profile focus on memory use activity.",
        "'LINE'",
        "Account \u2014 Can only be set for Account",
        "Boolean",
        "Specifies whether an MFA token can be saved in the client-side operating system keystore to promote continuous, secure connectivity without users needing to respond to an MFA prompt at the start of each connection attempt to Snowflake. For details and the list of supported Snowflake-provided clients, see Using MFA token caching to minimize the number of prompts during authentication \u2014 optional.",
        "TRUE: Stores an MFA token in the client-side operating system keystore to enable the client application to use the MFA token whenever a new connection is established. While true, users are not prompted to respond to additional MFA prompts.",
        "FALSE: Does not store an MFA token. Users must respond to an MFA prompt whenever the client application establishes a new connection with Snowflake.",
        "FALSE",
        "Account \u2014 Can be set only for Account",
        "Boolean",
        "Specifies whether a connection token can be saved in the client-side operating system keystore to promote continuous, secure connectivity without users needing to enter login credentials at the start of each connection attempt to Snowflake. For details and the list of supported Snowflake-provided clients, see Using connection caching to minimize the number of prompts for authentication \u2014 Optional.",
        "TRUE: Stores a connection token in the client-side operating system keystore to enable the client application to perform browser-based SSO without prompting users to authenticate whenever a new connection is established.",
        "FALSE: Does not store a connection token. Users are prompted to authenticate whenever the client application establishes a new connection with Snowflake. SSO to Snowflake is still possible if this parameter is set to false.",
        "FALSE",
        "Object (for Snowflake Scripting stored procedures)",
        "String (Constant)",
        "Controls whether Snowflake Scripting log messages and trace events are ingested automatically into the\nevent table. To set this parameter, run the\nALTER PROCEDURE command.",
        "LOGGING: Automatically adds the following additional logging information to the event table when a\nprocedure is executed:",
        "BEGIN/END of a Snowflake Scripting block.",
        "BEGIN/END of a child job request.",
        "This information is added to the event table only if the effective LOG_LEVEL is set\nto TRACE for the stored procedure.",
        "TRACING: Automatically adds the following additional trace information to the event table when a\nstored procedure is executed:",
        "Exception catching.",
        "Information about child job execution.",
        "Child job statistics.",
        "Stored procedure statistics, including execution time and input values.",
        "This information is added to the event table only if the effective TRACE_LEVEL is set\nto ALWAYS or ON_EVENT for the stored procedure.",
        "ALL: Automatically adds both the logging information added for the LOGGING value\nand the trace information added for the TRACING value.",
        "OFF: Does not automatically add logging information or trace information to the event table.",
        "OFF",
        "For more information about using this parameter, see Setting levels for logging, metrics, and tracing,\nAutomatically add log messages about blocks and child jobs,\nand Automatically emit trace events for child jobs and exceptions.",
        "Session \u2014 Can be set for Account \u00bb User \u00bb Session",
        "Boolean",
        "Specifies whether autocommit is enabled for the session. Autocommit determines whether a DML statement, when executed without an active transaction, is automatically committed after the\nstatement successfully completes. For more information, see Transactions.",
        "TRUE: Autocommit is enabled.",
        "FALSE: Autocommit is disabled, meaning DML statements must be explicitly committed or rolled back.",
        "TRUE",
        "N/A",
        "Boolean",
        "For Snowflake internal use only. View-only parameter that indicates whether API support for autocommit is enabled for your account. If the value is TRUE, you can enable or disable\nautocommit through the APIs for the following drivers/connectors:",
        "JDBC driver",
        "ODBC driver",
        "Snowflake Connector for Python",
        "Session \u2014 Can be set for Account \u00bb User \u00bb Session",
        "String (Constant)",
        "The format of VARCHAR values passed as input to VARCHAR-to-BINARY conversion functions. For more information, see\nBinary input and output.",
        "HEX , BASE64 , or UTF8 / UTF-8",
        "HEX",
        "Session \u2014 Can be set for Account \u00bb User \u00bb Session",
        "String (Constant)",
        "The format for VARCHAR values returned as output by BINARY-to-VARCHAR conversion functions. For more information, see\nBinary input and output.",
        "HEX or BASE64",
        "HEX",
        "Object (for databases, schemas, and Apache Iceberg\u2122 tables) \u2014 Can be set for Account \u00bb Database \u00bb Schema \u00bb Iceberg table",
        "String",
        "Specifies the catalog for Apache Iceberg\u2122 tables.\nFor more information, see the Iceberg table documentation.",
        "SNOWFLAKE or any valid catalog integration identifier.",
        "None",
        "Session \u2014 Can be set only for Session",
        "Boolean",
        "JDBC",
        "Enables users to log the data values bound to\nPreparedStatements.",
        "To see the values, you must not only set this session-level parameter to TRUE, but also set the\nconnection parameter named TRACING to either INFO or ALL.",
        "Set TRACING to ALL to see all debugging information and all binding information.",
        "Set TRACING to INFO to see the binding parameter values and less other debug information.",
        "Caution",
        "If you bind confidential information, such as medical diagnoses or passwords, that information is\nlogged. Snowflake recommends making sure that the log file is secure, or only using test data, when you set\nthis parameter to TRUE.",
        "TRUE or FALSE.",
        "FALSE",
        "Account \u2014 Can be set only for Account",
        "Integer",
        "Any",
        "Specifies the AES encryption key size, in bits, used by Snowflake to encrypt/decrypt files stored on internal stages (for loading/unloading data) when you use the SNOWFLAKE_FULL encryption type.",
        "128 or 256",
        "128",
        "Note",
        "This parameter is not used for encrypting/decrypting files stored in external stages (i.e. S3 buckets or Azure containers). Encryption/decryption of these files is accomplished using an external\nencryption key explicitly specified in the COPY command or in the named external stage referenced in the command.",
        "If you are using the JDBC driver and you wish to set this parameter to 256 (for strong encryption), additional JCE policy files must be installed on each client machine from which\ndata is loaded/unloaded. For more information about installing the required files, see Java requirements for the JDBC Driver.",
        "If you are using the Python connector (or SnowSQL) and you wish to set this parameter to 256 (for strong encryption), no additional installation or configuration tasks are required.",
        "Session \u2014 Can be set for Account \u00bb User \u00bb Session",
        "Integer",
        "JDBC, ODBC",
        "Parameter that specifies the maximum amount of memory the JDBC driver or ODBC driver should use for the result set from queries (in MB).",
        "For the JDBC driver:",
        "To simplify JVM memory management, the parameter sets a global maximum memory usage limit for all queries.",
        "CLIENT_RESULT_CHUNK_SIZE specifies the maximum size of each set (or chunk) of query results to download (in MB).\nThe driver might require additional memory to process a chunk; if so, it will adjust memory usage during runtime to process\nat least one thread/query. Verify that CLIENT_MEMORY_LIMIT is set significantly higher than CLIENT_RESULT_CHUNK_SIZE to\nensure sufficient memory is available.",
        "For the ODBC driver:",
        "This parameter is supported in version 2.22.0 and higher.",
        "CLIENT_RESULT_CHUNK_SIZE is not supported.",
        "Note",
        "The driver will attempt to honor the parameter value, but will cap usage at 80% of your system memory.",
        "The memory usage limit set in this parameter does not apply to any other JDBC or ODBC driver operations\n(e.g. connecting to the database, preparing a query, or PUT and GET statements).",
        "Any valid number of megabytes.",
        "1536 (effectively 1.5 GB)",
        "Most users should not need to set this parameter. If this parameter is not set by the user, the driver starts\nwith the default specified above.",
        "In addition, the JDBC driver actively manages its memory conservatively to avoid using up all available memory.",
        "Session \u2014 Can be set for User \u00bb Session",
        "Boolean",
        "JDBC, ODBC",
        "For specific ODBC functions and JDBC methods, this parameter can change the default search scope from all\ndatabases/schemas to the current database/schema. The narrower search typically returns fewer rows and executes\nmore quickly.",
        "For example, the getTables() JDBC method accepts a database name and schema name as arguments, and returns the\nnames of the tables in the database and schema. If the database and schema arguments are null, then by default, the\nmethod searches all databases and all schemas in the account. Setting CLIENT_METADATA_REQUEST_USE_CONNECTION_CTX to\nTRUE narrows the search to the current database and schema specified by the\nconnection context.",
        "In essence, setting this parameter to TRUE creates the following precedence for database and schema:",
        "Values passed as arguments to the functions/methods.",
        "Values specified in the connection context (if any).",
        "Default (all databases and all schemas).",
        "For more details, see the information below.",
        "This parameter applies to the following:",
        "JDBC driver methods (for the DatabaseMetaData class):",
        "getColumns",
        "getCrossReference",
        "getExportedKeys",
        "getForeignKeys",
        "getFunctions",
        "getImportedKeys",
        "getPrimaryKeys",
        "getSchemas",
        "getTables",
        "ODBC driver functions:",
        "SQLTables",
        "SQLColumns",
        "SQLPrimaryKeys",
        "SQLForeignKeys",
        "SQLGetFunctions",
        "SQLProcedures",
        "TRUE: If the database and schema arguments are null, then the driver retrieves metadata for only\nthe database and schema specified by the connection context.",
        "The interaction is described in more detail in the table below.",
        "FALSE: If the database and schema arguments are null, then the driver retrieves\nmetadata for all databases and schemas in the account.",
        "FALSE",
        "The connection context refers to the current database and schema for the session, which can be set using\nany of the following options:",
        "Specify the default namespace for the user who connects to Snowflake (and initiates the session). This can be\nset for the user through the CREATE USER or ALTER USER\ncommand, but must be set before the user connects.",
        "Specify the database and schema when connecting to Snowflake through the driver.",
        "Issue a USE DATABASE or USE SCHEMA command within the session.",
        "If the database or schema was specified by more than one of these, then the most recent one applies.",
        "When CLIENT_METADATA_REQUEST_USE_CONNECTION_CTX is set to TRUE:",
        "database argument",
        "schema argument",
        "Database used",
        "Schema used",
        "Non-null",
        "Non-null",
        "Argument",
        "Argument",
        "Non-null",
        "Null",
        "Argument",
        "All schemas",
        "Null",
        "Non-null",
        "Connection context",
        "Argument",
        "Null",
        "Null",
        "Connection context",
        "Session context",
        "Note",
        "For the JDBC driver, this behavior applies to version 3.6.27 (and higher).\nFor the ODBC driver, this behavior applies to version 2.12.96 (and higher).",
        "If you want to search only the connection context database, but want to search all schemas within that database,\nsee CLIENT_METADATA_USE_SESSION_DATABASE.",
        "Session \u2014 Can be set for Session",
        "Boolean",
        "JDBC",
        "This parameter applies to only the methods affected by CLIENT_METADATA_REQUEST_USE_CONNECTION_CTX.",
        "This parameter applies only when both of the following conditions are met:",
        "CLIENT_METADATA_REQUEST_USE_CONNECTION_CTX is FALSE or unset.",
        "No database or schema is passed to the relevant ODBC function or JDBC method.",
        "For specific ODBC functions and JDBC methods, this parameter can change the default search scope from all\ndatabases to the current database. The narrower search typically returns fewer rows and executes\nmore quickly.",
        "For more details, see the information below.",
        "TRUE:",
        "The driver searches all schemas in the connection context\u2019s database. (For more details about the\nconnection context, see the documentation for\nCLIENT_METADATA_REQUEST_USE_CONNECTION_CTX.)",
        "FALSE:",
        "The driver searches all schemas in all databases.",
        "FALSE",
        "",
        "When the database is null and the schema is null and CLIENT_METADATA_REQUEST_USE_CONNECTION_CTX is FALSE:",
        "CLIENT_METADATA_USE_SESSION_DATABASE",
        "Behavior",
        "FALSE",
        "All schemas in all databases are searched.",
        "TRUE",
        "All schemas in the current database are searched.",
        "Session \u2014 Can be set for Account \u00bb User \u00bb Session",
        "Integer",
        "JDBC, ODBC, Python, .NET",
        "Parameter that specifies the number of threads used by the client to pre-fetch large result sets. The driver will attempt to honor the parameter value, but defines the\nminimum and maximum values (depending on your system\u2019s resources) to improve performance.",
        "1 to 10",
        "4",
        "Most users should not need to set this parameter. If this parameter is not set by the user, the driver starts\nwith the default specified above, but also actively manages its thread count conservatively to avoid using up all\navailable memory.",
        "Session \u2014 Can be set for Account \u00bb User \u00bb Session",
        "Integer",
        "JDBC, Node.js, SQL API",
        "Parameter that specifies the maximum size of each set (or chunk) of query results to download (in MB). The JDBC driver downloads query results in chunks.",
        "Also see CLIENT_MEMORY_LIMIT.",
        "16 to 160",
        "160",
        "Most users should not need to set this parameter. If this parameter is not set by the user, the driver starts\nwith the default specified above, but also actively manages its memory conservatively to avoid using up all\navailable memory.",
        "Session \u2014 Can be set for Account \u00bb User \u00bb Session",
        "Boolean",
        "JDBC",
        "Parameter that indicates whether to match column name case-insensitively in ResultSet.get* methods in JDBC.",
        "TRUE: matches column names case-insensitively.",
        "FALSE: matches column names case-sensitively.",
        "FALSE",
        "Session \u2014 Can be set for Account \u00bb User \u00bb Session",
        "Boolean",
        "JDBC, ODBC, Python, Node.js",
        "Parameter that indicates whether to force a user to log in again after a period of inactivity in the session.",
        "TRUE: Snowflake keeps the session active indefinitely as long as the connection is active, even if there is no activity from the user.",
        "FALSE: The user must log in again after four hours of inactivity.",
        "FALSE",
        "Note",
        "Currently, the parameter only takes effect while initiating the session. You can modify the parameter value\nwithin the session level by executing an ALTER SESSION command, but it does not affect the session\nkeep-alive functionality, such as extending the session. For information about setting the parameter at\nthe session level, see the client documentation:",
        "JDBC",
        "ODBC",
        "Python",
        "Session \u2014 Can be set for Account \u00bb User \u00bb Session",
        "Integer",
        "SnowSQL, JDBC, Python, Node.js",
        "Number of seconds in-between client attempts to update the token for the session.",
        "900 to 3600",
        "3600",
        "Session \u2014 Can be set for Account \u00bb User \u00bb Session",
        "String (Constant)",
        "Any",
        "Specifies the TIMESTAMP_* variation to use when binding timestamp variables for JDBC or ODBC applications that use the bind API to load data.",
        "TIMESTAMP_LTZ or TIMESTAMP_NTZ",
        "TIMESTAMP_LTZ",
        "Account \u2014 Can be set only for Account",
        "String",
        "Specifies the regions where an inference request may be processed in case the request cannot be processed in the region\nwhere request is originally placed. Specifying DISABLED disables cross-region inferencing. For examples and details,\nsee Cross-region inference.",
        "This parameter can be set to one of the following:",
        "DISABLED",
        "ANY_REGION",
        "Comma-separated list including one or more of the following values:",
        "AWS_APJ",
        "AWS_EU",
        "AWS_US",
        "AZURE_US",
        "Value",
        "Behavior",
        "DISABLED",
        "Inference requests will only be handled in the region where the request is placed.",
        "ANY_REGION",
        "Inference requests may be routed to any region that supports cross-region inference (listed in this table) and that has availability,\nincluding the region where the request is placed.",
        "AWS_APJ",
        "Inference requests will be handled in either:",
        "The region where the request is placed.",
        "AWS ap-northeast-1",
        "AWS_EU",
        "Inference requests will be handled in either:",
        "The region where the request is placed.",
        "AWS eu-central-1",
        "AWS_US",
        "Inference requests will be handled in either:",
        "The region where the request is placed.",
        "Any of the following AWS cloud regions physically located within the United States:",
        "AWS us-west-2",
        "AWS us-east-1",
        "AZURE_US",
        "Inference requests will be handled in either:",
        "The region where the request is placed.",
        "Azure eastus2",
        "DISABLED",
        "Session \u2014 Can be set for Account \u00bb User \u00bb Session",
        "String",
        "Specifies the format for TIMESTAMP values in CSV files downloaded from Snowsight.",
        "If this parameter is not set, TIMESTAMP_LTZ_OUTPUT_FORMAT will be used for TIMESTAMP_LTZ values, TIMESTAMP_TZ_OUTPUT_FORMAT will be used for TIMESTAMP_TZ and TIMESTAMP_NTZ_OUTPUT_FORMAT for TIMESTAMP_NTZ values.",
        "For more information, see Date and time input and output formats or Download your query results.",
        "Any valid, supported timestamp format.",
        "No value.",
        "Enterprise Edition Feature",
        "Data Quality and data metric functions (DMFs) require Enterprise Edition. To inquire about upgrading, please contact\nSnowflake Support.",
        "Object (for tables)",
        "String",
        "Specifies the schedule to run the data metric functions associated to the table.",
        "The schedule can be based on a defined number of minutes, a cron expression, or a DML event on the table that does not involve\nreclustering. For details, see:",
        "Data metric function actions (dataMetricFunctionAction).",
        "Schedule your DMFs to run.",
        "No value.",
        "Object (for databases, schemas, and tables) \u2014 Can be set for Account \u00bb Database \u00bb Schema \u00bb Table",
        "Integer",
        "Number of days for which Snowflake retains historical data for performing Time Travel actions (SELECT, CLONE, UNDROP) on the object. A value of 0 effectively disables\nTime Travel for the specified database, schema, or table. For more information, see Understanding & using Time Travel.",
        "0 or 1 (for Standard Edition)",
        "0 to 90 (for Enterprise Edition or higher)",
        "1",
        "Session \u2014 Can be set for Account \u00bb User \u00bb Session",
        "String",
        "Specifies the input format for the DATE data type. For more information, see Date and time input and output formats.",
        "Any valid, supported date format or AUTO",
        "(AUTO specifies that Snowflake attempts to automatically detect the format of dates stored in the system during the session)",
        "AUTO",
        "Session \u2014 Can be set for Account \u00bb User \u00bb Session",
        "String",
        "Specifies the display format for the DATE data type. For more information, see Date and time input and output formats.",
        "Any valid, supported date format",
        "YYYY-MM-DD",
        "Object (for databases, schemas, and tables) \u2014 Can be set for Account \u00bb Database \u00bb Schema \u00bb Table",
        "String",
        "Sets the default collation used for the following DDL operations:",
        "CREATE TABLE",
        "ALTER TABLE \u2026 ADD COLUMN",
        "Setting this parameter forces all subsequently-created columns in the affected objects (table, schema, database, or account) to have\nthe specified collation as the default, unless the collation for the column is explicitly defined in the DDL.",
        "For example, if DEFAULT_DDL_COLLATION = 'en-ci', then the following two statements are equivalent:",
        "Any valid, supported collation specification.",
        "Empty string",
        "Note",
        "To set the default collation for the account, use the following command:",
        "ALTER ACCOUNT",
        "The default collation for table columns can be set at the table, schema, or database level during creation or any time afterwards:",
        "CREATE TABLE or ALTER TABLE",
        "CREATE SCHEMA or ALTER SCHEMA",
        "CREATE DATABASE or ALTER DATABASE",
        "Account \u2014 Can be set only for Account",
        "Boolean",
        "Determines the login flow for users. When enabled, Snowflake prompts users for their username or email address before presenting\nauthentication methods. For details, see Identifier-first login.",
        "TRUE: Snowflake uses an identifier-first login flow to authenticate users.",
        "FALSE: Snowflake presents all possible login options, even if those options don\u2019t apply to a particular user.",
        "FALSE",
        "Account \u2014 Can be set only for Account",
        "Boolean",
        "Specifies whether the SYSTEM$GET_PRIVATELINK_CONFIG function returns the private-internal-stages key in the query\nresult. The corresponding value in the query result is used during the configuration process for private connectivity to internal stages.",
        "TRUE: Returns the private-internal-stages key and value in the query result.",
        "FALSE: Does not return the private-internal-stages key and value in the query result.",
        "FALSE",
        "Preview Feature \u2014 Open",
        "Available to all accounts.",
        "User \u2014 Can be set for Account > User",
        "Boolean",
        "Controls whether users have access to personal databases.",
        "TRUE: Enables users to access their personal databases.",
        "FALSE: Prevents users from accessing their personal databases.",
        "FALSE",
        "Account \u2014 Can be set only for Account",
        "Boolean",
        "Specifies choice for the image repository to opt out of Tri-Secret Secure and Periodic rekeying.",
        "TRUE: Opts out Tri-Secret Secure and Periodic Rekeying for Image Repository.",
        "FALSE: Disallows the creation of an image repository for Tri-Secret Secure and periodic rekeying accounts. Similarly, disallows\nenabling Tri-Secret Secure and periodic rekeying for accounts that have enabled Image Repository.",
        "FALSE",
        "Account \u2014 Can be set only for Account",
        "Boolean",
        "Specifies the choice for the Snowpark Container Services block storage volume to opt out of Tri-Secret Secure and Periodic rekeying.",
        "TRUE: Opts out Tri-Secret Secure and periodic rekeying for Snowpark Container Services block storage volumes.",
        "FALSE: Disallows the creation of block storage volumes for Tri-Secret Secure and periodic rekeying accounts. Similarly,\ndisallows enabling Tri-Secret Secure and periodic rekeying for accounts that have enabled block storage volumes.",
        "FALSE",
        "Session \u2014 Can be set for Account \u00bb User \u00bb Session",
        "Boolean",
        "Specifies whether Snowflake may capture \u2013 in an event table \u2013 log messages or trace event data for unhandled exceptions\nin procedure or UDF handler code. For more information, see Capturing messages from unhandled exceptions.",
        "TRUE: Data about unhandled exceptions is captured as log or trace data if logging and tracing are enabled.",
        "FALSE: Data about unhandled exceptions is not captured.",
        "TRUE",
        "Session \u2014 Can be set for Account \u00bb User \u00bb Session",
        "Boolean",
        "Specifies whether to set the schema for unloaded Parquet files based on the logical column data types (i.e. the types in the unload SQL query or source table) or on the\nunloaded column values (i.e. the smallest data types and precision that support the values in the output columns of the unload SQL statement or source table).",
        "TRUE: The schema of unloaded Parquet data files is determined by the column values in the unload SQL query or source table. Snowflake optimizes table columns by setting the smallest precision that accepts all of the values. The unloader follows this pattern when writing values to Parquet files. The data type and precision of an output column are set to the smallest data type and precision that support its values in the unload SQL statement or source table. Accept this setting for better performance and smaller data files.",
        "FALSE: The schema is determined by the logical column data types. Set this value for a consistent output file schema.",
        "TRUE",
        "User \u2014 Can be set for Account \u00bb User",
        "Boolean",
        "Controls whether query text is redacted if a SQL query fails due to a syntax or parsing error. If FALSE, the content of a\nfailed query is redacted in the views, pages, and functions that provide a query history.",
        "Only users with a role that is granted or inherits the AUDIT privilege can set the ENABLE_UNREDACTED_QUERY_SYNTAX_ERROR parameter.",
        "When using the ALTER USER command to set the parameter to TRUE for a particular user, modify the user that you want to see the query\ntext, not the user who executed the query (if those are different users).",
        "TRUE: Disables the redaction of query text for queries that fail due to a syntax or parsing error.",
        "FALSE: Redacts the contents of a query from the views, pages, and functions that provide a query history when a query fails due to a\nsyntax or parsing error.",
        "FALSE",
        "Account \u2014 Can be set only for Account",
        "Boolean",
        "Specifies whether a network policy that uses network rules can restrict access to AWS internal stages.",
        "This parameter has no effect on network policies that do not use network rules.",
        "This account-level parameter affects both account-level and user-level network policies.",
        "For details about using network policies and network rules to restrict access to AWS internal stages, including the use of this parameter,\nsee Protecting internal stages on AWS.",
        "TRUE: Allows network polices that use network rules to restrict access to AWS internal stages. The network rule must\nalso use the appropriate MODE and TYPE to restrict access to the internal stage.",
        "FALSE: Network policies never restrict access to internal stages.",
        "FALSE",
        "Session \u2014 Can be set for Account \u00bb User \u00bb Session",
        "Boolean",
        "Specifies whether to return an error when the MERGE command is used to update or delete a target row that joins multiple source rows and the system cannot\ndetermine the action to perform on the target row.",
        "TRUE: An error is returned that includes values from one of the target rows that caused the error.",
        "FALSE: No error is returned and the merge completes successfully, but the results of the merge are nondeterministic.",
        "TRUE",
        "Session \u2014 Can be set for Account \u00bb User \u00bb Session",
        "Boolean",
        "Specifies whether to return an error when the UPDATE command is used to update a target row that joins multiple source rows and the system cannot determine the\naction to perform on the target row.",
        "TRUE: An error is returned that includes values from one of the target rows that caused the error.",
        "FALSE: No error is returned and the update completes, but the results of the update are nondeterministic.",
        "FALSE",
        "Account \u2014 Can be set only for Account",
        "String",
        "Specifies the name of the event table for logging messages from stored procedures and UDFs in this account.",
        "Any existing event table created by executing the CREATE EVENT TABLE command.",
        "None",
        "Account \u2014 Can be set only for Account",
        "Boolean",
        "Determines whether the ACCOUNTADMIN, ORGADMIN, and SECURITYADMIN roles can be used as the primary role when creating a\nSnowflake session based on the access token from the External OAuth authorization server.",
        "TRUE: Adds the ACCOUNTADMIN, ORGADMIN, and SECURITYADMIN roles to the EXTERNAL_OAUTH_BLOCKED_ROLES_LIST property of the\nExternal OAuth security integration, which means these roles cannot be used as the primary role when creating a Snowflake session using\nExternal OAuth authentication.",
        "FALSE: Removes the ACCOUNTADMIN, ORGADMIN, and SECURITYADMIN from the list of blocked roles defined by the\nEXTERNAL_OAUTH_BLOCKED_ROLES_LIST property of the External OAuth security integration.",
        "TRUE",
        "Object (for databases, schemas, and Apache Iceberg\u2122 tables) \u2014 Can be set for Account \u00bb Database \u00bb Schema \u00bb Iceberg table",
        "String",
        "Specifies the external volume for Apache Iceberg\u2122 tables. For more information,\nsee the Iceberg table documentation.",
        "Any valid external volume identifier.",
        "None",
        "Session \u2014 Can be set for Account \u00bb User \u00bb Session",
        "String (Constant)",
        "Display format for GEOGRAPHY values.",
        "For EWKT and EWKB, the SRID is always 4326 in the output.\nRefer to the note on EWKT and EWKB handling.",
        "GeoJSON, WKT, WKB, EWKT, or EWKB",
        "GeoJSON",
        "Session \u2014 Can be set for Account \u00bb User \u00bb Session",
        "String (Constant)",
        "Display format for GEOMETRY values.",
        "GeoJSON, WKT, WKB, EWKT, or EWKB",
        "GeoJSON",
        "Session \u2014 Can be set for Account \u00bb User \u00bb Session",
        "Integer",
        "Number of seconds to wait while trying to acquire row-level locks on a hybrid table, before timing out and aborting the statement.",
        "0 to any integer (no limit). A value of 0 disables lock waiting (that is, the statement must acquire the lock\nimmediately or abort). This value specifies how long the statement will wait for all of the row-level locks it needs to acquire after each\nexecution attempt (1 hour by default). If the statement cannot acquire all of the locks, it can be retried, and the same waiting period is applied.",
        "3600 (1 hour)",
        "See also LOCK_TIMEOUT.",
        "Account \u2014 Can be set only for Account",
        "Number.",
        "Sets the maximum estimated size limit for the initial replication of a primary database to a secondary database (in TB). Set this parameter on any account that stores a secondary database. This size limit helps prevent accounts from accidentally incurring large database replication charges.",
        "To remove the size limit, set the value to 0.0.",
        "Note that there is currently no default size limit applied to subsequent refreshes of a secondary database.",
        "0.0 and above with a scale of at least 1 (e.g. 20.5, 32.25, 33.333, etc.).",
        "10.0",
        "Session \u2014 Can be set for Account \u00bb User \u00bb Session",
        "Boolean",
        "Specifies whether to allow PUT and GET commands access to local file systems.",
        "TRUE: JDBC enables PUT and GET commands.",
        "FALSE: JDBC disables PUT and GET commands.",
        "TRUE",
        "Session \u2014 Can be set for Account \u00bb User \u00bb Session",
        "Boolean",
        "Specifies how JDBC processes columns that have a scale of zero (0).",
        "TRUE: JDBC processes a column whose scale is zero as BIGINT.",
        "FALSE: JDBC processes a column whose scale is zero as DECIMAL.",
        "TRUE",
        "Session \u2014 Can be set for Account \u00bb User \u00bb Session",
        "Boolean",
        "Specifies how JDBC processes TIMESTAMP_NTZ values.",
        "By default, when the JDBC driver fetches a value of type TIMESTAMP_NTZ from Snowflake, it converts the value to\n\u201cwallclock\u201d time using the client JVM timezone.",
        "Users who want to keep UTC timezone for the conversion can set this parameter to TRUE.",
        "This parameter applies only to the JDBC driver.",
        "TRUE: The driver uses UTC to get the TIMESTAMP_NTZ value in \u201cwallclock\u201d time.",
        "FALSE: The driver uses the client JVM\u2019s current timezone to get the TIMESTAMP_NTZ value in \u201cwallclock\u201d time.",
        "FALSE",
        "Session \u2014 Can be set for Account \u00bb User \u00bb Session",
        "Boolean",
        "Specifies whether the JDBC Driver uses the time zone of the JVM or the time zone of the session (specified by the\nTIMEZONE parameter) for the getDate(), getTime(), and getTimestamp() methods of the\nResultSet class.",
        "TRUE: The JDBC Driver uses the time zone of the session.",
        "FALSE: The JDBC Driver uses the time zone of the JVM.",
        "TRUE",
        "Session \u2014 Can be set for Account \u00bb User \u00bb Session",
        "Integer",
        "Specifies the number of blank spaces to indent each new element in JSON output in the session. Also specifies whether to insert newline characters after each element.",
        "0 to 16",
        "(a value of 0 returns compact output by removing all blank spaces and newline characters from the output)",
        "2",
        "Note",
        "This parameter does not affect JSON unloaded from a table into a file using the COPY INTO <location> command. The command always unloads JSON data in the NDJSON format:",
        "Each record from the table separated by a newline character.",
        "Within each record, compact formatting (i.e. no spaces or newline characters).",
        "Session \u2014 Can be set for Session",
        "Boolean",
        "Specifies how the Snowflake Node.js Driver processes numeric columns that have a scale of zero (0), for example INTEGER or NUMBER(p, 0).",
        "TRUE: JavaScript processes a column whose scale is zero as Bigint.",
        "FALSE: JavaScript processes a column whose scale is zero as Number.",
        "FALSE",
        "Note",
        "By default, Snowflake INTEGER columns (including BIGINT, NUMBER(p, 0), etc.) are converted to JavaScript\u2019s Number\ndata type. However, the largest legal Snowflake integer values are larger than the largest legal JavaScript\nNumber values. To convert Snowflake INTEGER columns to JavaScript Bigint, which can store larger values than\nJavaScript Number, set the session parameter JS_TREAT_INTEGER_AS_BIGINT.",
        "For examples of how to use this parameter, see Fetching integer data types as Bigint.",
        "Session \u2014 Can be set for Account \u00bb User \u00bb Session",
        "Integer",
        "Number of seconds to wait while trying to lock a resource, before timing out and aborting the statement.",
        "0 to any integer (no limit). A value of 0 disables lock waiting (the statement must acquire the lock\nimmediately or abort). If multiple resources need to be locked by the statement, the timeout applies separately\nto each lock attempt.",
        "43200 (12 hours)",
        "See also HYBRID_TABLE_LOCK_TIMEOUT.",
        "Session \u2014 Can be set for Account \u00bb User \u00bb Session",
        "Object (for databases, schemas, stored procedures, and UDFs) \u2014 Can be set for Account \u00bb Database \u00bb Schema \u00bb Procedure and Account \u00bb Database \u00bb Schema \u00bb Function",
        "String (Constant)",
        "Specifies the severity level of messages that should be ingested and made available in the active event table. Messages at\nthe specified level (and at more severe levels) are ingested. For more information about log levels, see\nSetting levels for logging, metrics, and tracing.",
        "TRACE",
        "DEBUG",
        "INFO",
        "WARN",
        "ERROR",
        "FATAL",
        "OFF",
        "OFF",
        "The following table lists the levels of messages ingested when you set the LOG_LEVEL parameter to a level.",
        "LOG_LEVEL Parameter Setting",
        "Levels of Messages Ingested",
        "TRACE",
        "TRACE",
        "DEBUG",
        "INFO",
        "WARN",
        "ERROR",
        "FATAL",
        "DEBUG",
        "DEBUG",
        "INFO",
        "WARN",
        "ERROR",
        "FATAL",
        "INFO",
        "INFO",
        "WARN",
        "ERROR",
        "FATAL",
        "WARN",
        "WARN",
        "ERROR",
        "FATAL",
        "ERROR",
        "ERROR",
        "FATAL",
        "FATAL",
        "ERROR (Only for Java UDFs, Java UDTFs, and Java and Scala stored procedures. For more information, see\nUnderstanding logging, metrics, and tracing levels)",
        "FATAL",
        "If this parameter is set in both the session and the object (or schema, database, or account), the more verbose value is used.\nSee Understanding how Snowflake determines level in effect.",
        "Object (for warehouses) \u2014 Can be set for Account \u00bb Warehouse",
        "Number",
        "Specifies the concurrency level for SQL statements (i.e. queries and DML) executed by a warehouse. When the level is reached, the operation performed depends on whether\nthe warehouse is a single-cluster or multi-cluster warehouse:",
        "Single-cluster or multi-cluster (in Maximized mode): Statements are queued until already-allocated resources are freed or additional resources are provisioned, which can be accomplished by\nincreasing the size of the warehouse.",
        "Multi-cluster (in Auto-scale mode): Additional clusters are started.",
        "MAX_CONCURRENCY_LEVEL can be used in conjunction with the STATEMENT_QUEUED_TIMEOUT_IN_SECONDS parameter to ensure a warehouse is never backlogged.",
        "In general, it limits the number of statements\nthat can be executed concurrently by a warehouse cluster, but there are exceptions. In the following cases, the actual number of\nstatements executed concurrently by a warehouse might be more or less than the specified level:",
        "Smaller, more basic statements: More statements might execute concurrently because small statements generally execute on a subset of the available compute resources in a warehouse. This means they\nonly count as a fraction towards the concurrency level.",
        "Larger, more complex statements: Fewer statements might execute concurrently.",
        "8",
        "Tip",
        "This value is a default only and can be changed at any time:",
        "Lowering the concurrency level for a warehouse can limit the number of concurrent queries running in a warehouse.\nWhen fewer queries are competing for the warehouse\u2019s resources at a given time, a query can potentially be given more resources, which\nmight result in faster query performance, particularly for a large/complex and multi-statement query.",
        "Raising the concurrency level for a warehouse might decrease the compute resources that are available for a statement; however, it does\nnot always limit the total number of concurrent queries that can be executed by the warehouse, nor does it necessarily impact total\nwarehouse performance, which depends on the nature of the queries being executed.",
        "Note that, as described earlier, this parameter impacts multi-cluster warehouses (in Auto-scale mode) because Snowflake automatically\nstarts a new cluster within the multi-cluster warehouse to avoid queuing. Thus, lowering the concurrency level for a multi-cluster\nwarehouse (in Auto-scale mode) potentially increases the number of active clusters at any time.",
        "Also, remember that Snowflake automatically allocates resources for each statement when it is submitted and the allocated amount is\ndictated by the individual requirements of the statement. Based on this, and through observations of user query patterns over time, we\u2019ve\nselected a default that balances performance and resource usage.",
        "As such, before changing the default, we recommend that you test the change by adjusting the parameter in small increments and\nobserving the impact against a representative set of your queries.",
        "Object (for databases, schemas, and tables) \u2014 Can be set for Account \u00bb Database \u00bb Schema \u00bb Table",
        "Integer",
        "Maximum number of days Snowflake can extend the data retention period for tables to prevent streams on the tables from becoming stale. By default, if the DATA_RETENTION_TIME_IN_DAYS setting for a source table is less than 14 days, and a stream has not been consumed, Snowflake temporarily extends this period to the stream\u2019s offset, up to a maximum of 14 days, regardless of the Snowflake Edition for your account. The MAX_DATA_EXTENSION_TIME_IN_DAYS parameter enables you to limit this automatic extension period to control storage costs for data retention or for compliance reasons.",
        "This parameter can be set at the account, database, schema, and table levels. Note that setting the parameter at the account or schema level only affects tables for which the parameter has not already been explicitly set at a lower level (e.g. at the table level by the table owner). A value of 0 effectively disables the automatic extension for the specified database, schema, or table. For more information about streams and staleness, see Introduction to Streams.",
        "0 to 90 (i.e. 90 days) \u2014 a value of 0 disables the automatic extension of the data retention period. To increase the maximum value for tables in your account, contact Snowflake Support.",
        "14",
        "Note",
        "This parameter can cause data to be retained longer than the default data retention.\nBefore increasing it, confirm that the new value fits your compliance requirements.",
        "Table retention is not extended for streams on shared tables. If you share a table,\nensure that you set the table retention time long enough for your data consumer to\nconsume the stream. If a provider shares a table with, for example, 7 days\u2019\nretention and keeps the 14-day default extension, the stream will be stale after 14\ndays in the provider account and after 7 days in the consumer account.",
        "Preview Feature \u2014 Open",
        "Metrics data collection is a preview feature available to all accounts.",
        "Session \u2014 Can be set for Account \u00bb User \u00bb Session",
        "Object (for databases, schemas, stored procedures, and UDFs) \u2014 Can be set for Account \u00bb Database \u00bb Schema \u00bb Procedure and Account \u00bb Database \u00bb Schema \u00bb Function",
        "String (Constant)",
        "Controls how metrics data is ingested into the event table. For more information about metric levels, see\nSetting levels for logging, metrics, and tracing.",
        "ALL: All metrics data will be recorded in the event table.",
        "NONE: No metrics data will be recorded in the event table.",
        "NONE",
        "Session \u2014 Can be set for Account \u00bb User \u00bb Session",
        "Integer (Constant)",
        "SQL API, JDBC, .NET, ODBC",
        "Number of statements to execute when using the multi-statement capability.",
        "0: Variable number of statements.",
        "1: One statement.",
        "More than 1: When MULTI_STATEMENT_COUNT is set as a session parameter, you can specify the exact number of statements to\nexecute.",
        "Negative numbers are not permitted.",
        "1",
        "Account \u2014 Can be set only for Account",
        "Integer",
        "Minimum number of days for which Snowflake retains historical data for performing Time Travel actions (SELECT, CLONE, UNDROP)\non an object. If a minimum number of days for data retention is set on an account, the data retention period for an object is determined by\nMAX(DATA_RETENTION_TIME_IN_DAYS, MIN_DATA_RETENTION_TIME_IN_DAYS).",
        "For more information, see Understanding & using Time Travel.",
        "0 or 1 (for Standard Edition)",
        "0 to 90 (for Enterprise Edition or higher)",
        "0",
        "Note",
        "This parameter only applies to permanent tables and does not apply to the following objects:",
        "Transient tables",
        "Temporary tables",
        "External tables",
        "Materialized views",
        "Streams",
        "This parameter can only be set and unset by account administrators (i.e. users with the ACCOUNTADMIN role or other role that is granted\nthe ACCOUNTADMIN role).",
        "Setting the minimum data retention time does not alter any existing DATA_RETENTION_TIME_IN_DAYS parameter value set on databases,\nschemas, or tables. The effective retention time of a database, schema, or table is MAX(DATA_RETENTION_TIME_IN_DAYS,\nMIN_DATA_RETENTION_TIME_IN_DAYS).",
        "Account \u2014 Can be set only for Account (can be set by account administrators and security administrators)",
        "Object (for users) \u2014 Can be set for Account \u00bb User",
        "String",
        "Specifies the network policy to enforce for your account. Network policies enable restricting access to your account based on\nusers\u2019 IP address. For more details, see Controlling network traffic with network policies.",
        "Any existing network policy (created using CREATE NETWORK POLICY)",
        "None",
        "Note",
        "This is the only account parameter that can be set by security administrators (i.e users with the SECURITYADMIN system role) or higher.",
        "Session \u2014 Can be set for Account \u00bb User \u00bb Session",
        "Boolean",
        "Specifies whether the ORDER or NOORDER property is set by default when you create a new sequence or add a new table\ncolumn.",
        "The ORDER and NOORDER properties determine whether or not the values are generated for the sequence or auto-incremented column\nin increasing or decreasing order.",
        "TRUE: When you create a new sequence or add a new table column, the NOORDER property is set by default.",
        "NOORDER specifies that the values are not guaranteed to be in increasing order.",
        "For example, if a sequence has START 1 INCREMENT 2, the generated values might be 1, 3, 101, 5, 103, etc.",
        "NOORDER can improve performance when multiple INSERT operations are performed concurrently (for example, when multiple\nclients are executing multiple INSERT statements).",
        "FALSE: When you create a new sequence or add a new table column, the ORDER property is set by default.",
        "ORDER specifies that the values generated for a sequence or auto-incremented column are in increasing order (or, if the interval\nis a negative value, in decreasing order).",
        "For example, if a sequence or auto-incremented column has START 1 INCREMENT 2, the generated values might be\n1, 3, 5, 7, 9, etc.",
        "If you set this parameter, the value that you set overrides the value in the 2024_01 behavior change bundle.",
        "TRUE",
        "Session \u2014 Can be set for Account \u00bb User \u00bb Session",
        "Boolean",
        "Specifies how ODBC processes columns that have a scale of zero (0).",
        "TRUE: ODBC processes a column whose scale is zero as BIGINT.",
        "FALSE: ODBC processes a column whose scale is zero as DECIMAL.",
        "FALSE",
        "Account \u2014 Can be set only for Account",
        "Boolean",
        "Determines whether the ACCOUNTADMIN, ORGADMIN, and SECURITYADMIN roles can be used as the primary role when creating a\nSnowflake session based on the access token from Snowflake\u2019s authorization server.",
        "TRUE: Adds the ACCOUNTADMIN, ORGADMIN, and SECURITYADMIN roles to the BLOCKED_ROLES_LIST property of the Snowflake OAuth\nsecurity integration, which means these roles cannot be used as the primary role when creating a Snowflake session using Snowflake\nOAuth.",
        "FALSE: Removes the ACCOUNTADMIN, ORGADMIN, and SECURITYADMIN from the list of blocked roles defined by the\nBLOCKED_ROLES_LIST property of the Snowflake OAuth security integration.",
        "TRUE",
        "Account \u2014 Can be set only for Account",
        "Boolean",
        "This parameter only applies to Enterprise Edition (or higher). It enables/disables re-encryption of table data with new keys on a yearly basis to provide\nadditional levels of data protection.",
        "You can enable and disable rekeying at any time. Enabling/disabling rekeying does not result in gaps in your encrypted data:",
        "If rekeying is enabled for a period of time and then disabled, all data already tagged for rekeying is rekeyed, but no further data is rekeyed until you re-enable it again.",
        "If rekeying is re-enabled, Snowflake automatically rekeys all data that has keys which meet the criteria (i.e. key is older than one year).",
        "For more information about rekeying of encrypted data, see Understanding Encryption Key Management in Snowflake.",
        "TRUE: Data is rekeyed after one year has passed since the data was last encrypted. Rekeying occurs in the background so no down-time is experienced and the affected data/table is always\navailable.",
        "FALSE: Data is not rekeyed.",
        "FALSE",
        "Note",
        "There are charges associated with data rekeying because, after data is rekeyed, the old data (with the previous key encryption) is maintained in Fail-safe for the standard time period (7 days). For\nthis reason, periodic rekeying is disabled by default. To enable periodic rekeying, you must explicitly enable it.",
        "Also, Fail-safe charges for rekeying are not listed individually in your monthly statement; they are included in the Fail-safe total for your account each month.",
        "For more information about Fail-safe, see Understanding and viewing Fail-safe.",
        "Object \u2014 Can be set for Account \u00bb Schema \u00bb Pipe",
        "Boolean",
        "Specifies whether to pause a running pipe, primarily in preparation for transferring ownership of the pipe to a different role:",
        "An account administrator (user with the ACCOUNTADMIN role) can set this parameter at the account level, effectively pausing or resuming all pipes in the account.",
        "A user with the MODIFY privilege on a schema can pause or resume all pipes in the schema.",
        "The pipe owner can set this parameter for a pipe.",
        "Note that setting the parameter at the account or schema level only affects pipes for which the parameter has not already been explicitly set at a lower level\n(e.g. at the pipe level by the pipe owner).",
        "This enables the practical use case in which an account administrator can pause all pipes at the account level, while a pipe owner can still have an individual pipe\nrunning.",
        "TRUE: Pauses the pipe. When the parameter is set to this value, the SYSTEM$PIPE_STATUS function shows the executionState\nas PAUSED. Note that the pipe owner can continue to submit files to a paused pipe; however, the files are not processed until the pipe is resumed.",
        "FALSE: Resumes the pipe, but only if ownership of the pipe has not been transferred while it was paused. When the parameter is set to this value, the\nSYSTEM$PIPE_STATUS function shows the executionState as RUNNING.",
        "If ownership of the pipe was transferred to another role after the pipe was paused, this parameter cannot be used to resume the pipe. Instead, use the\nSYSTEM$PIPE_FORCE_RESUME function to explicitly force the pipe to resume.",
        "This enables the new owner to use SYSTEM$PIPE_STATUS to evaluate the pipe status (e.g. determine how many files are waiting to be loaded)\nbefore resuming the pipe.",
        "FALSE (pipes are running by default)",
        "Note",
        "In general, pipes do not need to paused, except for transferring ownership.",
        "Account \u2014 Can be set only for Account",
        "Boolean",
        "Specifies whether to prevent ad hoc data unload operations to external cloud storage locations (i.e. COPY INTO <location> statements that specify the cloud storage URL and access settings directly in the statement). For an example, see Unloading data from a table directly to files in an external location.",
        "TRUE: COPY INTO <location> statements must reference either a named internal (Snowflake) or external stage or an internal user or table stage. A named external stage must store the cloud storage URL and access settings in its definition.",
        "FALSE: Ad hoc data unload operations to external cloud storage locations are permitted.",
        "FALSE",
        "User \u2014 Can be set for Account \u00bb User",
        "Boolean",
        "Specifies whether to prevent data unload operations to internal (Snowflake) stages using COPY INTO <location> statements.",
        "TRUE: Unloading data from Snowflake tables to any internal stage, including user stages, table stages, or named internal stages is prevented.",
        "FALSE: Unloading data to internal stages is permitted, limited only by the default restrictions of the stage type:",
        "The current user can only unload data to their own user stage.",
        "Users can only unload data to table stages when their active role has the OWNERSHIP privilege on the table.",
        "Users can only unload data to named internal stages when their active role has the WRITE privilege on the stage.",
        "FALSE",
        "Preview Feature \u2014 Open",
        "The Python profiler is in preview and is available to all accounts.",
        "Session \u2014 Can be set only for Session",
        "String",
        "Specifies the fully-qualified name of the stage in which to save a report when\nprofiling Python handler code.",
        "Fully-qualified name of the stage in which to save the report.",
        "Use a temporary stage to store output only for the duration of the session.",
        "Use a permanent stage to preserve the profiler output outside of the scope of a session.",
        "For more information, see Specify the Snowflake stage where profile output should be written.",
        "''",
        "Preview Feature \u2014 Open",
        "The Python profiler is in preview and is available to all accounts.",
        "Session \u2014 Can be set only for Session",
        "String",
        "Specifies the list of Python modules to include in a report when profiling Python handler code.",
        "Use this parameter to specify modules that are contained in staged handlers or that contain dependencies that you want to include\nin the profile.",
        "A comma-separated list of Python module names.",
        "For examples, see Including modules with the PYTHON_PROFILER_MODULES parameter and Profiling staged handler code.",
        "''",
        "Session \u2014 Can be set for Account \u00bb User \u00bb Session",
        "String (up to 2000 characters)",
        "Optional string that can be used to tag queries and other SQL statements executed within a session. The tags are displayed in the output of the QUERY_HISTORY , QUERY_HISTORY_BY_*\nfunctions.",
        "None",
        "Session \u2014 Can be set for Account \u00bb User \u00bb Session",
        "Object \u2014 Can be set for Account \u00bb Database \u00bb Schema \u00bb Table",
        "Boolean",
        "Specifies whether letters in double-quoted object identifiers are stored and resolved as uppercase letters. By default,\nSnowflake preserves the case of alphabetic characters when storing and resolving double-quoted identifiers. (see\nIdentifier resolution.) You can use this parameter in situations in which\nthird-party applications always use double quotes around identifiers.",
        "Note",
        "Changing this parameter from the default value can affect your ability to find objects that were previously created with\ndouble-quoted mixed case identifiers. Refer to Impact of changing the parameter.",
        "When set on a table, schema, or database, the setting only affects the evaluation of table names in the bodies of views and\nuser-defined functions (UDFs). If your account uses double-quoted identifiers that should be treated as case-insensitive\nand you plan to share a view or UDF with an account that treats double-quoted identifiers as case-sensitive, you can set\nthis on the view or UDF that you plan to share. This allows the other account to resolve the table names in the view or UDF\ncorrectly.",
        "TRUE: Letters in double-quoted identifiers are stored and resolved as uppercase letters.",
        "FALSE: The case of letters in double-quoted identifiers is preserved. Snowflake resolves and stores the identifiers in the specified case.",
        "For more information, see Identifier resolution.",
        "FALSE",
        "For example:",
        "Identifier",
        "Param set to FALSE (default)",
        "Param set to TRUE",
        "\"columnname\"",
        "resolves to:",
        "columnname",
        "COLUMNNAME",
        "\"columnName\"",
        "resolves to:",
        "columnName",
        "COLUMNNAME",
        "\"ColumnName\"",
        "resolves to:",
        "ColumnName",
        "COLUMNNAME",
        "\"COLUMNNAME\"",
        "resolves to:",
        "COLUMNNAME",
        "COLUMNNAME",
        "Object \u2014 Can be set for Account \u00bb Database \u00bb Schema \u00bb Iceberg table",
        "Boolean",
        "Specifies whether to replace invalid UTF-8 characters with the Unicode replacement character (\ufffd) in query results\nfor Apache Iceberg\u2122 tables that use an external catalog.",
        "TRUE: Snowflake replaces invalid UTF-8 characters with the Unicode replacement character.",
        "FALSE: Snowflake leaves invalid UTF-8 characters unchanged. Snowflake returns a user error message if it encounters an invalid UTF-8\ncharacter.",
        "FALSE",
        "Account \u2014 Can be set only for Account",
        "Boolean",
        "Specifies whether to require a storage integration object as cloud credentials when creating a named external stage (using CREATE STAGE) to access a private cloud storage location.",
        "TRUE: Creating an external stage to access a private cloud storage location requires referencing a storage integration object as cloud credentials.",
        "FALSE: Creating an external stage does not require referencing a storage integration object. Users can instead reference explicit cloud provider credentials, such as secret keys or access tokens, if they have been configured for the storage location.",
        "FALSE",
        "Account \u2014 Can be set only for Account",
        "Boolean",
        "Specifies whether to require using a named external stage that references a storage integration object as cloud credentials when loading data from or unloading data to a private cloud storage location.",
        "TRUE: Loading data from or unloading data to a private cloud storage location requires using a named external stage that references a storage integration object; specifying a named external stage that references explicit cloud provider credentials, such as secret keys or access tokens, produces a user error.",
        "FALSE: Users can load data from or unload data to a private cloud storage location using a named external stage that references explicit cloud provider credentials.",
        "If PREVENT_UNLOAD_TO_INLINE_URL is FALSE, then users can specify the explicit cloud provider credentials directly in the COPY statement.",
        "FALSE",
        "Session \u2014 Can be set for Account \u00bb User \u00bb Session",
        "Number",
        "SQL API",
        "Specifies the maximum number of rows returned in a result set.",
        "0 to any number (i.e. no limit) \u2014 a value of 0 specifies no maximum.",
        "0",
        "Session \u2014 Can be set for Account \u00bb User \u00bb Session",
        "String",
        "Specifies the DNS name of an Amazon S3 interface endpoint. Requests sent to the internal stage of an account via\nAWS PrivateLink for Amazon S3 use this\nendpoint to connect.",
        "For more information, see Accessing Internal stages with dedicated interface endpoints.",
        "Valid region-scoped DNS Name of an S3 interface endpoint.",
        "The standard format begins with an asterisk (*) and ends with vpce.amazonaws.com\n(e.g. *.vpce-sd98fs0d9f8g.s3.us-west-2.vpce.amazonaws.com). For more details about obtaining this value, refer to\nAWS configuration.",
        "Alternative formats include bucket.vpce-xxxxxxxx.s3.<region>.vpce.amazonaws.com and vpce-xxxxxxxx.s3.<region>.vpce.amazonaws.com.",
        "Empty string",
        "Deprecated Feature",
        "This parameter is deprecated. For more information, see\nMigrating to a SAML2 security integration.",
        "Account \u2014 Can be set only for Account",
        "JSON",
        "Enables federated authentication. This deprecated parameter enables federated authentication. This parameter accepts a JSON\nobject, enclosed in single quotes, with the following fields:",
        "Where:",
        "Specifies the certificate (generated by the IdP) that verifies communication between the IdP and Snowflake.",
        "Indicates the Issuer/EntityID of the IdP.",
        "Optional.",
        "For information on how to obtain this value in Okta and AD FS, see Migrating to a SAML2 security integration.",
        "Specifies the URL endpoint (provided by the IdP) where Snowflake sends the SAML requests.",
        "Specifies the type of IdP used for federated authentication (\"OKTA\" , \"ADFS\" , \"Custom\").",
        "Specifies the button text for the IdP in the Snowflake login page. The default label is Single Sign On. If you change the default label, the label you specify can only contain alphanumeric\ncharacters (i.e. special characters and blank spaces are not currently supported).",
        "Note that, if the \"type\" field is \"Okta\", a value for the label field does not need to be specified because Snowflake displays the Okta logo in the button.",
        "For more information, including examples of setting the parameter, see Migrating to a SAML2 security integration.",
        "None",
        "Session \u2014 Can be set for Account \u00bb User \u00bb Session",
        "String",
        "Specifies the path to search to resolve unqualified object names in queries. For more information, see\nName resolution in queries.",
        "Comma-separated list of identifiers. An identifier can be a fully or partially qualified schema name.",
        "$current, $public",
        "For more information about the default settings, see default search path.",
        "Note",
        "You cannot set this parameter within a client connection string, such as a JDBC or ODBC connection string. You must\nestablish a session before setting a search path.",
        "Session \u2014 Can be set for Account \u00bb User \u00bb Session",
        "String",
        "Specifies the name of a consumer account to simulate for testing/validating shared data, particularly shared secure views. When this parameter is set in a session, shared views return rows as if executed in the specified consumer account rather than the provider account.",
        "Note",
        "Simulations only succeed when the current role is the owner of the view.\nIf the current role does not own the view, simulations fail with the error:",
        "For more information, see About Secure Data Sharing and Create and configure shares.",
        "None",
        "Important",
        "This is a session parameter, which means it can be set at the account level; however, it only applies to testing queries on shared views. Because the parameter affects all queries in a session, it should\nnever be set at the account level.",
        "Deprecated Feature",
        "This parameter is deprecated. For more information, see\nMigrating to a SAML2 security integration.",
        "Account \u2014 Can be set only for Account",
        "Boolean",
        "This deprecated parameter disables preview mode for testing SSO (after enabling federated authentication) before rolling it out to users:",
        "TRUE: Preview mode is disabled and users will see the button for Snowflake-initiated SSO for your identity provider (as specified in SAML_IDENTITY_PROVIDER) in the Snowflake main login page.",
        "FALSE: Preview mode is enabled and SSO can be tested using the following URL:",
        "If your account is in US West: https://<account_identifier>.snowflakecomputing.com/console/login?fedpreview=true",
        "If your account is in any other region:\nhttps://<account_identifier>.<region_id>.snowflakecomputing.com/console/login?fedpreview=true",
        "For more information, see:",
        "Migrating to a SAML2 security integration",
        "Account identifiers",
        "FALSE",
        "Session and Object (for warehouses)",
        "Can be set for Account \u00bb User \u00bb Session; can also be set for individual warehouses",
        "Number",
        "Amount of time, in seconds, a SQL statement (query, DDL, DML, etc.) remains queued for a warehouse before it is canceled by the system. This parameter can be used in conjunction with the\nMAX_CONCURRENCY_LEVEL parameter to ensure a warehouse is never backlogged.",
        "The parameter can be set within the session hierarchy. It can also be set for a warehouse to control the queue timeout for all SQL statements processed by the warehouse. When the parameter is set for\nboth a warehouse and a session, the lowest non-zero value is enforced. For example:",
        "A warehouse has a queued timeout of 120 seconds.",
        "The queued timeout for the session is set to 60 seconds.",
        "The session timeout takes precedence (i.e. any statement submitted in the session is canceled after being queued for longer than 60 seconds).",
        "Note",
        "For runs of tasks, the USER_TASK_TIMEOUT_MS task parameter takes precedence over the\nSTATEMENT_QUEUED_TIMEOUT_IN_SECONDS setting.",
        "When comparing the values of these two parameters, note that\nSTATEMENT_QUEUED_TIMEOUT_IN_SECONDS is set in units of seconds, while USER_TASK_TIMEOUT_MS\nuses units of milliseconds.",
        "For more information about USER_TASK_TIMEOUT_MS, see the\nOptional Parameters section of\nCREATE TASK.",
        "0 to any number (i.e. no limit) \u2014 a value of 0 specifies that no timeout is enforced. A statement will remained queued as long as the queue persists.",
        "0 (i.e. no timeout)",
        "Session and Object (for warehouses)",
        "Can be set for Account \u00bb User \u00bb Session; can also be set for individual warehouses",
        "Number",
        "Amount of time, in seconds, after which a running SQL statement (query, DDL, DML, etc.) is canceled by the system.",
        "The parameter can be set within the session hierarchy. It can also be set for an individual warehouse to control the runtime for all SQL statements processed by the warehouse. When the parameter is\nset for both a warehouse and a session, the lowest non-zero value is enforced. For example:",
        "A warehouse has a timeout of 1000 seconds.",
        "The timeout for the session is set to 500 seconds.",
        "The session timeout takes precedence (i.e. any statement submitted in the session is canceled after running for longer than 500 seconds).",
        "Note",
        "For runs of tasks:",
        "If a task relies on a virtual warehouse for its compute resources and\nSTATEMENT_TIMEOUT_IN_SECONDS is set at the warehouse level, then the effective\ntimeout is the smaller of the following parameters:",
        "STATEMENT_TIMEOUT_IN_SECONDS",
        "USER_TASK_TIMEOUT_MS (parameter set on the task)",
        "Otherwise, the USER_TASK_TIMEOUT_MS task parameter takes precedence over the\nSTATEMENT_TIMEOUT_IN_SECONDS setting for task runs.",
        "When comparing the values of these two parameters, note that STATEMENT_TIMEOUT_IN_SECONDS\nis set in units of seconds, while USER_TASK_TIMEOUT_MS uses units of milliseconds.",
        "For more information about USER_TASK_TIMEOUT_MS, see the\nOptional Parameters section of\nCREATE TASK.",
        "0 to 604800 (i.e. 7 days) \u2014 a value of 0 specifies that the maximum timeout value is enforced.",
        "172800 (i.e. 2 days)",
        "Object (for databases, schemas, and Apache Iceberg\u2122 tables) \u2014 Can be set for Account \u00bb Database \u00bb Schema \u00bb Iceberg table",
        "String (Constant)",
        "Specifies the storage serialization policy for Snowflake-managed Apache Iceberg\u2122 tables.",
        "COMPATIBLE: Snowflake performs encoding and compression that ensures interoperability with third-party compute engines.",
        "OPTIMIZED: Snowflake performs encoding and compression that ensures the best table performance within Snowflake.",
        "OPTIMIZED",
        "Session \u2014 Can be set for Account \u00bb User \u00bb Session",
        "Boolean",
        "This parameter specifies whether JSON output in a session is compatible with the general standard (as described by http://json.org).",
        "By design, Snowflake allows JSON input that contains non-standard values; however, these non-standard values might result in Snowflake outputting JSON that is incompatible with other platforms and\nlanguages. This parameter, when enabled, ensures that Snowflake outputs valid/compatible JSON.",
        "TRUE: Strict JSON output is enabled, enforcing the following behavior:",
        "Missing and undefined values in input mapped to JSON NULL.",
        "Non-finite numeric values in input (Infinity, -Infinity, NaN, etc.) mapped to strings with valid JavaScript representations. This enables compatibility with JavaScript and also allows conversion of\nthese values back to numeric values.",
        "FALSE: Strict JSON output is not enabled.",
        "FALSE",
        "For example:",
        "Non-standard JSON Input",
        "Param set to FALSE (default)",
        "Param set to TRUE",
        "[289, 2188,]",
        "outputs:",
        "[ 289, 2188, undefined ]",
        "[ 289, 2188, null ]",
        "[undefined, undefined]",
        "outputs:",
        "[ undefined, undefined ]",
        "[ null, null ]",
        "[Infinity,inf,-Infinity,-inf]",
        "outputs:",
        "[ Infinity, Infinity, -Infinity, -Infinity ]",
        "[ \"Infinity\", \"Infinity\", \"-Infinity\", \"-Infinity\" ]",
        "[NaN,nan]",
        "outputs:",
        "[ NaN, NaN ]",
        "[ \"NaN\", \"NaN\" ]",
        "Object (for databases, schemas, and tasks) \u2014 Can be set for Account \u00bb Database \u00bb Schema \u00bb Task",
        "Integer",
        "Number of consecutive failed task runs after which a standalone task or\ntask graph root task is suspended automatically. Failed task runs include\nruns in which the SQL code in the task body either produces a user error or times out. Task\nruns that are skipped, canceled, or that fail due to a system error are considered indeterminate\nand are not included in the count of failed task runs.",
        "When the parameter is set to 0, the failed task is not automatically suspended.",
        "When the parameter is set to a value greater than 0, the following behavior applies to\nruns of standalone tasks or task graph root tasks:",
        "A standalone task is automatically suspended after the specified number of consecutive task\nruns either fail or time out.",
        "A root task is automatically suspended after the specified number of times in consecutive runs\nafter any single task in a task graph fails or times out, after all\nTASK_AUTO_RETRY_ATTEMPTS for that task.",
        "For example, if a root task has SUSPEND_TASK_AFTER_NUM_FAILURES set to 3, and\nit has a child task with TASK_AUTO_RETRY_ATTEMPTS set to 3, then after that child task\nfails 9 consecutive times, the root task is suspended.",
        "The default value for the parameter is set to 10, which means that the task is automatically suspended after 10 consecutive failed task runs.",
        "When you explicitly set the parameter value at the account, database, or schema level, the\nchange is applied to tasks contained in the modified object during their next scheduled run\n(including any child task in a task graph run in progress).",
        "Suspending a standalone task resets its count of failed task runs. Suspending the root task of a task graph resets the count for each\ntask in the task graph.",
        "0 - No upper limit.",
        "10",
        "Object (for databases, schemas, and tasks) \u2014 Can be set for Account \u00bb Database \u00bb Schema \u00bb Task",
        "Integer",
        "Specifies the number of automatic task graph retry attempts. If any task graphs complete in a FAILED state, Snowflake\ncan automatically retry the task graphs from the last task in the graph that failed. Failed task runs include runs in which the SQL code in\nthe task body either produces a user error or times out. Task runs that are skipped or canceled are considered indeterminate and are not included in the count of failed task runs.",
        "The automatic task graph retry is disabled by default. To enable this feature, set TASK_AUTO_RETRY_ATTEMPTS to a value greater than\n0.",
        "When you set the parameter value at the account, database, or schema level, the change is applied to tasks contained in the modified object\nduring their next scheduled run.",
        "0 - No upper limit.",
        "0",
        "Session \u2014 Can be set for Account \u00bb User \u00bb Session",
        "Boolean",
        "Specifies whether the DATEADD function (and its aliases) always consider a day to be exactly 24 hours for expressions that span multiple days.",
        "TRUE: A day is always exactly 24 hours.",
        "FALSE: A day is not always 24 hours.",
        "FALSE",
        "Important",
        "If set to TRUE, the actual time of day might not be preserved when daylight saving time (DST) is in effect. For example:",
        "Session \u2014 Can be set for Account \u00bb User \u00bb Session",
        "String",
        "Specifies the input format for the TIMESTAMP data type alias. For more information, see Date and time input and output formats.",
        "Any valid, supported timestamp format or AUTO",
        "(AUTO specifies that Snowflake attempts to automatically detect the format of timestamps stored in the system during the session)",
        "AUTO",
        "Session \u2014 Can be set for Account \u00bb User \u00bb Session",
        "String",
        "Specifies the display format for the TIMESTAMP_LTZ data type. If CSV_TIMESTAMP_FORMAT is not set, TIMESTAMP_LTZ_OUTPUT_FORMAT is used when downloading CSV files. For more information, see Date and time input and output formats.",
        "Any valid, supported timestamp format",
        "None",
        "Session \u2014 Can be set for Account \u00bb User \u00bb Session",
        "String",
        "Specifies the display format for the TIMESTAMP_NTZ data type. If CSV_TIMESTAMP_FORMAT is not set, TIMESTAMP_NTZ_OUTPUT_FORMAT is used when downloading CSV files. For more information, see Date and time input and output formats.",
        "Any valid, supported timestamp format",
        "YYYY-MM-DD HH24:MI:SS.FF3",
        "Session \u2014 Can be set for Account \u00bb User \u00bb Session",
        "String",
        "Specifies the display format for the TIMESTAMP data type alias. For more information, see Date and time input and output formats.",
        "Any valid, supported timestamp format",
        "YYYY-MM-DD HH24:MI:SS.FF3 TZHTZM",
        "Session \u2014 Can be set for Account \u00bb User \u00bb Session",
        "String",
        "Specifies the TIMESTAMP_* variation that the TIMESTAMP data type alias maps to.",
        "TIMESTAMP_LTZ , TIMESTAMP_NTZ , or TIMESTAMP_TZ",
        "TIMESTAMP_NTZ",
        "Session \u2014 Can be set for Account \u00bb User \u00bb Session",
        "String",
        "Specifies the display format for the TIMESTAMP_TZ data type. If CSV_TIMESTAMP_FORMAT is not set, TIMESTAMP_TZ_OUTPUT_FORMAT is used when downloading CSV files. For more information, see Date and time input and output formats.",
        "Any valid, supported timestamp format",
        "None",
        "Session \u2014 Can be set for Account \u00bb User \u00bb Session",
        "String (Constant)",
        "Specifies the time zone for the session.",
        "You can specify a time zone name or a link name from release 2021a of the IANA Time Zone Database (e.g.\nAmerica/Los_Angeles, Europe/London, UTC, Etc/GMT, etc.).",
        "America/Los_Angeles",
        "Note",
        "Time zone names are case-sensitive and must be enclosed in single quotes (e.g. 'UTC').",
        "Snowflake does not support the majority of timezone abbreviations (e.g. PDT, EST, etc.) because a\ngiven abbreviation might refer to one of several different time zones. For example, CST might refer to Central\nStandard Time in North America (UTC-6), Cuba Standard Time (UTC-5), and China Standard Time (UTC+8).",
        "Session \u2014 Can be set for Account \u00bb User \u00bb Session",
        "String",
        "Specifies the input format for the TIME data type. For more information, see Date and time input and output formats.",
        "Any valid, supported time format or AUTO",
        "(AUTO specifies that Snowflake attempts to automatically detect the format of times stored in the system during the session)",
        "AUTO",
        "Session \u2014 Can be set for Account \u00bb User \u00bb Session",
        "String",
        "Specifies the display format for the TIME data type. For more information, see Date and time input and output formats.",
        "Any valid, supported time format",
        "HH24:MI:SS",
        "Session \u2014 Can be set for Account \u00bb User \u00bb Session",
        "Object (for databases, schemas, stored procedures, and UDFs) \u2014 Can be set for Account \u00bb Database \u00bb Schema \u00bb Procedure and Account \u00bb Database \u00bb Schema \u00bb Function",
        "String (Constant)",
        "Controls how trace events are ingested into the event table. For more information about trace levels, see\nSetting levels for logging, metrics, and tracing.",
        "ALWAYS: All spans and trace events will be recorded in the event table.",
        "ON_EVENT: Trace events will be recorded in the event table only when your stored procedures or UDFs explicitly add events.",
        "OFF: No spans or trace events will be recorded in the event table.",
        "OFF",
        "Note",
        "When tracing events, you must also set the LOG_LEVEL parameter to one of its supported values.",
        "Session \u2014 Can be set for Account \u00bb User \u00bb Session",
        "BOOLEAN",
        "Specifies the action to perform when a statement issued within a non-autocommit transaction returns with an error.",
        "TRUE: The non-autocommit transaction is aborted. All statements issued inside that transaction will fail until a commit or rollback statement is executed to close that transaction.",
        "FALSE: The non-autocommit transaction is not aborted.",
        "FALSE",
        "Session \u2014 Can be set for Account \u00bb User \u00bb Session",
        "String",
        "Specifies the isolation level for transactions in the user session.",
        "READ COMMITTED (only currently-supported value)",
        "READ COMMITTED",
        "Session \u2014 Can be set for Account \u00bb User \u00bb Session",
        "Number",
        "Specifies the \u201ccentury start\u201d year for 2-digit years (i.e. the earliest year such dates can represent). This parameter prevents ambiguous dates when importing or converting data with\nthe YY date format component (i.e. years represented as 2 digits).",
        "1900 to 2100 (any value outside of this range returns an error)",
        "1970",
        "For example:",
        "Year",
        "Param set to 1900",
        "Param set to 1970 (default)",
        "Param set to 1980",
        "Param set to 1990",
        "Param set to 2000",
        "00",
        "becomes:",
        "1900",
        "2000",
        "2000",
        "2000",
        "2000",
        "79",
        "becomes:",
        "1979",
        "1979",
        "2079",
        "2079",
        "2079",
        "89",
        "becomes:",
        "1989",
        "1989",
        "1989",
        "2089",
        "2089",
        "99",
        "becomes:",
        "1999",
        "1999",
        "1999",
        "1999",
        "2099",
        "Session \u2014 Can be set for Account \u00bb User \u00bb Session",
        "String (Constant)",
        "Determines if an unsupported (i.e. non-default) value specified for a constraint property returns an error.",
        "IGNORE: Snowflake does not return an error for unsupported values.",
        "FAIL: Snowflake returns an error for unsupported values.",
        "IGNORE",
        "Important",
        "This parameter does not determine whether the constraint is created. Snowflake does not create constraints using unsupported values, regardless of how this parameter is set.",
        "For more information, see Constraint properties.",
        "Session \u2014 Can be set for Account \u00bb User \u00bb Session",
        "Boolean",
        "Specifies whether to reuse persisted query results, if available, when a matching query is submitted.",
        "TRUE: When a query is submitted, Snowflake checks for matching query results for previously-executed queries and, if a matching result exists, uses the result instead of executing the\nquery. This can help reduce query time because Snowflake retrieves the result directly from the cache.",
        "FALSE: Snowflake executes each query when submitted, regardless of whether a matching query result exists.",
        "TRUE",
        "Object (for databases, schemas, and tasks) \u2014 Can be set for Account \u00bb Database \u00bb Schema \u00bb Task",
        "String",
        "Specifies the size of the compute resources to provision for the first run of the task, before a task history is available for\nSnowflake to determine an ideal size. Once a task has successfully completed a few runs, Snowflake ignores this parameter setting. If the\ntask history is unavailable for a given task, the compute resources revert to this initial size.",
        "Note",
        "This parameter applies only to serverless tasks.",
        "The size is equivalent to the compute resources available when creating a warehouse. If the parameter is omitted, the first runs of the\ntask are executed using a medium-sized (MEDIUM) warehouse.",
        "You can change the initial size for individual tasks (using ALTER TASK) after the task is created but\nbefore it has run successfully once. Changing the parameter after the first run of this task starts has no effect on the\ncompute resources for current or future task runs.",
        "Note that suspending and resuming a task does not remove the task history used to size the compute resources. The task history is\nonly removed if the task is recreated (using the CREATE OR REPLACE TASK syntax).",
        "Any traditional warehouse size: SMALL, MEDIUM, LARGE, etc., with a maximum size of XXLARGE.",
        "MEDIUM",
        "Object (for databases, schemas, and tasks) \u2014 Can be set for Account \u00bb Database \u00bb Schema \u00bb Task",
        "Number",
        "Defines how frequently a triggered task can execute in seconds. If data changes occur more often than the specified minimum, changes will be grouped and processed together.",
        "The task will run every 12 hours even if this value is set to more than 12 hours.",
        "10 - 604800 (1 week).",
        "30",
        "Object (for databases, schemas, and tasks) \u2014 Can be set for Account \u00bb Database \u00bb Schema \u00bb Task",
        "Number",
        "Specifies the time limit on a single run of the task before it times out (in milliseconds).",
        "Note",
        "Before you increase the time limit for tasks significantly, consider whether the SQL statements in the task definitions could be\noptimized (either by rewriting the statements or using stored procedures) or whether the warehouse size for tasks with user-managed\ncompute resources should be increased.",
        "In some situations, the STATEMENT_TIMEOUT_IN_SECONDS parameter has a higher precedence than USER_TASK_TIMEOUT_MS. For\ndetails, see STATEMENT_TIMEOUT_IN_SECONDS.",
        "0 - 604800000 (7 days). A value of 0 specifies that the maximum timeout value is enforced.",
        "3600000 (1 hour)",
        "Session \u2014 Can be set for Account \u00bb User \u00bb Session",
        "Number",
        "Specifies how the weeks in a given year are computed.",
        "0: The semantics used are equivalent to the ISO semantics, in which a week belongs to a given year if at least 4 days of that week are in that year.",
        "1: January 1 is included in the first week of the year and December 31 is included in the last week of the year.",
        "0 (i.e. ISO-like behavior)",
        "Tip",
        "1 is the most common value, based on feedback we\u2019ve received. For more information, including examples, see Calendar weeks and weekdays.",
        "Session \u2014 Can be set for Account \u00bb User \u00bb Session",
        "Number",
        "Specifies the first day of the week (used by week-related date functions).",
        "0: Legacy Snowflake behavior is used (i.e. ISO-like semantics).",
        "1 (Monday) to 7 (Sunday): All the week-related functions use weeks that start on the specified day of the week.",
        "0 (i.e. legacy Snowflake behavior)",
        "Tip",
        "1 is the most common value, based on feedback we\u2019ve received. For more information, including examples, see Calendar weeks and weekdays.",
        "Was this page helpful?",
        "On this page",
        "Related content"
    ]
}