{
    "url": "https://docs.snowflake.com/en/developer-guide/udf/java/udf-java-tabular-functions",
    "title": "Tabular Java UDFs (UDTFs) | Snowflake Documentation",
    "paragraphs": [
        "This document explains how to write a UDTF (user-defined table function) in Java.",
        "Your Java UDTF handler class processes rows received in the UDTF call and returns a tabular result. The received rows are partitioned,\neither implicitly by Snowflake or explicitly in the syntax of the function call. You can use the methods you implement in the class to\nprocess individual rows as well as the partitions into which they\u2019re grouped.",
        "Your handler class can process partitions and rows with the following:",
        "A zero-argument constructor as an initializer. You can use this to set up partition-scoped state.",
        "A process method for processing each row.",
        "A zero-argument endPartition method as a finalizer to complete partition processing, including returning a value scoped to the\npartition.",
        "For more detail, see Java classes for UDTFs (in this topic).",
        "Each Java UDTF also requires an output row class, which specifies the Java data types of the columns of the output row(s) that\nare generated by the handler class. Details are included in The output row class (in this topic).",
        "When it receives rows that are implicitly partitioned by Snowflake, your handler code can make no assumptions about partitions. Running\nwith implicit partitioning is most useful when the UDTF only needs to look at rows in isolation to produce its output and no state is\naggregated across rows. In this case, the code probably does not need a constructor or an endPartition method.",
        "To improve performance, Snowflake usually executes multiple instances of the UDTF handler code in parallel. Each partition of rows\nis passed to a single instance of the UDTF.",
        "Although each partition is processed by only one UDTF instance, the converse is not necessarily true \u2014 a single UDTF instance can\nprocess multiple partitions sequentially. It is therefore important to use the initializer and finalizer to initialize and clean\nup for each partition to avoid carrying over accumulated values from the processing of one partition to the processing of another\npartition.",
        "Note",
        "Tabular functions (UDTFs) have a limit of 500 input arguments and 500 output columns.",
        "The primary components of the UDTF are the handler class and the output row class.",
        "Snowflake interacts with the UDTF primarily by invoking the following methods of the handler class:",
        "The initializer (the constructor).",
        "The per-row method (process).",
        "The finalizer method (endPartition).",
        "The handler class can contain additional methods needed to support these three methods.",
        "The handler class also contains a method getOutputClass, which is described later.",
        "Throwing an exception from any method in the handler class (or the output row class)\ncauses processing to stop. The query that called the UDTF fails with an error message.",
        "A handler class can have a constructor, which must take zero arguments.",
        "The constructor is invoked once for each partition prior to any invocations of process.",
        "The constructor cannot produce output rows.",
        "Use the constructor to initialize state for the partition; this state can be used by the process and\nendPartition methods. The constructor is also the appropriate place to put any long-running initialization that\nneeds to be done only once per partition rather than once per row.",
        "The constructor is optional.",
        "The process method is invoked once for each row in the input partition.",
        "The arguments passed to the UDTF are passed to process. The values of the arguments are converted from SQL data types to\nJava data types. (For information about mapping SQL and Java data types, see SQL-Java Data Type Mappings.)",
        "The parameter names of the process method can be any valid Java identifiers; the names do not need to match the names\nspecified in the CREATE FUNCTION statement.",
        "Each time that process is called, it can return zero, one, or multiple rows.",
        "The data type returned by the process method must be Stream<OutputRow>, where Stream is defined in\njava.util.stream.Stream, and OutputRow is the name of the output row class. The example below shows a simple\nprocess method that merely returns its input via a Stream:",
        "If the process method does not keep or use any state in the object\n(e.g. if the method is designed to just exclude selected input rows from\nthe output), you can declare the method static.  If the\nprocess method is static and the handler class does not\nhave a constructor or non-static endPartition method, Snowflake\npasses each row directly to the static process method without\nconstructing an instance of the handler class.",
        "If you need to skip an input row and process the next row (e.g. if you are\nvalidating the input rows), return an empty Stream object. For\nexample, the process method below only returns the rows for\nwhich number is a positive integer. If number is not positive,\nthe method returns an empty Stream object to skip the current\nrow and continue processing the next row.",
        "If process returns a null Stream, then processing stops. (The endPartition method is still called even if\na null Stream is returned.)",
        "This method is required.",
        "This optional method can be used to generate output rows that are based on any state information aggregated in process. This method is\ninvoked once for each partition, after all rows in that partition have been\npassed to process.",
        "If you include this method, it is called on each partition, regardless of whether the data was partitioned explicitly or implicitly.\nIf the data is not partitioned meaningfully, the output of the finalizer might not be meaningful.",
        "Note",
        "If the user does not partition the data explicitly, Snowflake partitions the data implicitly. For details, see:\npartitions.",
        "This method can output zero, one, or multiple rows.",
        "Note",
        "While Snowflake supports large partitions with timeouts tuned to process them successfully, especially large partitions can cause\nprocessing to time out (such as when endPartition takes too long to complete). Please contact Snowflake Support if you need the\ntimeout threshold adjusted for specific usage scenarios.",
        "This method returns information about the output row class. The output row class contains\ninformation about the data types of the returned row.",
        "Snowflake uses the output row class to help specify conversions between Java data types and SQL data types.",
        "When a Java UDTF returns a row, the value in each column of the row must be converted from the\nJava data type to the corresponding SQL data type. The SQL data types are specified in the RETURNS clause of the\nCREATE FUNCTION statement. However, the mapping between Java and SQL data types is not 1-to-1, so Snowflake needs to know\nthe Java data type for each returned column. (For more information about mapping SQL and Java data types, see\nSQL-Java Data Type Mappings.)",
        "A Java UDTF specifies the Java data types of the output columns by defining an output row class. Each row returned from the UDTF is\nreturned as an instance of the output row class. Each instance of the output row class contains one public field for each output\ncolumn. Snowflake reads the values of the public fields from each instance of the output row class, converts the Java values to SQL\nvalues, and constructs a SQL output row containing those values.",
        "The values in each instance of the output row class are set by calling the output row class\u2019s constructor. The constructor\naccepts parameters that correspond to the output columns and then sets the public fields to those parameters.",
        "The code below defines a sample output row class:",
        "The public variables specified by this class must match the columns specified in the RETURNS TABLE (...) clause of the\nCREATE FUNCTION statement. For example, the OutputRow class above corresponds to the RETURNS clause below:",
        "Important",
        "The matching between the SQL column names and the Java public field names in the output row class is case-insensitive.\nFor example, in the Java and SQL code shown above, the Java field named id corresponds to the SQL column named ID.",
        "The output row class is used as follows:",
        "The handler class uses the output row class to specify the return type of the process method and the\nendPartition method. The handler class also uses the output row class to construct returned values. For example:",
        "The output row class is also used in the handler class\u2019s getOutputClass method, which is a static method that\nSnowflake calls in order to learn the Java data types of the outputs:",
        "Throwing an exception from any method in the output row class (or the handler class) causes\nprocessing to stop. The query that called the UDTF fails with an error message.",
        "The UDTF\u2019s Java code must meet the following requirements:",
        "The code must define an output row class.",
        "The UDTF handler class must include a public method named process that returns a Stream of <output_row_class>, where\nStream is defined in java.util.stream.Stream.",
        "The UDTF handler class must define a public static method named getOutputClass, which must return\n<output_row_class>.class.",
        "If the Java code does not meet these requirements, then either creation or execution of the UDTF fails:",
        "If the session has an active warehouse at the time the CREATE FUNCTION statement executes, then Snowflake detects\nviolations when the function is created.",
        "If the session does not have an active warehouse at the time the CREATE FUNCTION statement executes, then Snowflake detects\nviolations when the function is called.",
        "For general information about calling UDFs and UDTFs, see Calling a UDF.",
        "This example shows how to create a UDTF. This example returns two copies of each input and returns one additional row for\neach partition.",
        "This example shows how to call a UDTF. To keep this example simple, the statement passes a literal value rather than a column,\nand omits the OVER() clause.",
        "This example calls the UDTF with values read from another table. Each time that the process method is called,\nit is passed a value from the city_name column of the current row of the cities_of_interest table. As above, the UDTF is\ncalled without an explicit OVER() clause.",
        "Create a simple table to use as a source of inputs:",
        "Call the Java UDTF:",
        "Attention",
        "In this example, the syntax used in the FROM clause is identical to the syntax of an inner join (i.e. FROM t1, t2);\nhowever, the operation performed is not a true inner join. The actual behavior is that the function is called with\nthe values from each row in the table. In other words, given the following FROM clause:",
        "the behavior would be equivalent to the following pseudocode:",
        "The examples section in the documentation for JavaScript UDTFs contains more\ncomplex examples of queries that call UDTFs with values from tables.",
        "If the statement does not explicitly specify partitioning, then the Snowflake execution engine\nuses implicit partitioning.",
        "If there is only one partition, then the endPartition method is called only once and the output of the query includes only\none row that contains the value Created in constructor and output from endPartition(). If the data is grouped into\ndifferent numbers of partitions during different executions of the statement, the endPartition method is called different\nnumbers of times, and the output contains different numbers of copies of this row.",
        "For more information, see implicit partitioning.",
        "Java UDTFs can also be called using explicit partitioning.",
        "The following example uses the same UDTF and table created earlier. The example partitions the data by city_name.",
        "The following example uses the same UDTF and table created earlier and partitions the data by a constant, which forces\nSnowflake to use only a single partition:",
        "Note that only one copy of the message Created in constructor and output from endPartition() was included in the output,\nwhich indicates that endPartition was called only once.",
        "In some cases, a UDTF requires a very large amount of memory to process each input row. For example, a UDTF might read and\nprocess a file that is too large to fit into memory.",
        "To process large files in a UDF or UDTF, use the SnowflakeFile or InputStream class. For more information, see\nProcessing unstructured data with UDF and procedure handlers.",
        "Was this page helpful?",
        "On this page",
        "Related content"
    ]
}