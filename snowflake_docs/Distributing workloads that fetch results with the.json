{
    "url": "https://docs.snowflake.com/en/developer-guide/python-connector/python-connector-distributed-fetch",
    "title": "Distributing workloads that fetch results with the Snowflake Connector for Python | Snowflake Documentation",
    "paragraphs": [
        "If you are using a distributed environment to parallelize workloads, you can use the Snowflake Connector for Python to distribute\nthe work of fetching and processing results.",
        "After you use the Cursor object to execute a query, you can distribute the work of fetching the results by using\nresult batches. A result batch encapsulates a function that retrieves a subset of the results. You can assign different workers\nto use different result batches to fetch and process results in parallel.",
        "After executing a query, you can retrieve the results in one of the following formats:",
        "ResultBatch objects.",
        "To do this, call the get_result_batches() method in the Cursor object.\nThis returns a list of ResultBatch objects that you can assign to different workers for processing. For example:",
        "PyArrow tables.",
        "For more information, see PyArrow tables.",
        "You can use the following methods to retrieve the result batches as PyArrow tables:",
        "fetch_arrow_all(): Call this method to return a PyArrow table containing all of the results.",
        "fetch_arrow_batches(): Call this method to return an iterator that you can use to return a PyArrow table for each\nresult batch.",
        "For example:",
        "pandas DataFrame objects.",
        "If you have\ninstalled the pandas-compatible version of the Snowflake Connector for Python,\nyou can use the following methods to retrieve the result batches as pandas DataFrame objects:",
        "fetch_pandas_all(): Call this method to return a pandas DataFrame containing all of the results.",
        "fetch_pandas_batches(): Call this method to return an iterator that you can use to return a pandas DataFrame for each\nresult batch.",
        "For example:",
        "To move the result batches to other workers or nodes, you can serialize and deserialize the result batches. For example:",
        "The next sections explain how to work with ResultBatch objects:",
        "Iterating over rows in a result batch",
        "Materializing the rows in a result batch",
        "Getting the number of rows and size of a result batch",
        "Converting an arrow result batch to a PyArrow table or pandas DataFrame",
        "With a ResultBatch object, you can iterate over the rows that are part of that batch. For example:",
        "When you create an iterator of a ResultBatch object, the object fetches and converts the subset of rows for that batch.",
        "To materialize the subset of rows in a result batch by passing that ResultBatch object to the list() function. For\nexample:",
        "If you need to determine the number of rows in a result batch and the size of the data, you can use\nrowcount,\ncompressed_size,\nand uncompressed_size attributes of the ResultBatch object.\nFor example:",
        "Note that these attributes are available before you iterate over the result batch. You don\u2019t need to fetch the subset of rows for\nthe batch in order to get the values of these attributes.",
        "To convert an ArrowResultBatch to a PyArrow table or a pandas DataFrame, use the following methods:",
        "to_pandas(): Call this method to return a pandas DataFrame containing the rows in a ArrowResultBatch, if you have\ninstalled the pandas-compatible version of the Snowflake Connector for Python.",
        "to_arrow(): Call this method to return a PyArrow table containing the rows in a ResultBatch.",
        "For example:",
        "Was this page helpful?",
        "On this page"
    ]
}