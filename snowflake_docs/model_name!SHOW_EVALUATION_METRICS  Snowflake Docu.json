{
    "url": "https://docs.snowflake.com/en/sql-reference/classes/forecast/methods/show_evaluation_metrics",
    "title": "<model_name>!SHOW_EVALUATION_METRICS | Snowflake Documentation",
    "paragraphs": [
        "Returns out-of-sample evaluation metrics generated using time-series cross validation.",
        "If you need to select specific columns from the data returned by this method, you can call the method in the FROM clause of a\nSELECT statement. See Selecting columns from SQL class instance methods that return tabular data.",
        "You can call this method to retrieve the cross-validation metrics generated when the model was trained, or you\ncan call it with additional data that was not available at training time (out-of-sample data) and receive\nmetrics based on how well the model predicts that data.",
        "Return time series cross-validation metrics generated at training time:",
        "These metrics are available only if evaluate=TRUE in the CONFIG_OBJECT during model construction\n(this is the default).",
        "Compute cross-validation metrics on additional out-of-sample data:",
        "The following arguments only apply to the additional out-of-sample data use case.",
        "Required:",
        "Not all of the following arguments are required for every use case.",
        "A reference to a table, view, or query\nthat contains the future timestamps and values of the target and any exogenous variables used during training. Columns\nare matched between this argument and the original exogenous training data by name.",
        "To create this reference, you can use the TABLE keyword with the table name, view name,\nor query, or you can call the SYSTEM$REFERENCE or\nSYSTEM$QUERY_REFERENCE function.",
        "Name of the column containing the timestamps in input_data.",
        "Name of the column containing the target (dependent value) in input_data.",
        "Optional:",
        "The name of the column in input_data specifying the series.",
        "An OBJECT containing key-value pairs used to configure the evaluation job.",
        "Key",
        "Type",
        "Default",
        "Description",
        "prediction_interval",
        "FLOAT",
        "0.95",
        "A value greater than or equal to 0.0 and less than 1.0. The default value of 0.95 means 95% of future points are\nexpected to fall within the interval [lower_bound, upper_bound] derived from the forecast result.",
        "on_error",
        "STRING",
        "'ABORT'",
        "String (constant) specifying the error handling method. This is most useful when forecasting multiple series.\nSupported values are:",
        "'abort': Abort the model forecasting operation if an error is encountered in any time series.",
        "'skip': Skip any time series where forecasting encounters an error. This allows forecasting\nto succeed for other time series. Series that fail are absent from the model output.",
        "Column",
        "Type",
        "Description",
        "SERIES",
        "VARIANT",
        "Series value (NULL if model was trained with single time series).",
        "ERROR_METRIC",
        "VARCHAR",
        "The name of the error metric used. The method returns the following metrics:",
        "Point Metrics:",
        "MAE: Mean Absolute Error.",
        "MAPE: Mean Absolute Percentage Error.",
        "MDA: Mean Directional Accuracy.",
        "MSE: Mean Squared Error.",
        "SMAPE: Symmetric Mean Absolute Percentage Error.",
        "Interval Metrics: These metrics use the prediction_interval argument from the Evaluation configuration.",
        "COVERAGE_INTERVAL: The proportion of actual values that fall within the prediction interval.",
        "WINKLER_ALPHA: Winkler Score.",
        "LOGS",
        "VARIANT",
        "Contains error or warning messages.",
        "See Examples.",
        "Was this page helpful?",
        "On this page"
    ]
}