{
    "url": "https://docs.snowflake.com/en/user-guide/snowflake-cortex/cortex-analyst",
    "title": "Cortex Analyst | Snowflake Documentation",
    "paragraphs": [
        "Preview Feature \u2014 Open",
        "Available to accounts in most Snowflake regions. See Region Availability for a full list.",
        "Cortex Analyst is a fully-managed, LLM-powered Snowflake Cortex\nfeature that helps you create applications capable of reliably answering business questions based on your structured\ndata in Snowflake. With Cortex Analyst, business users can ask questions in natural language and receive direct\nanswers without writing SQL. Available as a convenient REST API, Cortex Analyst can be seamlessly integrated into any\napplication.",
        "Building a production-grade conversational self-service analytics solution requires a service that generates accurate\ntext-to-SQL responses. For most teams, developing such a service that successfully balances accuracy, latency, and costs\nis a daunting task. Cortex Analyst simplifies this process by providing a fully managed, sophisticated\nagentic AI system that handles all of these complexities, generating highly accurate text-to-SQL responses. It helps you\naccelerate the delivery of high-precision, self-serve conversational analytics to business teams, while avoiding time\nsinks such as complex RAG solution patterns, model experimentation, and GPU capacity planning. The generated SQL queries\nare executed against the scalable Snowflake engine, ensuring industry-leading price performance and lower total cost of\nownership (TCO).",
        "Tip",
        "Want to get started with Cortex Analyst quickly? Try the Tutorial: Answer questions about time-series revenue data with Cortex Analyst tutorial.",
        "Self-serve analytics via natural language queries. Delight your business teams and non-technical users with instant\nanswers and insights from their structured data in Snowflake. Using Cortex Analyst, you can build downstream chat\napplications that allow your users to ask questions using natural language and receive accurate answers on the fly.",
        "Convenient REST API for integration into existing business workflows. Cortex Analyst takes an API-first approach,\ngiving you full control over the end user experience. Easily integrate Cortex Analyst into existing business tools\nand platforms, bringing the power of data insights to where business users already operate, such as Streamlit apps,\nSlack, Teams, custom chat interfaces, and more.",
        "Powered by state-of-the-art large language models: By default, Cortex Analyst is powered by the latest Meta Llama\nand Mistral models, which run securely inside Snowflake Cortex, Snowflake\u2019s\nintelligent, fully managed AI service. Optionally, you can also give Cortex Analyst access to the latest\nAzure-hosted OpenAI GPT models. At runtime, Cortex Analyst selects the best combination of models to ensure the\nhighest accuracy and performance for each query. For details, see Enabling use of Azure OpenAI models. As\nLLMs evolve, Snowflake will continue to explore adding more models to the mix to further improve performance and\naccuracy.",
        "Semantic model for high precision and accuracy: Generic AI solutions often struggle with text-to-SQL conversions\nwhen given only a database schema, as schemas lack critical knowledge like business process definitions and metrics\nhandling. Cortex Analyst overcomes this limitation by using a semantic model that\nbridges the gap between business users and databases. Captured in a lightweight YAML file, the overall structure and\nconcepts of the semantic model are similar to those of database schemas, but allow for a richer description of the\nsemantic information around the data.",
        "Security and governance. Snowflake\u2019s privacy-first foundation and enterprise-grade security ensure that you can\nexplore AI-driven use cases with confidence, knowing your data is protected by the highest standards of privacy and\ngovernance.",
        "Cortex Analyst does not train on Customer Data. We do not use your Customer Data to train or fine-tune any Model to\nbe made available for use across our customer base. Additionally, for inference, Cortex Analyst utilizes the metadata\nprovided in the semantic model YAML file (e.g., table names, column names, value type, descriptions, etc.) only for\nSQL-query generation. This SQL query is then executed in your Snowflake virtual warehouse to generate the final\noutput.",
        "Data stays within Snowflake\u2019s governance boundary. By default, Cortex Analyst is powered by Snowflake-hosted LLMs\nfrom Mistral and Meta, ensuring that no data, including metadata or prompts, leaves Snowflake\u2019s governance boundary.\nIf you opt to use Azure OpenAI models, only metadata and prompts are transmitted outside of Snowflake\u2019s governance\nboundary.",
        "Seamless integration with Snowflake\u2019s Privacy and Governance features. Cortex Analyst fully integrates with\nSnowflake\u2019s role-based access control (RBAC) policies, ensuring that SQL queries generated and executed adhere to\nall established access controls. This guarantees robust security and governance for your data.",
        "To make a request to Cortex Analyst, you must use a role that has the\nSNOWFLAKE.CORTEX_USER role granted.",
        "To use Cortex Analyst with a semantic model, you also need the following privileges:",
        "Privilege",
        "Object",
        "USAGE",
        "Stage that contains the semantic model YAML file, if the semantic model is uploaded to a stage.",
        "USAGE",
        "The Cortex Search services mentioned in the semantic model.",
        "SELECT",
        "The tables mentioned in the semantic model.",
        "Requests to the Cortex Analyst API must include an authorization token. For details on how to authenticate to the API,\nsee Authenticating Snowflake REST APIs with Snowflake.",
        "Note that the example in this topic uses a session token to authenticate to a Snowflake account.",
        "By default, the CORTEX_USER role is granted to the PUBLIC role. The PUBLIC role is automatically granted to all users and roles.\nIf you don\u2019t want all users to have this privilege, you can revoke access to the PUBLIC role and grant access to specific roles.\nFor more information, see Required privileges.",
        "To control access to specific semantic models, you can store the YAML file in a stage and control access to that stage.",
        "Cortex Analyst is natively available in the following regions.",
        "AWS ap-northeast-1 (Tokyo)",
        "AWS ap-southeast-2 (Sydney)",
        "AWS us-east-1 (Virginia)",
        "AWS us-west-2 (Oregon)",
        "AWS eu-central-1 (Frankfurt)",
        "AWS eu-west-1 (Ireland)",
        "Azure East US 2 (Virginia)",
        "Azure West Europe (Netherlands)",
        "If your Snowflake account is in a different cloud region, you can still use Cortex Analyst by leveraging\nCross-region inference. Once cross-region inference is enabled, Cortex Analyst\nprocesses requests in other regions for models that are not available in your default region. For optimal performance,\nconfigure cross-region with AWS US regions.",
        "If you upload a semantic model YAML file to a stage, access to that semantic model is controlled by access to the\nstage it\u2019s uploaded to. This means that any role with access to the stage can access the semantic models on that\nstage, even if the role doesn\u2019t have access to the underlying tables.",
        "By default, Cortex Analyst is rate-limited to 20 requests per minute, which should be sufficient for proof of\nconcept. Contact your Sales Engineer to request a higher limit.",
        "By default, Cortex Analyst is powered by Snowflake-hosted Cortex LLMs. You can, however, explicitly opt-in to allow\nCortex Analyst to use the latest OpenAI GPT models, hosted by Microsoft Azure, alongside the Snowflake-hosted models. At\nruntime, Cortex Analyst selects the optimal combination of models to ensure the highest accuracy and performance for\neach query.",
        "Note",
        "If you opt in to using Azure OpenAI models, Cortex Analyst is\navailable for use in all AWS, Azure, and GCP regions, except for Gov and VPS deployments.",
        "You can configure your account to allow use of the Azure OpenAI GPT models with the\nENABLE_CORTEX_ANALYST_MODEL_AZURE_OPENAI parameter. By default, the parameter is disabled and can only be set by the\nACCOUNTADMIN role using the ALTER ACCOUNT command:",
        "Tip",
        "To see the current value of this parameter, use the following SQL statement.",
        "See ENABLE_CORTEX_ANALYST_MODEL_AZURE_OPENAI for more details.",
        "When this parameter is enabled, Cortex Analyst might be powered by any combination of:",
        "Snowflake-hosted models, currently Mistral Large and Llama3 models",
        "Azure OpenAI models, currently GPT-4o (requires explicit opt-in)",
        "Note",
        "Cortex Analyst might use different models in the future to further improve performance and accuracy.",
        "Semantic model files are classified as metadata. If you opt in to using Azure OpenAI\nmodels in Cortex Analyst, your semantic model will be processed by Microsoft Azure, a third party. Customer Data,\nhowever, is not shared with or processed by Azure.",
        "The ENABLE_CORTEX_ANALYST_MODEL_AZURE_OPENAI account parameter, if TRUE, allows\nCortex Analyst to use Azure OpenAI models.",
        "Parameter Type",
        "Session",
        "Data Type",
        "BOOLEAN",
        "Description",
        "Controls whether Cortex Analyst can use Azure OpenAI models to process requests.",
        "Values",
        "FALSE: Cortex Analyst uses only Snowflake-hosted models to process requests.",
        "TRUE: Cortex Analyst can use Azure OpenAI models, in addition to Snowflake-hosted models, to process requests.",
        "Default",
        "FALSE",
        "Cortex Analyst supports multi-turn conversations for data-related questions. This feature enables asking follow-up\nquestions that build on previous queries, creating a more dynamic and interactive data exploration experience.\nFor example, the user asks, \u201cWhat is the month-over-month revenue growth for 2021 in Asia?\u201d, then follows up with,\n\u201cWhat about North America?\u201d",
        "Cortex Analyst recognizes the follow-up, retrieves the context from the initial query, and rephrases the second question as:\n\u201cWhat is the month-over-month revenue growth for 2021 in North America?\u201d Cortex Analyst then generates a SQL\nquery to answer this question.",
        "To use this feature, pass the conversation history in the messages field:",
        "The conversation history is an array of messages in chronological order, where each message has a role and content. The\nrole can be \"user\" (for previous questions) or \"analyst\" (for previous responses). Analyst responses have both text and\nSQL responses, as shown in the example above, while user messages have only text.",
        "Some of the following limitations might be addressed in future versions of Cortex Analyst.",
        "Cortex Analyst doesn\u2019t have access to results from previous SQL queries. For example, if you first ask,\n\u201cWhat are my products?\u201d and then ask, \u201cWhat is the revenue of the second product?\u201d, Cortex Analyst cannot refer to\nthe list of products from the first query to get the second product.",
        "Cortex Analyst is limited to answering questions that can be resolved with SQL. It does not generate insights\nfor broader business-related queries, such as \u201cWhat trends do you observe?\u201d",
        "If a conversation includes too many turns or the user shifts intent frequently, Cortex Analyst might struggle to interpret\nthe follow-up questions. In such cases, reset the conversation and start again.",
        "Developers can use the following resources to get started with Cortex Analyst:",
        "Basic code example: The Cortex Analyst example in the following section provides a simple, easy-to-read script that helps\nyou create an interactive app using Cortex Analyst.",
        "Choose this option if you want a basic fundamental example to start with, and are comfortable with using Streamlit and making your own\nmodifications. You can run this example either in Streamlit in Snowflake (SiS) or locally.",
        "Snowflake Samples repository: If you\u2019re instead looking for a more comprehensive implementation, the Cortex Analyst advanced SiS demo\nin the Snowflake Samples repository has all the features and options already set up. This repository is configured with various pre-built\nfeatures that make deploying Cortex Analyst seamless and robust.",
        "Choose this option if you are trying to test out the feature for the first time, or have fewer custom modifications to make.",
        "Note",
        "This is shown only as an example. Snowflake does not provide support for the below content,\nnor does Snowflake warrant that the below content is accurate.",
        "To learn more, see the Cortex Analyst advanced SiS demo in the Snowflake Samples GitHub\nrepository.",
        "Follow these steps to create an interactive Streamlit in Snowflake (SiS) or standalone Streamlit app that uses Cortex Analyst.",
        "Create a semantic model",
        "Upload the semantic model to stage",
        "Create and run a Streamlit in Snowflake app",
        "Interact with the Streamlit in Snowflake app",
        "A semantic model is a lightweight mechanism that addresses issues related to the language difference between\nbusiness users and database definitions by allowing for the specification of additional semantic details\nabout a dataset. These additional semantic details, like more descriptive names or synonyms, enable Cortex Analyst to answer data questions\nmuch more reliably.",
        "Start with a list of questions you would like Cortex Analyst to answer. Based on that, decide on the dataset for your semantic model.",
        "Create your semantic model YAML based on the specification. For convenience, try\nthe Semantic model generator. Also, be sure to review the tips for creating a semantic\nmodel.",
        "You can upload a semantic model YAML file to a stage or pass the semantic model YAML\nas a string in the request body. If you upload a semantic model YAML to a stage, access to that semantic model is controlled by\naccess to the stage it\u2019s uploaded to. This means that any role with access to the stage can access the semantic models on that\nstage even if the role doesn\u2019t have access to the tables that the models are based on. Ensure that roles granted access to a stage\nhave SELECT access on all tables referenced in all semantic models on that stage.",
        "Below is an example of how to set up the stages containing the semantic models. One stage (public) is accessible to all members of the\norganization, whereas another stage (sales) is only accessible to the sales_analyst role.",
        "Create the database and schema for the stage. The following example creates a database named semantic_model with a schema named\ndefinition but you can use any valid identifier string for these names.",
        "Then create the stages for storing your semantic models:",
        "If using Snowsight, you can refresh the page and find the newly created stages in the\ndatabase object explorer.\nYou can open the stage page in a new tab and upload your YAML files in Snowsight.",
        "Alternatively, you can use the Snowflake CLI client\nto upload from your local file system.",
        "This example shows you how to create a Streamlit in Snowflake app that takes a natural language question as input and calls\nCortex Analyst to generate an answer based on the semantic model you provide.",
        "Note",
        "This is shown only as an example. Snowflake does not provide support for the below content,\nnor does Snowflake warrant that the below content is accurate.",
        "For more information on creating and running Streamlit apps in Snowflake, see About Streamlit in Snowflake.",
        "Follow the directions in Create a Streamlit app by using Snowsight to create a new\nStreamlit app in Snowsight.",
        "Copy the Streamlit code from our GitHub repo into the code editor.",
        "Replace the placeholder values with your account details.",
        "To preview the app, select Run to update the content in the Streamlit preview pane.",
        "Navigate to the Streamlit app in your browser or the Streamlit in Snowflake preview pane.",
        "Start asking questions about your data in natural language (e.g. \u201cWhat questions can I ask?\u201d).",
        "You can also use the example code to build a standalone app.",
        "Note",
        "This is shown only as an example. Snowflake does not provide support for the below content,\nnor does Snowflake warrant that the below content is accurate.",
        "Install Streamlit.",
        "Create a Python file locally called analyst_api.py.",
        "Copy the Streamlit code from our GitHub repo into the file.",
        "Replace the placeholder values with your account details.",
        "Run the Streamlit app using streamlit run analyst_api.py.",
        "The database and schema specified in the code is the stage location for the semantic model YAML file. The role used\nin the Snowflake connector should have access to underlying data defined in semantic model.",
        "For a more comprehensive implementation, see the Cortex Analyst advanced SiS demo in the Snowflake Samples GitHub\nrepository. This repository is configured with various pre-built features that make deploying Cortex Analyst seamless and robust.",
        "If you do not want Cortex Analyst to be available in your account, disable the feature by changing the\nENABLE_CORTEX_ANALYST parameter using the ACCOUNTADMIN role:",
        "Parameter Type",
        "Session",
        "Data Type",
        "BOOLEAN",
        "Description",
        "Controls whether Cortex Analyst functionality is enabled in your account.",
        "Values",
        "FALSE: Cortex Analyst functionality is not available.",
        "TRUE: Cortex Analyst functionality is available. If ENABLE_CORTEX_ANALYST_MODEL_AZURE_OPENAI is set to TRUE, Cortex Analyst can use Azure OpenAI models\nas well as Snowflake-hosted models. Otherwise, only Snowflake-hosted models can be used.",
        "Default",
        "TRUE",
        "The credit rate usage for Cortex Analyst is based on the number of messages processed as outlined in the Snowflake\nService Consumption Table. Only successful responses (HTTP 200) are counted. The number of tokens in each message does\nnot affect cost.",
        "Note",
        "The above charges cover AI costs for text-to-SQL. Additional warehouse costs apply if you execute the SQL generated by Cortex Analyst.",
        "Cortex Analyst is powered by machine learning technology, including Meta\u2019s Llama 3 and Mistral Large models.\nThe foundation Llama 3 models are licensed under the Llama 3\nCommunity License and Copyright (c) Meta Platforms, Inc. All Rights Reserved. Your use of this feature is subject to\nMeta\u2019s Acceptable Use Policy.",
        "The data classification of inputs and outputs are as set forth in the following table.",
        "Input data classification",
        "Output data classification",
        "Designation",
        "Usage Data",
        "Usage Data",
        "Preview AI Features [1]",
        "Represents the defined term used in the AI Terms and Acceptable Use Policy.",
        "For additional information, refer to Snowflake AI and ML.",
        "Was this page helpful?",
        "On this page",
        "Related content"
    ]
}