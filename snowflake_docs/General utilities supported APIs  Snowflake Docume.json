{
    "url": "https://docs.snowflake.com/en/developer-guide/snowpark/reference/python/1.26.0/modin/supported/general_supported",
    "title": "General utilities supported APIs | Snowflake Documentation",
    "paragraphs": [
        "The following table is structured as follows: The first column contains the method name.\nThe second column is a flag for whether or not there is an implementation in Snowpark for\nthe method in the left column.",
        "Note",
        "Y stands for yes, i.e., supports distributed implementation, N stands for no and API simply errors out,\nP stands for partial (meaning some parameters may not be supported yet), and D stands for defaults to single\nnode pandas execution via UDF/Sproc.",
        "Data manipulations",
        "Method",
        "Snowpark implemented? (Y/N/P/D)",
        "Missing parameters",
        "Notes for current implementation",
        "concat",
        "P",
        "levels is not supported,\ncopy is ignored",
        "crosstab",
        "P",
        "N if aggfunc is not one of\n\u201ccount\u201d, \u201cmean\u201d, \u201cmin\u201d, \u201cmax\u201d, or \u201csum\u201d, or\nmargins is True, normalize is \u201call\u201d or True,\nand values is passed.",
        "cut",
        "P",
        "retbins, labels",
        "N if retbins=True``or ``labels!=False",
        "__dataframe__",
        "P",
        "N for columns of type Timedelta and columns\ncontaining list objects",
        "factorize",
        "N",
        "from_dummies",
        "N",
        "get_dummies",
        "P",
        "sparse is ignored",
        "Y if params dummy_na, drop_first\nand dtype are default, otherwise N",
        "json_normalize",
        "Y",
        "lreshape",
        "N",
        "melt",
        "P",
        "col_level, ignore_index",
        "N if df.columns is a MultiIndex",
        "merge",
        "P",
        "validate",
        "N if param validate is given",
        "merge_asof",
        "P",
        "suffixes, tolerance",
        "N if param direction is nearest",
        "merge_ordered",
        "N",
        "pivot",
        "P",
        "See pivot_table",
        "pivot_table",
        "P",
        "observed, margins,\nsort",
        "N if index, columns, or values is\nnot str; or MultiIndex; or any argfunc is not\n\u201ccount\u201d, \u201cmean\u201d, \u201cmin\u201d, \u201cmax\u201d, or \u201csum\u201d",
        "qcut",
        "P",
        "N if labels!=False or retbins=True.",
        "read_pickle",
        "Y",
        "Uses native pandas for reading.",
        "read_csv",
        "P",
        "Reads both local and staged file(s) into a Snowpark\npandas DataFrame. Note, the order of rows in the\nmay differ from the order of rows in the original\nfile(s) if using staged csvs.",
        "Local files are parsed with native pandas and thus\nsupport most of the parameters supported by pandas\nitself. The usecols and names parameter are\napplied after creating a temp table in snowflake.",
        "Previously staged files will use the Snowflake\nCOPY FROM parser and schema inference. If you\nneed to use staged files often, it is recommended\nthat you upload these as parquet files to improve\nperformance. You can force the use of the Snowflake\nparser with engine=snowflake",
        "read_excel",
        "Y",
        "Uses native pandas to read excel files, using the\nengine specified by the pandas. You will need to\nseparately install a supported excel reader such\nas openpyxl. Please refer to the native pandas\nread excel documentation for more details.",
        "read_json",
        "P",
        "orient, typ, dtype,\nconvert_axes, lines,\nconvert_dates, date_unit,\nkeep_default_dates,\nencoding_errors, nrows,\nand chunksize will raise\nan error.\nprecise_float, engine,\ndtype_backend, and\nstorage_options are ignored.",
        "P:\n- if ndjson files are passed\n- Supported parameters are compression and\nencoding",
        "read_html",
        "Y",
        "Uses native pandas for reading.",
        "read_xml",
        "Y",
        "Uses native pandas for reading.",
        "read_parquet",
        "P",
        "use_nullable_dtypes,\nfilesystem, and filters\nwill raise an error if used.\nengine, storage_options,\ndtype_backend, and\n**kwargs are ignored.",
        "Supported parameter(s) are: columns",
        "read_snowflake",
        "Y",
        "Reading from tables as well as SELECT SQL Queries\nsupported, but ordering is not guaranteed for\nSQL Queries that contain ORDER BY clauses. More\ncomplex queries, including CTEs and CTEs with\nanonymous stored procedures are also supported.\nObtaining results from stored procedures is also\nsupported via CALL queries.",
        "read_sas",
        "Y",
        "Uses native pandas to read sas files.",
        "read_table",
        "N",
        "to_pandas",
        "Y",
        "to_snowflake",
        "Y",
        "**kwargs are currently\nignored",
        "to_snowpark",
        "Y",
        "Convert the Snowpark pandas DataFrame or Series to\na Snowpark DataFrame. Once converted to a Snowpark\nDataFrame, no ordering information will be\npreserved.",
        "unique",
        "Y",
        "wide_to_long",
        "N",
        "Top-level dealing with missing data",
        "Method",
        "Snowpark implemented? (Y/N/P/D)",
        "Notes for current implementation",
        "isna",
        "Y",
        "isnull",
        "Y",
        "notna",
        "Y",
        "notnull",
        "Y",
        "Top-level dealing with numeric data",
        "Method",
        "Snowpark implemented? (Y/N/P/D)",
        "Missing parameters",
        "Notes for current implementation",
        "to_numeric",
        "P",
        "downcast is ignored",
        "N if error == \"ignore\"",
        "Top-level dealing with datetime-like data",
        "Method",
        "Snowpark implemented? (Y/N/P/D)",
        "Missing parameters",
        "Notes for current implementation",
        "bdate_range",
        "P",
        "N for custom frequencies",
        "date_range",
        "P",
        "N for custom frequencies",
        "infer_freq",
        "N",
        "period_range",
        "N",
        "timedelta_range",
        "N",
        "to_datetime",
        "P",
        "cache is ignored",
        "N:\n- if format is None or not supported in\nSnowflake\n- or if params exact, infer_datetime_format\nis given\n- or origin == \"julian\"\n- or arg is DataFrame and data type is not int\n- or arg is Series and data type is string",
        "to_timedelta",
        "P",
        "errors",
        "N if errors is given or converting from\nstring type",
        "Top-level dealing with Interval data",
        "Method",
        "Snowpark implemented? (Y/N/P/D)",
        "Notes for current implementation",
        "interval_range",
        "N",
        "Top-level evaluation",
        "Method",
        "Snowpark implemented? (Y/N/P/D)",
        "Notes for current implementation",
        "eval",
        "N",
        "Datetime formats",
        "Method",
        "Snowpark implemented? (Y/N/P/D)",
        "Notes for current implementation",
        "tseries.api.guess_datetime_format",
        "N",
        "Hashing",
        "Method",
        "Snowpark implemented? (Y/N/P/D)",
        "Notes for current implementation",
        "util.hash_array",
        "N",
        "util.hash_pandas_object",
        "N",
        "Importing from other DataFrame libraries",
        "Method",
        "Snowpark implemented? (Y/N/P/D)",
        "Notes for current implementation",
        "api.interchange.from_dataframe",
        "N",
        "Was this page helpful?"
    ]
}