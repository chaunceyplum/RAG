{
    "url": "https://docs.snowflake.com/en/developer-guide/udf/python/udf-python-packages.html#local-development-and-testing",
    "title": "Using third-party packages | Snowflake Documentation",
    "paragraphs": [
        "Stages can be used to import third-party packages. You can also specify Anaconda packages to install when you create Python UDFs.",
        "Snowflake stages can be used to import packages. You can bring in any Python code that follows guidelines defined in General limitations.\nFor more information, see Creating a Python UDF with code uploaded from a stage.",
        "You can only upload pure Python packages or packages with native code through a Snowflake stage. If your uploaded package has dependency on x86 CPU architecture, then you must use Snowpark-optimized warehouses and  use the RESOURCE_CONSTRAINT warehouse property, with CPU architecture x86.",
        "As an example, you can use the following SQL, which creates a warehouse named so_warehouse that has x86 CPU architecture:",
        "To install a package with native code via importing from Stage, use the following example:",
        "For convenience, a number of popular open source third-party Python packages that are built and provided by Anaconda are made available\nto use out of the box inside Snowflake virtual warehouses. There is no additional cost for such use of the Anaconda packages apart from\nSnowflake\u2019s standard consumption-based pricing. With the exception of Snowflake Notebooks, Anaconda packages are currently not eligible for\nuse within Snowpark Container Services (SPCS). To use Python packages in a container image for SPCS, you can install these packages from\nPyPi using pip.",
        "To view the list of third-party packages from Anaconda, see the Anaconda Snowflake channel.",
        "To request the addition of new packages, go to the Snowflake Ideas page in the Snowflake Community. Select the\nPython Packages & Libraries category and check if someone has already submitted a request. If so, vote on it. Otherwise, click New Idea\nand submit your suggestion.",
        "Before you start using the packages provided by Anaconda inside Snowflake, you must acknowledge\nthe External Offerings Terms.",
        "Note",
        "You must use the ORGADMIN role to accept the terms. You only need to accept the\nExternal Offerings Terms once for your Snowflake account. If you do not have\naccess to the ORGADMIN role, see Enabling the ORGADMIN role in an account.",
        "Sign in to Snowsight.",
        "Select Admin \u00bb Billing & Terms.",
        "In the Anaconda section, select Enable.",
        "In the Anaconda Packages dialog, click the link to review the External Offerings Terms page.",
        "If you agree to the terms, select Acknowledge & Continue.",
        "If you encounter an error when attempting to accept the External Offerings Terms,\nit may be due to missing information in your user profile, such as a first name, last name, or email address. If you have administrator\nprivileges, see Add user details to your user profile to update your profile using Snowsight. Otherwise, contact an\nadministrator to update your account.",
        "You can display all packages available and their version information by querying the PACKAGES view in the Information Schema.",
        "To display version information about a specific package, for example numpy, use this command:",
        "Note",
        "Some packages in the Anaconda Snowflake channel are not intended for use inside Snowflake UDFs because UDFs are executed within a restricted engine.\nFor more information, see Following good security practices.",
        "When queries that call Python UDFs are executed inside a Snowflake warehouse, Anaconda packages are installed seamlessly and cached on the virtual warehouse on your behalf.",
        "You can display a list of the packages and modules a UDF or UDTF is using by executing the DESCRIBE FUNCTION command.\nExecuting the DESCRIBE FUNCTION command for a UDF whose handler is implemented in Python returns the values of several properties, including a list of imported modules and packages,\nas well as installed packages, the function signature, and its return type.",
        "When specifying the identifier for the UDF, be sure to include function parameter types, if any.",
        "For an example of how to use an imported Anaconda package in a Python UDF,\nrefer to Importing a package in an in-line handler.",
        "You can use a packages policy to set allowlists and blocklists for third-party Python packages from Anaconda at the account level.\nThis lets you meet stricter auditing and security requirements and gives you more fine-grained control over which packages are available or blocked in your environment.\nFor more information, see Packages policies.",
        "For more efficient resource management, newly provisioned virtual warehouses do not preinstall Anaconda packages.\nInstead, Anaconda packages are installed on-demand the first time a UDF is used.\nThe packages are cached for future UDF execution on the same warehouse. The cache is dropped when the warehouse is suspended.\nThis may result in slower performance the first time a UDF is used or after the warehouse is resumed.\nThe additional latency could be approximately 30 seconds.",
        "To help you create a conda environment on your local machine for development and testing, Anaconda has\ncreated a Snowflake channel which mirrors a subset of the packages and versions that are supported in\nthe Snowflake Python UDF environment.\nYou may use the Snowflake conda channel for local testing and development at no cost under the Supplemental Embedded Software\nTerms to Anaconda\u2019s Terms of Service.",
        "For example, to create a new conda environment locally using the Snowflake channel, type something like\nthis on the command line:",
        "Note that because of platform differences, your local conda environment may not be exactly the same as\nthe server environment.",
        "Within the create function statement, the package specification (for example, packages = ('numpy','pandas')) should\nonly specify the top-level packages that the UDF is using directly.\nAnaconda performs dependency management of packages and will install the required dependencies automatically. Because of this,\nyou should not specify dependency packages.",
        "Anaconda will install the most up-to-date version of the package and its dependencies if you don\u2019t specify a package version.\nGenerally, it isn\u2019t necessary to specify a particular package version.\nNote that version resolution is performed once, when the UDF is created using the create function command.\nAfter that, the resulting version resolution is frozen and the same set of packages will be used when this particular UDF executes.",
        "For an example of how to use the package specification within the create function statement, see Importing a package in an in-line handler.",
        "Some data science frameworks, such as Scikit-learn and TensorFlow, might be slow when doing single-row ML prediction.\nTo improve performance, do batch prediction instead of single-row prediction.\nTo do this, you can use vectorized Python UDFs, with which you can define Python functions that receive input rows in batches, on which machine\nlearning or data science libraries are optimized to operate. For more information, see Vectorized Python UDFs.",
        "Some data science libraries, such as NLTK, Keras,\nand spaCy provide functionality to download additional corpora, data, or models on demand.",
        "However, on-demand downloading does not work with Python UDFs due to Snowflake security constraints, which disable some\ncapabilities, such as network access and writing to files.",
        "To work around this issue, download the data to your local environment and then provide it\nto the UDF via a Snowflake stage.",
        "When using XGBoost in UDF or UDTF for parallel prediction or training, the concurrency for each XGBoost instance should\nbe set to 1. This ensures that XGBoost is configured for optimal performance when executing in\nthe Snowflake environment.",
        "Examples:",
        "When using Tensorflow/Keras for prediction, use Model.predict_on_batch and\nnot Model.predict.",
        "Example:",
        "Was this page helpful?",
        "On this page"
    ]
}