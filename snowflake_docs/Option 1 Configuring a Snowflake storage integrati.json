{
    "url": "https://docs.snowflake.com/en/user-guide/data-load-s3-config-storage-integration",
    "title": "Option 1: Configuring a Snowflake storage integration to access Amazon S3 | Snowflake Documentation",
    "paragraphs": [
        "This topic describes how to use storage integrations to allow Snowflake to read data from and write data to an Amazon S3 bucket referenced in an external (i.e. S3) stage. Integrations are named, first-class Snowflake objects that avoid the need for passing explicit cloud provider credentials such as secret keys or access tokens. Integration objects store an AWS identity and access management (IAM) user ID. An administrator in your organization grants the integration IAM user permissions in the AWS account.",
        "An integration can also list buckets (and optional paths) that limit the locations users can specify when creating external stages that use the integration.",
        "Note",
        "Completing the instructions in this section requires permissions in AWS to create and manage IAM policies and roles. If you are not an\nAWS administrator, ask your AWS administrator to perform these tasks.",
        "Access to S3 storage in government regions using a storage integration is limited to Snowflake accounts\nhosted on AWS in the same government region.",
        "Confirm that Snowflake supports the AWS region that your storage is hosted in. For more information, see\nSupported Cloud Regions.",
        "The following diagram shows the integration flow for a S3 stage:",
        "An external (i.e. S3) stage references a storage integration object in its definition.",
        "Snowflake automatically associates the storage integration with a S3 IAM user created for your account. Snowflake creates a single IAM user that is referenced by all S3 storage integrations in your Snowflake account.",
        "An AWS administrator in your organization grants permissions to the IAM user to access the bucket referenced in the stage definition. Note that many external stage objects can reference different buckets and paths and use the same storage integration for authentication.",
        "When a user loads or unloads data from or to a stage, Snowflake verifies the permissions granted to the IAM user on the bucket before allowing or denying access.",
        "This section describes how to configure a Snowflake storage integration object to delegate authentication responsibility for cloud storage\nto a Snowflake identity and access management (IAM) entity.",
        "Snowflake requires the following permissions on an S3 bucket and folder to be able to access files in the folder (and sub-folders):",
        "s3:GetBucketLocation",
        "s3:GetObject",
        "s3:GetObjectVersion",
        "s3:ListBucket",
        "Note",
        "The following additional permissions are required to perform additional SQL actions:",
        "Permission",
        "SQL Action",
        "s3:PutObject",
        "Unload files to the bucket.",
        "s3:DeleteObject",
        "Either automatically purge files from the stage after a successful load or execute REMOVE statements to manually remove files.",
        "As a best practice, Snowflake recommends creating an IAM policy for Snowflake access to the S3 bucket. You can then attach the policy to the role and use the security credentials generated by AWS for the role to access files in the bucket.",
        "The following step-by-step instructions describe how to configure access permissions for Snowflake in your AWS Management Console so that you can use an\nS3 bucket to load and unload data:",
        "Log into the AWS Management Console.",
        "From the home dashboard, search for and select IAM.",
        "From the left-hand navigation pane, select Account settings.",
        "Under Security Token Service (STS) in the Endpoints list, find the Snowflake\nregion where your account is located. If the STS status is inactive,\nmove the toggle to Active.",
        "From the left-hand navigation pane, select Policies.",
        "Select Create Policy.",
        "For Policy editor, select JSON.",
        "Add a policy document that will allow Snowflake to access the S3 bucket and folder.",
        "The following policy (in JSON format) provides Snowflake with the required permissions to load or unload data using a single bucket and folder path. You can also purge data files using the PURGE copy option.",
        "Copy and paste the text into the policy editor:",
        "Note",
        "Make sure to replace bucket and prefix with your actual bucket name and folder path prefix.",
        "The Amazon Resource Names (ARN) for buckets in\ngovernment regions have a arn:aws-us-gov:s3::: prefix.",
        "The ARN for buckets in public AWS regions in China have a arn:aws-cn:s3::: prefix.",
        "Note",
        "Setting the \"s3:prefix\": condition to either [\"*\"] or [\"<path>/*\"] grants access to all prefixes in the\nspecified bucket or path in the bucket, respectively.",
        "Note that AWS policies support a variety of different security use cases.",
        "The following policy provides Snowflake with the required permissions to load data from a single read-only bucket and folder\npath. The policy includes the s3:GetBucketLocation, s3:GetObject, s3:GetObjectVersion, and\ns3:ListBucket permissions:",
        "Alternative policy: Load from a read-only S3 bucket",
        "Select Next.",
        "Enter a Policy name (for example, snowflake_access) and an optional Description.",
        "Select Create policy.",
        "To configure access permissions for Snowflake in the AWS Management Console, do the following:",
        "From the left-hand navigation pane in the Identity and Access Management (IAM) Dashboard, select Roles.",
        "Select Create role.",
        "Select AWS account as the trusted entity type.",
        "Select Another AWS account",
        "In the Account ID field, enter your own AWS account ID temporarily. Later, you modify the trust relationship and grant\naccess to Snowflake.",
        "Select the Require external ID option. An external ID is used to grant access to your AWS resources\n(such as S3 buckets) to a third party like Snowflake.",
        "Enter a placeholder ID such as 0000.\nIn a later step, you will modify the trust relationship for your IAM role and specify the external ID for your storage integration.",
        "Select Next.",
        "Select the policy you created in Step 1: Configure Access Permissions for the S3 Bucket (in this topic).",
        "Select Next.",
        "Enter a name and description for the role, then select Create role.",
        "You have now created an IAM policy for a bucket, created an IAM role, and attached the policy to the role.",
        "On the role summary page, locate and record the Role ARN value. In the next step, you will create a Snowflake integration that\nreferences this role.",
        "Note",
        "Snowflake caches the temporary credentials for a period that cannot exceed the 60 minute expiration time. If you revoke access from\nSnowflake, users might be able to list files and access data from the cloud storage location until the cache expires.",
        "Create a storage integration using the CREATE STORAGE INTEGRATION command. A storage integration is a Snowflake\nobject that stores a generated identity and access management (IAM) user for your S3 cloud storage, along with an optional set of allowed\nor blocked storage locations (i.e. buckets). Cloud provider administrators in your organization grant permissions on the storage locations\nto the generated user. This option allows users to avoid supplying credentials when creating stages or loading data.",
        "A single storage integration can support multiple external (i.e. S3) stages. The URL in the stage definition must align with the S3\nbuckets (and optional paths) specified for the STORAGE_ALLOWED_LOCATIONS parameter.",
        "Note",
        "Only account administrators (users with the ACCOUNTADMIN role) or a role with the global CREATE INTEGRATION privilege can execute this\nSQL command.",
        "Where:",
        "integration_name is the name of the new integration.",
        "iam_role is the Amazon Resource Name (ARN) of the role you created in Step 2: Create the IAM Role in AWS (in this topic).",
        "protocol is one of the following:",
        "s3 refers to S3 storage in public AWS regions outside of China.",
        "s3china refers to S3 storage in public AWS regions in China.",
        "s3gov refers to S3 storage in government regions.",
        "bucket is the name of a S3 bucket that stores your data files (e.g. mybucket). The required STORAGE_ALLOWED_LOCATIONS\nparameter and optional STORAGE_BLOCKED_LOCATIONS parameter restrict or block access to these buckets, respectively, when stages that\nreference this integration are created or modified.",
        "path is an optional path that can be used to provide granular control over objects in the bucket.",
        "The following example creates an integration that allows access to all buckets in the account but blocks access to the defined sensitivedata folders.",
        "Additional external stages that also use this integration can reference the allowed buckets and paths:",
        "Note",
        "Optionally, use the STORAGE_AWS_EXTERNAL_ID parameter to specify\nyour own external ID. You might choose this option\nto use the same external ID across multiple external volumes and/or storage integrations.",
        "To retrieve the ARN for the IAM user that was created automatically for your Snowflake account, use the DESCRIBE INTEGRATION.",
        "Where:",
        "integration_name is the name of the integration you created in Step 3: Create a Cloud Storage Integration in Snowflake\n(in this topic).",
        "For example:",
        "Record the values for the following properties:",
        "Property",
        "Description",
        "STORAGE_AWS_IAM_USER_ARN",
        "The AWS IAM user created for your Snowflake account; for example, arn:aws:iam::123456789001:user/abc1-b-self1234. Snowflake provisions a single IAM user for your entire Snowflake account. All S3 storage integrations in your account use that IAM user.",
        "STORAGE_AWS_EXTERNAL_ID",
        "The external ID that Snowflake uses to establish a trust relationship with AWS. If you didn\u2019t specify an external ID\n(STORAGE_AWS_EXTERNAL_ID) when you created the storage integration, Snowflake generates an ID for you to use.",
        "You provide these values in the next section.",
        "The following step-by-step instructions describe how to configure IAM access permissions for Snowflake in your AWS Management Console so that you can use a S3 bucket to load and unload data:",
        "Log in to the AWS Management Console.",
        "Select IAM.",
        "From the left-hand navigation pane, select Roles.",
        "Select the role you created in Step 2: Create the IAM Role in AWS (in this topic).",
        "Select the Trust relationships tab.",
        "Select Edit trust policy.",
        "Modify the policy document with the DESC STORAGE INTEGRATION output values you recorded in\nStep 4: Retrieve the AWS IAM User for your Snowflake Account (in this topic):",
        "Policy document for IAM role",
        "Where:",
        "snowflake_user_arn is the STORAGE_AWS_IAM_USER_ARN value you recorded.",
        "snowflake_external_id is the STORAGE_AWS_EXTERNAL_ID value you recorded.",
        "In this example, the snowflake_external_id value is MYACCOUNT_SFCRole=2_a123456/s0aBCDEfGHIJklmNoPq=.",
        "Note",
        "For security reasons, if you create a new storage integration (or recreate an existing storage integration using the CREATE OR\nREPLACE STORAGE INTEGRATION syntax) without specifying an external ID, the new integration has a different external ID and\ncan\u2019t resolve the trust relationship unless you update the trust policy.",
        "Select Update policy to save your changes.",
        "Note",
        "Snowflake caches the temporary credentials for a period that cannot exceed the 60 minute expiration time. If you revoke access from\nSnowflake, users might be able to list files and load data from the cloud storage location until the cache expires.",
        "Note",
        "You can use the SYSTEM$VALIDATE_STORAGE_INTEGRATION\nfunction to validate the configuration for your storage integration .",
        "Create an external (i.e. S3) stage that references the storage integration you created in Step 3: Create a Cloud Storage Integration in Snowflake (in this topic).",
        "Note",
        "Creating a stage that uses a storage integration requires a role that has the CREATE STAGE privilege for the schema as well as the USAGE privilege on the storage integration. For example:",
        "Create the stage using the CREATE STAGE command.",
        "For example, set mydb.public as the current database and schema for the user session, and then create a stage named my_s3_stage. In this example, the stage references the S3 bucket and path mybucket1/path1, which are supported by the integration. The stage also references a named file format object called my_csv_format:",
        "Note",
        "The stage owner (i.e. the role with the OWNERSHIP privilege on the stage) must have the USAGE privilege on the storage integration.",
        "Append a forward slash (/) to the URL value to filter to the specified folder path. If the forward slash is omitted, all files and\nfolders starting with the prefix for the specified path are included.",
        "Note that the forward slash is required to access and retrieve unstructured data files in the stage.",
        "To load or unload data from or to a stage that uses an integration, a role must have the USAGE privilege on the stage. It is not necessary to also have the USAGE privilege on the storage integration.",
        "The STORAGE_INTEGRATION parameter is handled separately from other stage parameters, such as FILE_FORMAT. Support for these other parameters is the same regardless of the integration used to access your S3 bucket.",
        "Next: AWS data file encryption",
        "Was this page helpful?",
        "On this page",
        "Related content"
    ]
}