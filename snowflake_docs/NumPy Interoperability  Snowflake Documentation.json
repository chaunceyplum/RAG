{
    "url": "https://docs.snowflake.com/en/developer-guide/snowpark/reference/python/1.26.0/modin/numpy#positional-operations",
    "title": "NumPy Interoperability | Snowflake Documentation",
    "paragraphs": [
        "Snowpark pandas provides limited interoperability with NumPy functions through the NumPy\nNEP18 and NEP13 specifications defined by __array_ufunc__ and __array_function__.\nA discrete number of NumPy APIs are translated to distributed snowpark pandas functions.\nNumPy ufuncs called with Snowpark pandas arguments will ignore kwargs.",
        "NumPy method",
        "Notes for current implementation",
        "np.where",
        "Mapped to np.where(cond, x, y) to x.where(cond, y)\ncond, x, and y should have the same shapes or be\nscalars. The result is always a Snowpark pandas\nDataFrame.",
        "Since this function maps to df.where the\ncolumn and index labels are considered, as opposed\nstrict positional indexing in NumPy.",
        "cond, x, and y can either be all non-scalars or a\nmix of scalars and non-scalars, such that\nnon-scalars have the same shape. (If cond, x, and\ny are all scalars, NumPy will not call the\ndispatcher at all, and the normal NumPy behavior\nwill occur.)",
        "np.full_like",
        "columns=range(width))",
        "np.may_share_memory",
        "Returns False",
        "np.abs",
        "Mapped to df.abs()",
        "np.absolute",
        "Mapped to df.abs()",
        "np.add",
        "Mapped to df.__add__(df2)",
        "np.subtract",
        "Mapped to df.__sub__(df2)",
        "np.multiply",
        "Mapped to df.__mul__(df2)",
        "np.divide",
        "Mapped to df.__truediv__(df2)",
        "np.exp",
        "Mapped to df.apply(snowpark.functions.exp)",
        "np.true_divide",
        "Mapped to df.__truediv__(df2)",
        "np.float_power",
        "Mapped to df.__pow__(df2)",
        "np.log",
        "Mapped to df.apply(snowpark.functions.ln)",
        "np.log2",
        "Mapped to df.apply(snowpark.functions.log, base=2)",
        "np.log10",
        "Mapped to df.apply(snowpark.functions.log, base=10)",
        "np.mod",
        "Mapped to df.__mod__(df2)",
        "np.negative",
        "Mapped to -df",
        "np.positive",
        "Mapped to df",
        "np.trunc",
        "Mapped to df.apply(snowpark.functions.trunc)",
        "np.sqrt",
        "Mapped to df.apply(snowpark.functions.sqrt)",
        "np.ceil",
        "Mapped to df.apply(snowpark.functions.ceil)",
        "np.floor",
        "Mapped to df.apply(snowpark.functions.floor)",
        "np.remainder",
        "Mapped to df.__mod__(df2)",
        "np.greater",
        "Mapped to df > df2",
        "np.greater_equal",
        "Mapped to df >= df2",
        "np.less",
        "Mapped to df < df2",
        "np.less_equal",
        "Mapped to df <= df2",
        "np.not_equal",
        "Mapped to df != df2",
        "np.equal",
        "Mapped to df == df2",
        "np.logical_and",
        "Mapped to df.__and__(df2)",
        "np.logical_or",
        "Mapped to df.__or__(df2)",
        "np.logical_xor",
        "Mapped to df.__xor__(df2)",
        "np.logical_not",
        "Mapped to ~df.astype(bool)",
        "np.sin",
        "Mapped to df.apply(snowpark.functions.sin)",
        "np.cos",
        "Mapped to df.apply(snowpark.functions.cos)",
        "np.tan",
        "Mapped to df.apply(snowpark.functions.tan)",
        "np.sinh",
        "Mapped to df.apply(snowpark.functions.sinh)",
        "np.cosh",
        "Mapped to df.apply(snowpark.functions.cosh)",
        "np.tanh",
        "Mapped to df.apply(snowpark.functions.tanh)",
        "NumPy differs from pandas and Snowflake pandas in several key respects. It is\nimportant to understand that the interoperability provided is to support\ncommon pandas use-cases, rather than matrix or linear algebra operations. NumPy\nfunctions are mapped, with some transformation, to their pandas analogues.",
        "NEP18 does not specify the return value when implementing a function like np.where,\nbut they suggest that the return value should match the input types. We follow\nthat suggestion here and return a Snowpark pandas DataFrame.",
        "NumPy will \u201cbroadcast\u201d all arguments into the same array shape so operations\ncan be vectorized on the CPU. Snowpark pandas should not do this because all\nexecution runs within Snowflake. All input DataFrames or Series should be of\nthe same shape and will not be broadcast. Scalar values can also be used as\nan input.",
        "NumPy always performs positional operations on input datatypes, assuming they\nare similarly shaped and meaningful arrays. Pandas can have DataFrames which\nrepresent the same data but with different column ordering. Even when a numpy\nmethod is called on a Snow pandas DataFrame we continue to consider the labels\nwhile performing the operation.",
        "Was this page helpful?",
        "On this page"
    ]
}