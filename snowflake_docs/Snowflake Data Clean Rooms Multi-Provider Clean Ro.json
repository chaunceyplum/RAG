{
    "url": "https://docs.snowflake.com/en/user-guide/cleanrooms/demo-flows/multiprovider",
    "title": "Snowflake Data Clean Rooms: Multi-Provider Clean Rooms | Snowflake Documentation",
    "paragraphs": [
        "Feature \u2014 Generally Available",
        "Not available in government regions.",
        "This topic provides an example of running an analysis across a cluster of clean rooms from multiple providers. It demonstrates how a query can access data across clean rooms while maintaining the security guarantees of each clean room. It also demonstrates how the consumer can define the template used to run the analysis, which is a common use case for multi-provider clean rooms.",
        "In a multi-provider analysis, data is used from each clean room in a completely secure manner. Snowflake Data Clean Rooms ensures compliance with every individual clean room security policy, while also attesting that all SQL run against the data is exactly what each clean room participant expects.",
        "In many cases, the consumer executing a multi-provider analysis wants to be able to define the template for the analysis rather than use a template defined by the providers. This allows consumers to control how they gain insights when analyzing data from multiple parties. For more information about consumer-defined templates, see Using the developer API to add consumer-defined templates.",
        "Note",
        "Multi-provider clean room analyses are not allowed in clean rooms which have been shared across regions.",
        "The multi-provider analysis example includes the following steps:",
        "Provider:",
        "a. Create two clean rooms, which simulates two different providers.",
        "b. Share the clean rooms with the same consumer.",
        "Consumer:",
        "a. Install both provider clean rooms.",
        "b. Send requests to add a consumer-defined template to the clean rooms.",
        "Provider:",
        "a. Approve the consumer\u2019s requests to add a consumer-defined template.",
        "b. Set column policies for the consumer-defined template.",
        "Consumer:",
        "a. Raise multi-provider analysis request.",
        "Provider:",
        "a. Enable the clean rooms for multi-provider analysis.",
        "b. Approve multi-provider analysis requests from the consumer.",
        "Consumer",
        "a. Execute the analysis across the clean room cluster.",
        "You need two separate Snowflake accounts to complete this example. Use the first account to execute the provider\u2019s commands, then switch to the second account to execute the consumer\u2019s commands.",
        "Use a Snowflake worksheet in the provider account to execute the commands in this section.",
        "Before using the Developer APIs, you need to assume the SAMOOHA_APP_ROLE role and specify the warehouse used to execute the APIs. If you don\u2019t have the SAMOOHA_APP_ROLE role, contact your account administrator.",
        "Execute the following commands to set up your environment:",
        "Create a name for the clean room. Enter a new clean room name to avoid colliding with existing clean room names. Note that clean room names can only be alphanumeric. Clean room names cannot contain special characters other than spaces and underscores.",
        "First, execute the following commands to set a clean room name for each of our example clean rooms:",
        "If the clean room name set above already exists as an existing clean room, this process will fail.",
        "This procedure takes approximately 45 seconds to run.",
        "The second argument to provider.cleanroom_init is the distribution of the clean room. This can either be INTERNAL or EXTERNAL. For testing purposes, if you are sharing the clean room to an account in the same organization, you can use INTERNAL to bypass the automated security scan which must take place before an application package is released to collaborators. However, if you are sharing this clean room to an account in a different organization, you must use an EXTERNAL clean room distribution.",
        "In order to view the status of the security scan, execute the following commands:",
        "Once you have created your clean room, you must set its release directive before it can be shared with any collaborator. However, if your distribution was set to EXTERNAL, you must wait for the security scan to complete before setting the release directive. You can continue running the remainder of the steps while the scan runs and return here before the provider.create_or_update_cleanroom_listing step.",
        "In order to set the release directive, call:",
        "You can link tables into the clean room by specifying fully qualified table names (<Database>.<Schema>.<Table>) as an array. For example, to link a table into both clean rooms, execute the following commands:",
        "Note",
        "If this step doesn\u2019t work even though your table exists, the database that contains the table might not be registered. To register the database, execute the following commands as a user with the ACCOUNTADMIN role.",
        "You can verify that the datasets were linked to the clean room by executing the following commands.",
        "To determine which columns to use as the join policy, you can look at your dataset to determine the PII columns. For example, to see the top 10 rows of a table, execute the following query:",
        "Next, specify which columns the consumer is allowed to join on when running templates within the clean room. Execute the following commands on identity columns like email. If you set the join policy a second time, the previously set join policy is completely replaced by the new one.",
        "If you want to view the join policy that has been added to the clean room, execute the following commands:",
        "Finally, add a consumer to each clean room by adding their Snowflake account locator and account name. The Snowflake account name must be of the form <ORGANIZATION>.<ACCOUNT_NAME>.",
        "Multiple consumer accounts can be passed into the provider.add_consumers function as a comma separated string, or you can execute provider.add_consumers multiple times.",
        "Note",
        "Before executing the following commands, make sure you have set the release directive using provider.set_default_release_directive. You can see the latest available version and patches using:",
        "To share the clean rooms with a consumer, execute the following commands:",
        "If you want to view the consumers who have been added to the clean rooms, execute the following commands:",
        "You can view the clean rooms that have been recently created by executing the following command:",
        "You can more information about the clean rooms recently created by executing the following commands:",
        "Any clean room created can also be deleted. The following command drops the clean room entirely, so any consumers who previously had access to the clean room can no longer be able to use it.",
        "The first part of the provider flow is now finished. Switch to the consumer account to continue with consumer flow to install the clean rooms.",
        "You will then need to switch back to the provider side to enable multi-provider computation in your clean rooms.",
        "Use a Snowflake worksheet in the consumer account to execute the commands in this section.",
        "As a consumer, you can have multiple clean rooms shared with you. Before running a multi-provider analysis across them all, you need to install each one into your account and link the datasets you intend to use for analyses.",
        "Before using the Developer APIs, you need to assume the SAMOOHA_APP_ROLE role and specify the warehouse used to execute the APIs. If you don\u2019t have the SAMOOHA_APP_ROLE role, contact your account administrator.",
        "Execute the following commands to set up your environment:",
        "Before installing the clean rooms, assign a name for each clean room that the provider has shared with you.",
        "The following commands install the clean rooms in the consumer account:",
        "After the clean room has been installed, the provider has to finish setting up the clean room on their side before it is enabled for use. The below function allows you to check the status of the clean room. Once it has been enabled, you should be able to run the Run Analysis command below. It typically takes about 1 minute for the clean room to be enabled.",
        "After a clean room share has been installed, the list of clean rooms available can be viewed using the below command.",
        "Link datasets into the clean room to carry out secure computation with the provider\u2019s data.",
        "Note",
        "If this step doesn\u2019t work even though your table exists, the database that contains the table might not be registered. To register the database, execute the following commands as a user with the ACCOUNTADMIN role.",
        "If you want to view the datasets that you have added to the clean room, call the following procedure.",
        "The consumer running a multi-provider analysis is often in the best position to know how to extract value from the data from multiple parties. A consumer can send a request to clean room providers to include a consumer-defined template in the clean room so the consumer can use it to run analyses. For more information about adding consumer-defined templates to a clean room, see Adding Consumer-Defined Templates.",
        "Note",
        "Analyses in multi-provider clean rooms work by rendering all tables from other clean rooms, as well from the current clean room, into the source_tables argument in the template. However, during security validations and request approval, each clean room also receives just the tables relevant to them. Therefore, the template should be written generically without assuming a specific number of source_table arguments, which allows it to scale across one or more source_table inputs. You can use a Jinja for-loop to implement this.",
        "For this example, the consumer send the following requests. Each request includes the Jinja code that defines the template.",
        "The provider must approve the consumer\u2019s requests to include a consumer-defined template in the clean rooms.",
        "The provider uses the provider.list_template_requests command to list the requests, including obtaining the UUID of the new request. The provider then approves the requests by executing the provider.approve_template_request command. For more information about this process, see Adding Consumer-Defined Templates.",
        "For every table and template combination, set the columns that the consumer can use in an analysis, for example, the columns they can group on or aggregate. This gives flexibility so that the same table can allow different column selections depending on the underlying template. Wait until after you have added a template to set the column policy on a table.",
        "Note that the column policy is replace only, so if the function is called again, then the previously set column policy is completely replaced by the new one.",
        "Column policies should not be used on identity columns like email, HEM, or RampID because you don\u2019t want the consumer to be able to group by these columns. In the production environment, the Snowflake infers PII columns and blocks this operation, but this inference is not available in a sandbox environment. It should only be used on columns that you want the consumer to be able to aggregate and group by, for example, Status, Age Band, Region Code, or Days Active.",
        "For the \u201ccolumn_policy\u201d and \u201cjoin_policy\u201d to carry out checks on the consumer analysis requests, all column names MUST be referred to as  dimensions or measure_columns in the SQL Jinja template. Make sure you use these tags to refer to columns you want to be checked in custom SQL Jinja templates.",
        "To set the column policy for a template/table combination, execute the following commands:",
        "The next step is to raise requests for a multi-provider analysis across the set of clean rooms you have installed. This set of clean rooms is known as a clean room cluster. This process writes requests to each provider asking whether this multi-provider analysis can be approved and executed. These requests are asynchronously processed by the provider using either an automated or a manual flow. If an automated approval flow is used, request processing is done in about 2 minutes, and if approval is given by each clean room (after checking the request for compliance with the clean room\u2019s security policies), the flow can be executed.",
        "The multi-provider clean room request flow requires that the provider tables be specified under the source_table array argument. The tables need to start with the clean room name in which they exist. The overall form is <CLEANROOM_NAME>.<DB>.<SCHEMA>.<TABLE> . Consumer tables can be provided under the my_table array argument.",
        "This API first verifies the request with each clean room\u2019s security policies before raising the multi-provider analysis request to each clean room\u2019s provider. If these checks fail, this API will return the error message it encountered.",
        "To run the analysis, you need to pass in some parameters to the run_analysis function. This section shows you how to determine what parameters to pass in.",
        "Template names",
        "First, you can see the supported analysis templates by executing the following command:",
        "Before running an analysis with a template, you need to know what arguments to specify and what types are expected. For custom templates, you can execute the following command:",
        "This returns a large number of different SQL Jinja parameters. To parse the SQL Jinja template and extract the arguments that need to be specified in run_analysis into a list, execute the following command.",
        "Dataset names",
        "If you want to view the dataset names that have been added to the clean room by the provider, execute the following command. Note that you cannot view the data present in the datasets that have been added to the clean room by the provider.",
        "You can also see the tables you\u2019ve linked to the clean room by executing the following command:",
        "Dimension and measure columns",
        "While running the analysis, you might want to filter, group by and aggregate on certain columns. If you want to view the column policy that has been added to the clean room by the provider, execute the following command:",
        "Common errors",
        "If you are getting Not approved: unauthorized columns used error as a result of run analysis, try viewing the join policy and column policy set by the provider.",
        "It is also possible that you have exhausted your privacy budget, which prevents you from executing more queries. Your remaining privacy budget can be viewed using the following command. The budget resets daily, or the clean room provider can reset it manually.",
        "You can check if Differential Privacy has been enabled for your clean room using the following API:",
        "You are now switching back to the provider account to enable multi-provider analysis for the consumer and to process the requests raised.",
        "A consumer cannot successfully execute a multi-provider analysis until you enable the clean room for this purpose. When enabling the clean room for the consumer, you also specify which clean rooms can be included in the multi-provider analysis. The consumer cannot execute a multi-provider analysis that involves your clean room and the clean room of another provider unless you expressly approve the other provider\u2019s clean room.",
        "To allow a consumer to run a multi-provider analysis using a clean room from any other provider, specify an empty list when executing the following commands.",
        "Note",
        "This can only be called on consumers who have already installed the clean room.",
        "After multi-provider analysis has been enabled in each clean room, all multi-provider analysis requests raised against the clean rooms can be viewed using the following API:",
        "Request approval can happen in one of two ways:",
        "Automatically using a task that listens to incoming requests and triggers when needed.",
        "Manually by a user explicitly processing incoming multi-provider analysis requests.",
        "By default, approvals are manual and the task is created in a suspended state by the enable_multiprovider_computation API. This requires a user to manually process incoming requests. This can be done by executing the following commands:",
        "Note",
        "This API can either be made to operate on a request ID level by specifying a particular request ID from the output of view_multiprovider_requests API, or REQUEST_ID can be passed in as \u2018-1\u2019 to process all incoming requests.",
        "This process does not approve incoming requests, but rather passes them through a processing logic to verify if it can be approved based on factors such as the age of the request and whether the requested collaborators are in your list of approved collaborators you set during enable_multiprovider_computation.",
        "Once the request is processed, it is written to the samooha_cleanroom_${UUID}.admin.request_log_multiprovider table. You can see the list of requests and whether they have been approved or not through queries like the following:",
        "Previous requests that haven\u2019t been approved can also be overridden to APPROVE=True, or conversely access can be removed by setting APPROVE=False using the following queries. See the Security Considerations section below for more details on the <CONDITIONS>.",
        "If the automated approval flow is preferred over manual approvals, then the multi-provider analysis tasks need to be resumed by executing the following commands:",
        "Conversely, if the automated approval flow is currently engaged, it can be switched off by executing the following commands:",
        "Multi-provider analyses work through adding the hash of an approved query to a row access policy. The row access policy is usually created under the samooha_cleanroom_${UUID}.shared_schema schema, and the definition of the row access policy is:",
        "The row access policy works by finding approved requests in the samooha_cleanroom_${UUID}.admin.request_log_multiprovider table on your account for the specific consumer of your clean room, and checking that the hash of the current query running in their account matches the query that was approved.",
        "All security access to your data for multi-provider flows is gated through the approvals noted in this table (samooha_cleanroom_${UUID}.admin.request_log_multiprovider). You must manage it proactively to ensure only the queries you wish to have access to your data are allowed to run.",
        "Simple queries can be used to either approve or un-approve (that is, remove the approvals of) previously processed requests. For example, you can execute the following queries:",
        "As seen in the row access policy, access is given to the data depending on the query_hash. However, the query_hash can also depend on which clean room is randomly selected to execute the query, so the <CONDITIONS> passed into the query above to determine which requests to revoke access to/approve need to follow these best practices:",
        "If manually approving a request, try to be as specific as possible about the request by either filtering on request_id and/or cleanroom_names, requester_account and template_name.",
        "If revoking a previous approval for a query, revoke all requests where the query_hash matches, and also revoke all requests for that given requester_account and template_name and cleanroom_names (see example below).",
        "If a new request is not approved, it does not change the approval of previous requests. If you wish to revoke previous query access, you need to mark the corresponding requests with APPROVED=False in the samooha_cleanroom_${UUID}.admin.request_log_multiprovider table.",
        "If you change the set of allowed collaborators by running enable_multiprovider_computation again, previous requests are not revoked by default. You need to manage approvals by revoking access to previous collaborations by setting APPROVED=False in the samooha_cleanroom_${UUID}.admin.request_log_multiprovider table.",
        "An example of how to thoroughly revoke a particular collaboration\u2019s ability to make requests. Suppose there was a collaboration running on requester_account=ABC123 that you wanted to revoke. You can execute the following queries:",
        "The access for both the query hash and for that template in that clean room collaboration are revoked.",
        "Here are some sample queries that allow you to see how many queries have been raised by each requester account:",
        "After the request raised by the prepare_multiprovider_flow API has been approved, it can be executed using the following API across the clean room cluster. This execution happens by one clean room being randomly selected to execute the flow, and as long as both clean rooms have approved the request, the multi-provider analysis is allowed to proceed.",
        "Note also that once a request has been approved after the prepare_multiprovider_flow procedure, the execute_multiprovider_flow can be called as many times as needed without needing to call prepare_multiprovider_flow again. However, in order to run a different analysis or one across a different clean room cluster, the prepare_multiprovider_flow needs to be called again.",
        "Once the interoperability requests are written to each provider, the approval takes the form of request-specific customer templates that get added to the clean room and executed during the analysis. These set up the infrastructure required. You can view these templates being added in real-time by the request\u2019s approval process by executing the following commands.",
        "Was this page helpful?",
        "On this page",
        "Related content"
    ]
}