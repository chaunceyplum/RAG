{
    "url": "https://docs.snowflake.com/en/release-notes/2022-01",
    "title": "January 2022 | Snowflake Documentation",
    "paragraphs": [
        "The following new features, behavior changes, and updates (enhancements, fixes, etc.) have been introduced this month. If you have any\nquestions about these additions, please contact\nSnowflake Support.",
        "Important",
        "Each release may include updates that require the web interface to be refreshed.",
        "As a general practice, to ensure these updates do not impact your usage, we recommend refreshing the web interface after each Snowflake\nrelease has been deployed.",
        "With this release, Snowflake is pleased to announce the general availability of support for Java UDFs (user-defined functions) on AWS.",
        "Users can write custom functions in the Java programming language and call those as though they were built-in functions. Users can provide\nJava source code inline or bring their JAR files, including libraries.",
        "For more information, see Introduction to Java UDFs.",
        "With this release, we are pleased to announce the general availability of Snowpark on AWS.",
        "Snowpark is a new developer experience that provides an intuitive API for querying and processing data in a data pipeline. Using this\nlibrary, you can build applications that process data in Snowflake without moving data to the system where your application code runs.",
        "Snowpark has several features that distinguish it from other client libraries:",
        "The Snowpark API provides programming language constructs for building SQL statements.",
        "For example, the API provides a select method that you can use to specify the column names to return, rather than writing\n\u2018select column_name\u2019 as a string.",
        "Although you can still use a string to specify the SQL statement to execute, you benefit from features like intelligent code completion and type checking when you use the native language constructs provided by\nSnowpark.",
        "Snowpark operations are executed lazily on the server, which reduces the amount of data transferred between your client and the Snowflake\ndatabase.",
        "The core abstraction in Snowpark is the DataFrame, which represents a set of data and provides methods to operate on that data. In your\nclient code, you construct a DataFrame object and set it up to retrieve the data that you want to use (for example, the columns\ncontaining the data, the filter to apply to rows, etc.).",
        "The data isn\u2019t retrieved at the time when you construct the DataFrame object. Instead, when you are ready to retrieve the data, you can\nperform an action that evaluates the DataFrame objects and sends the corresponding SQL statements to the Snowflake database for\nexecution.",
        "You can create user-defined functions (UDFs) in your code, and Snowpark can push your code to the server, where the code can operate on\nthe data.",
        "You can write functions in the same language that you use to write your client code (for example, by using anonymous functions in Scala).\nTo use these functions to process data in the Snowflake database, you define and call user-defined functions (UDFs) in your custom code.",
        "Snowpark automatically pushes the custom code for UDFs to the Snowflake database. When you call the UDF in your client code, your custom\ncode is executed on the server (where the data is). You don\u2019t need to transfer the data to your client in order to execute the function\non the data.",
        "Snowpark is available for the Scala programming language.",
        "For more information, see Snowpark API.",
        "With this release, we are pleased to announce the general availability of support for unstructured data in Snowflake. This feature enables\nusers to access, load, govern, and share unstructured files of data types for which Snowflake has no native support, including some\nindustry-specific types. Support for unstructured files adds to the existing robust support for structured and semi-structured data.",
        "Support for unstructured data files is provided through the following functionality:",
        "File functions",
        "REST API for unstructured data support",
        "Directory tables",
        "With this release, we are pleased to announce a preview of Snowflake Scripting.",
        "Snowflake Scripting is an extension to Snowflake SQL that adds support for procedural logic. You can use Snowflake Scripting to write stored\nprocedures in SQL.",
        "For more information, see the Snowflake Scripting Developer Guide.",
        "With this release, we are pleased to announce a preview of error notifications for Snowpipe. When Snowpipe encounters errors while loading\ndata from a staged file, this feature triggers a notification that describes the errors using cloud messaging, enabling further analysis of\nthe data in the file.",
        "Note",
        "Currently, this feature is limited to Snowflake accounts hosted on Amazon Web Services (AWS). Pipe objects in an account can load\ndata from files in any supported cloud storage service; however, Snowpipe can only push error notifications to Amazon Simple Notification\nService.",
        "Support for Snowflake accounts hosted on Google Cloud or Microsoft Azure and respective cloud messaging services is planned.",
        "This feature supports calls to the Snowpipe REST API as well as automated (auto-ingest) Snowpipe using a cloud messaging service.",
        "Preview features are intended for evaluation and testing purposes, and are not recommended for use in production.",
        "With this release, Snowflake is pleased to announce the general availability of conditional columns (i.e. arguments) as an optional\nconfiguration to the masking policy signature. When using conditional columns in the masking policy signature, the first column and its data\ntype always specifies the column on which the masking policy expression operates (i.e. mask or unmask the data).",
        "These additional columns can be included in the masking policy expression to determine whether the data in the first column should be masked\nor unmasked. Using conditional columns in a masking policy signature allows masking policy administrators more freedom when creating policy\nconditions to mask or unmask data.",
        "For more information, see Understanding Column-level Security.",
        "With this release, Snowflake introduces the Copies Over Time dashboard, which shows a 365-day view of the copy history for bulk\ndata loads (i.e. using the COPY INTO <table> command) and Snowpipe. To view the copy history for all tables in\nyour account, in the left navigation bar, click Compute \u00bb History \u00bb Copies.",
        "You can also view the Copies Over Time page for a table. To view the dashboard, explore your database\nobjects and select a table. On the table details page, click Copy History.",
        "Note that the new web interface is currently in preview.",
        "Was this page helpful?",
        "On this page",
        "Related info",
        "For more details about the individual releases in which these changes were introduced, see:",
        "Releases"
    ]
}