{
    "url": "https://docs.snowflake.com/en/developer-guide/snowpark/reference/scala/com/snowflake/snowpark/index.html",
    "title": "Snowpark 1.15.0  - com.snowflake.snowpark",
    "paragraphs": [
        "This package contains all Snowpark logical types.",
        "This package contains all Snowpark logical types.",
        "0.1.0",
        "com\n        \n        .\n        \n         snowflake",
        "Provides a way to track an asynchronous query in Snowflake.",
        "Provides a way to track an asynchronous query in Snowflake.",
        "You can use this object to check the status of an asynchronous query and retrieve the results.",
        "To check the status of an asynchronous query that you submitted earlier,\ncall\n              \n               Session.createAsyncJob\n              \n              , and pass in the query ID. This returns an\n              \n               AsyncJob\n              \n              object\nthat you can use to check the status of the query and retrieve the query results.",
        "Example 1: Create an AsyncJob by specifying a valid\n              \n               <query_id>\n              \n              , check whether\nthe query is running or not, and get the result rows.",
        "Example 2: Create an AsyncJob by specifying a valid\n              \n               <query_id>\n              \n              and cancel the query if\nit is still running.",
        "0.11.0",
        "Represents a\n            \n             CASE\n            \n            expression.",
        "Represents a\n              \n               CASE\n              \n              expression.",
        "To construct this object for a CASE expression, call the\n              \n               functions.when\n              \n              . specifying a condition and the\ncorresponding result for that condition. Then, call the\n              \n               when\n              \n              and\n              \n               otherwise\n              \n              methods to\nspecify additional conditions and results.",
        "For example:",
        "0.2.0",
        "Represents a column or an expression in a DataFrame.",
        "Represents a column or an expression in a DataFrame.",
        "To create a Column object to refer to a column in a DataFrame, you can:",
        "For example:",
        "This class also defines utility functions for constructing expressions with Columns.",
        "The following examples demonstrate how to use Column objects in expressions:",
        "0.1.0",
        "DataFrame for loading data from files in a stage to a table.",
        "DataFrame for loading data from files in a stage to a table.\nObjects of this type are returned by the\n              \n               DataFrameReader\n              \n              methods that load data from files\n(e.g.\n              \n               csv\n              \n              ).",
        "To save the data from the staged files to a table, call the\n              \n               copyInto()\n              \n              methods.\nThis method uses the COPY INTO\n              \n               <table_name>\n              \n              command to copy the data to a specified table.",
        "0.9.0",
        "Provides APIs to execute CopyableDataFrame actions asynchronously.",
        "Provides APIs to execute CopyableDataFrame actions asynchronously.",
        "0.11.0",
        "Represents a lazily-evaluated relational dataset that contains a collection of\n            \n             Row\n            \n            objects\nwith columns defined by a schema (column name and type).",
        "Represents a lazily-evaluated relational dataset that contains a collection of\n              \n               Row\n              \n              objects\nwith columns defined by a schema (column name and type).",
        "A DataFrame is considered lazy because it encapsulates the computation or query\nrequired to produce a relational dataset. The computation is not performed until\nyou call a method that performs an action (e.g.\n              \n               collect\n              \n              ).",
        "Creating a DataFrame",
        "You can create a DataFrame in a number of different ways, as shown in the examples below.",
        "Example 1: Creating a DataFrame by reading a table.",
        "Example 2: Creating a DataFrame by reading files from a stage.",
        "Example 3: Creating a DataFrame by specifying a sequence or a range.",
        "Example 4: Create a new DataFrame by applying transformations to other existing DataFrames.",
        "Performing operations on a DataFrame",
        "Broadly, the operations on DataFrame can be divided into two types:",
        "Transforming a DataFrame",
        "The following examples demonstrate how you can transform a DataFrame.",
        "Example 5. Using the\n              \n               select\n              \n              method to select the columns that\nshould be in the DataFrame (similar to adding a\n              \n               SELECT\n              \n              clause).",
        "Example 6. Using the\n              \n               Column.as\n              \n              method to rename a column in a DataFrame (similar to using\n              \n               SELECT col AS alias\n              \n              ).",
        "Example 7. Using the\n              \n               filter\n              \n              method to filter data (similar to adding a\n              \n               WHERE\n              \n              clause).",
        "Example 8. Using the\n              \n               sort\n              \n              method to specify the sort order of the data (similar\nto adding an\n              \n               ORDER BY\n              \n              clause).",
        "Example 9. Using the\n              \n               groupBy\n              \n              method to\nreturn a\n              \n               RelationalGroupedDataFrame\n              \n              that you can use to group and aggregate results (similar\nto adding a\n              \n               GROUP BY\n              \n              clause).",
        "RelationalGroupedDataFrame\n              \n              provides methods for aggregating results, including:",
        "Example 10. Using a\n              \n               Window\n              \n              to build a\n              \n               WindowSpec\n              \n              object that you can use for\n              \n               windowing functions\n              \n              (similar to using '<function> OVER ... PARTITION BY ... ORDER BY').",
        "Performing an action on a DataFrame",
        "The following examples demonstrate how you can perform an action on a DataFrame.",
        "Example 11: Performing a query and returning an array of Rows.",
        "Example 12: Performing a query and print the results.",
        "0.1.0",
        "Provides APIs to execute DataFrame actions asynchronously.",
        "Provides APIs to execute DataFrame actions asynchronously.",
        "0.11.0",
        "Provides functions for handling missing values in a DataFrame.",
        "Provides functions for handling missing values in a DataFrame.",
        "0.2.0",
        "Provides methods to load data in various supported formats from a Snowflake stage to a DataFrame.",
        "Provides methods to load data in various supported formats from a Snowflake stage to a DataFrame.\nThe paths provided to the DataFrameReader must refer to Snowflake stages.",
        "To use this object:",
        "The following examples demonstrate how to use a DataFrameReader.",
        "Example 1:\n              \n              Loading the first two columns of a CSV file and skipping the first header line.",
        "Example 2:\n              \n              Loading a gzip compressed json file.",
        "If you want to load only a subset of files from the stage, you can use the\n              \n               pattern\n              \n              option to specify a regular expression that matches the files that you want to load.",
        "Example 3:\n              \n              Loading only the CSV files from a stage location.",
        "In addition, if you want to load the files from the stage into a specified table with COPY INTO\n              \n               <table_name>\n              \n              command, you can use a\n              \n               copyInto()\n              \n              method e.g.\n              \n               CopyableDataFrame.copyInto(tableName:String)*\n              \n              .",
        "Example 4:\n              \n              Loading data from a JSON file in a stage to a table by using COPY INTO\n              \n               <table_name>\n              \n              .",
        "0.1.0",
        "Provides eagerly computed statistical functions for DataFrames.",
        "Provides eagerly computed statistical functions for DataFrames.",
        "To access an object of this class, use\n              \n               DataFrame.stat\n              \n              .",
        "0.2.0",
        "Provides methods for writing data from a DataFrame to supported output destinations.",
        "Provides methods for writing data from a DataFrame to supported output destinations.",
        "You can write data to the following locations:",
        "To use this object to write into a table:",
        "For example:",
        "To save data to a file on a stage:",
        "For example:",
        "Example 1:\n              \n              Write a DataFrame to a CSV file.",
        "Example 2:\n              \n              Write a DataFrame to a CSV file without compression.",
        "0.1.0",
        "Provides APIs to execute DataFrameWriter actions asynchronously.",
        "Provides APIs to execute DataFrameWriter actions asynchronously.",
        "0.11.0",
        "Result of deleting rows in an Updatable",
        "Result of deleting rows in an Updatable",
        "0.7.0",
        "Provides methods for working on files in a stage.",
        "Provides methods for working on files in a stage.",
        "To access an object of this class, use\n              \n               Session.file\n              \n              .",
        "For example:",
        "0.4.0",
        "Represents the results of downloading a file from a stage location to the local file system.",
        "Represents the results of downloading a file from a stage location to the local file system.",
        "NOTE:\n              \n               fileName\n              \n              is the relative path to the file on the stage. For example, if you\n      download\n              \n               @myStage/prefix1/file1.csv.gz\n              \n              ,\n              \n               fileName\n              \n              is\n              \n               prefix1/file1.csv.gz\n              \n              .",
        "0.4.0",
        "A Container of grouping sets that you pass to\n            \n             DataFrame.groupByGroupingSets\n            \n            .",
        "A Container of grouping sets that you pass to\n              \n               DataFrame.groupByGroupingSets\n              \n              .",
        "a list of grouping sets",
        "0.4.0",
        "A DataFrame that returns cached data.",
        "A DataFrame that returns cached data. Repeated invocations of actions on\nthis type of dataframe are guaranteed to produce the same results.\nIt is returned from\n              \n               cacheResult\n              \n              functions (e.g.\n              \n               DataFrame.cacheResult\n              \n              ).",
        "0.4.0",
        "Builder for a matched clause.",
        "Builder for a matched clause. It provides APIs to build update and delete actions",
        "0.7.0",
        "Builder for a merge action.",
        "Builder for a merge action. It provides APIs to build matched and not matched clauses.",
        "0.7.0",
        "Provides APIs to execute MergeBuilder actions asynchronously.",
        "Provides APIs to execute MergeBuilder actions asynchronously.",
        "1.3.0",
        "Result of merging a DataFrame into an Updatable DataFrame",
        "Result of merging a DataFrame into an Updatable DataFrame",
        "0.7.0",
        "Provides a way to track an asynchronously executed action in a MergeBuilder.",
        "Provides a way to track an asynchronously executed action in a MergeBuilder.",
        "1.3.0",
        "Builder for a not matched clause.",
        "Builder for a not matched clause. It provides APIs to build insert actions",
        "0.7.0",
        "Represents the results of uploading a local file to a stage location.",
        "Represents the results of uploading a local file to a stage location.",
        "0.4.0",
        "Represents an underlying DataFrame with rows that are grouped by\ncommon values.",
        "Represents an underlying DataFrame with rows that are grouped by\ncommon values. Can be used to define aggregations on these grouped\nDataFrames.",
        "Example:",
        "The methods\n              \n               DataFrame.groupBy\n              \n              ,\n              \n               DataFrame.cube\n              \n              and\n              \n               DataFrame.rollup\n              \n              return an instance of type\n              \n               RelationalGroupedDataFrame",
        "0.1.0",
        "Represents a row returned by the evaluation of a\n            \n             DataFrame\n            \n            .",
        "Represents a row returned by the evaluation of a\n              \n               DataFrame\n              \n              .",
        "0.1.0",
        "Provides methods to register a SProc (Stored Procedure) in the Snowflake database.",
        "Provides methods to register a SProc (Stored Procedure) in the Snowflake database.",
        "Session.sproc\n              \n              returns an object of this class.",
        "To register anonymous temporary SProcs which work in the current session:",
        "To register named temporary SProcs which work in the current session:",
        "It requires a user stage when registering a permanent SProc. Snowpark will upload all\nJAR files for the SProc and any dependencies. It is also required to specify Owner or\nCaller modes via the parameter 'isCallerMode'.",
        "This object also provides a convenient methods to execute SProc lambda functions directly\nwith current session on the client side. The functions are designed for debugging and\ndevelopment only. Since the local and Snowflake server environments are different, the outputs\nof executing a SP function with these test function and on Snowflake server may be different too.",
        "1.8.0",
        "Please refer to the companion\n            \n             SaveMode$\n            \n            object.",
        "Please refer to the companion\n              \n               SaveMode$\n              \n              object.",
        "0.1.0",
        "Establishes a connection with a Snowflake database and provides methods for creating DataFrames\nand accessing objects for working with files in stages.",
        "Establishes a connection with a Snowflake database and provides methods for creating DataFrames\nand accessing objects for working with files in stages.",
        "When you create a\n              \n               Session\n              \n              object, you provide configuration settings to establish a\nconnection with a Snowflake database (e.g. the URL for the account, a user name, etc.). You can\nspecify these settings in a configuration file or in a Map that associates configuration\nsetting names with values.",
        "To create a Session from a file:",
        "To create a Session from a map of configuration properties:",
        "Session contains functions to construct\n              \n               DataFrame\n              \n              s like\n              \n               Session.table\n              \n              ,\n              \n               Session.sql\n              \n              , and\n              \n               Session.read",
        "0.1.0",
        "Represents a Snowpark client side exception.",
        "Represents a Snowpark client side exception.",
        "0.1.0",
        "The reference to a Stored Procedure which can be created by\n            \n             Session.sproc.register\n            \n            methods, and used in\n            \n             Session.storedProcedure\n            \n            method.",
        "The reference to a Stored Procedure which can be created by\n              \n               Session.sproc.register\n              \n              methods, and used in\n              \n               Session.storedProcedure\n              \n              method.",
        "For example:",
        "1.8.0",
        "Looks up table functions by funcName and returns tableFunction object\nwhich can be used in DataFrame.join and Session.tableFunction methods.",
        "Looks up table functions by funcName and returns tableFunction object\nwhich can be used in DataFrame.join and Session.tableFunction methods.",
        "It can reference both system-defined table function and\nuser-defined table functions.",
        "Example",
        "table function name,\n                can be a short name like func or\n                a fully qualified name like database.schema.func",
        "0.4.0",
        "Provides a way to track an asynchronously executed action in a DataFrame.",
        "Provides a way to track an asynchronously executed action in a DataFrame.",
        "To get the result of the action (e.g. the number of results from a\n              \n               count()\n              \n              action\nor an Array of\n              \n               Row\n              \n              objects from the\n              \n               collect()\n              \n              action), call the\n              \n               getResult\n              \n              method.",
        "To perform an action on a DataFrame asynchronously, call an action method on the\n              \n               DataFrameAsyncActor\n              \n              object returned by\n              \n               DataFrame.async\n              \n              . For example:",
        "Each of these methods returns a TypedAsyncJob object that you can use to get\nthe results of the action.",
        "0.11.0",
        "Provides methods to register lambdas and functions as UDFs in the Snowflake database.",
        "Provides methods to register lambdas and functions as UDFs in the Snowflake database.",
        "Session.udf\n              \n              returns an object of this class.",
        "You can use this object to register temporary UDFs that you plan to use in the current session:",
        "You can also register permanent UDFs that you can use in subsequent sessions. When registering\na permanent UDF, you must specify a stage where the registration method will upload the JAR\nfiles for the UDF and any dependencies.",
        "The methods that register a UDF return a\n              \n               UserDefinedFunction\n              \n              object, which you can use in\n              \n               Column\n              \n              expressions.",
        "If you do not need to refer to a UDF by name, use\n              \n               com.snowflake.snowpark.functions.udf\n              \n              to create an anonymous UDF instead.",
        "Snowflake supports the following data types for the parameters for a UDF:",
        "SQL Type",
        "Scala Type",
        "Notes",
        "NUMBER",
        "Short or Option[Short]",
        "Supported",
        "NUMBER",
        "Int or Option[Int]",
        "Supported",
        "NUMBER",
        "Long or Option[Long]",
        "Supported",
        "FLOAT",
        "Float or Option[Float]",
        "Supported",
        "DOUBLE",
        "Double or Option[Double]",
        "Supported",
        "NUMBER",
        "java.math.BigDecimal",
        "Supported",
        "VARCHAR",
        "String or java.lang.String",
        "Supported",
        "BOOL",
        "Boolean or Option[Boolean]",
        "Supported",
        "DATE",
        "java.sql.Date",
        "Supported",
        "TIMESTAMP",
        "java.sql.Timestamp",
        "Supported",
        "BINARY",
        "Array[Byte]",
        "Supported",
        "ARRAY",
        "Array[String] or Array[Variant]",
        "Supported array of type Array[String] or Array[Variant]",
        "OBJECT",
        "Map[String, String] or Map[String, Variant]",
        "Supported mutable map of type scala.collection.mutable.Map[String, String] or scala.collection.mutable.Map[String, Variant]",
        "GEOGRAPHY",
        "com.snowflake.snowpark.types.Geography",
        "Supported",
        "VARIANT",
        "com.snowflake.snowpark.types.Variant",
        "Supported",
        "0.1.0",
        "Provides methods to register a UDTF (user-defined table function) in the Snowflake database.",
        "Provides methods to register a UDTF (user-defined table function) in the Snowflake database.",
        "Session.udtf\n              \n              returns an object of this class.",
        "To register an UDTF, you must:",
        "The next sections describe these steps in more detail.",
        "Define a class that inherits from one of the\n              \n               UDTF[N]\n              \n              classes (e.g.\n              \n               UDTF0\n              \n              ,\n              \n               UDTF1\n              \n              , etc.),\nwhere\n              \n               n\n              \n              specifies the number of input arguments for your UDTF. For example, if your\nUDTF passes in 3 input arguments, extend the\n              \n               UDTF3\n              \n              class.",
        "In your class, override the following three methods:",
        "When a UDTF is called, the rows are grouped into partitions before they are passed to the UDTF:",
        "For an explanation of partitions, see\n              \n               Table Functions and Partitions",
        "This method is invoked once for each row in the input partition.",
        "The arguments passed to the registered UDTF are passed to\n              \n               process()\n              \n              . For each\nargument passed to the UDTF, you must have a corresponding argument in the signature\nof the\n              \n               process()\n              \n              method. Make sure that the type of the argument in the\n              \n               process()\n              \n              method matches the Snowflake data type of the corresponding argument in the UDTF.",
        "Snowflake supports the following data types for the parameters for a UDTF:",
        "SQL Type",
        "Scala Type",
        "Notes",
        "NUMBER",
        "Short or Option[Short]",
        "Supported",
        "NUMBER",
        "Int or Option[Int]",
        "Supported",
        "NUMBER",
        "Long or Option[Long]",
        "Supported",
        "FLOAT",
        "Float or Option[Float]",
        "Supported",
        "DOUBLE",
        "Double or Option[Double]",
        "Supported",
        "NUMBER",
        "java.math.BigDecimal",
        "Supported",
        "VARCHAR",
        "String or java.lang.String",
        "Supported",
        "BOOL",
        "Boolean or Option[Boolean]",
        "Supported",
        "DATE",
        "java.sql.Date",
        "Supported",
        "TIMESTAMP",
        "java.sql.Timestamp",
        "Supported",
        "BINARY",
        "Array[Byte]",
        "Supported",
        "ARRAY",
        "Array[String] or Array[Variant]",
        "Supported array of type Array[String] or Array[Variant]",
        "OBJECT",
        "Map[String, String] or Map[String, Variant]",
        "Supported mutable map of type scala.collection.mutable.Map[String, String] or scala.collection.mutable.Map[String, Variant]",
        "VARIANT",
        "com.snowflake.snowpark.types.Variant",
        "Supported",
        "This method is invoked once for each partition, after all rows in that partition have been\npassed to the\n              \n               process()\n              \n              method.",
        "You can use this method to generate output rows, based on any state information that you\naggregate in the\n              \n               process()\n              \n              method.",
        "In this method, define the output schema for the rows returned by the\n              \n               process()\n              \n              and\n              \n               endPartition()\n              \n              methods.",
        "Construct and return a\n              \n               types.StructType\n              \n              object that uses an Array of\n              \n               types.StructField\n              \n              objects\nto specify the Snowflake data type of each field in a returned row.",
        "Snowflake supports the following DataTypes for the output schema for a UDTF:",
        "DataType",
        "SQL Type",
        "Notes",
        "BooleanType",
        "Boolean",
        "Supported",
        "ShortType",
        "NUMBER",
        "Supported",
        "IntegerType",
        "NUMBER",
        "Supported",
        "LongType",
        "NUMBER",
        "Supported",
        "DecimalType",
        "NUMBER",
        "Supported",
        "FloatType",
        "FLOAT",
        "Supported",
        "DoubleType",
        "DOUBLE",
        "Supported",
        "StringType",
        "VARCHAR",
        "Supported",
        "BinaryType",
        "BINARY",
        "Supported",
        "TimeType",
        "TIME",
        "Supported",
        "DateType",
        "DATE",
        "Supported",
        "TimestampType",
        "TIMESTAMP",
        "Supported",
        "VariantType",
        "VARIANT",
        "Supported",
        "ArrayType(StringType)",
        "ARRAY",
        "Supported",
        "ArrayType(VariantType)",
        "ARRAY",
        "Supported",
        "MapType(StringType, StringType)",
        "OBJECT",
        "Supported",
        "MapType(StringType, VariantType)",
        "OBJECT",
        "Supported",
        "The following is an example of a UDTF class that generates a range of rows.",
        "The UDTF passes in 2 arguments, so the class extends\n              \n               UDTF2\n              \n              .",
        "The arguments\n              \n               start\n              \n              and\n              \n               count\n              \n              specify the starting number for the row and the\nnumber of rows to generate.",
        "Next, create an instance of the new class, and register the class by calling one of the\n              \n               UDTFRegistration\n              \n              methods. You can register a temporary or permanent UDTF\nby name. If you don't need to call the UDTF by name, you can register an anonymous\nUDTF.",
        "To register a temporary UDTF by name, call\n              \n               registerTemporary\n              \n              , passing in a name\nfor the UDTF and an instance of the UDTF class. For example:",
        "If you need to use the UDTF in subsequent sessions, register a permanent UDTF.",
        "When registering a permanent UDTF, you must specify a stage where the registration\nmethod will upload the JAR files for the UDTF and its dependencies. For example:",
        "If you do not need to refer to a UDTF by name, use\n              \n               UDTF)\n              \n              to create an anonymous UDTF instead.",
        "The methods that register a UDTF return a\n              \n               TableFunction\n              \n              object, which you can use in\n              \n               Session.tableFunction\n              \n              .",
        "1.2.0",
        "Represents a lazily-evaluated Updatable.",
        "Represents a lazily-evaluated Updatable. It extends\n              \n               DataFrame\n              \n              so all\n              \n               DataFrame\n              \n              operations can be applied on it.",
        "Creating an Updatable",
        "You can create an Updatable by calling\n              \n               session.table\n              \n              with the name of\nthe Updatable.",
        "Example 1: Creating a Updatable by reading a table.",
        "0.7.0",
        "Provides APIs to execute Updatable actions asynchronously.",
        "Provides APIs to execute Updatable actions asynchronously.",
        "0.11.0",
        "Result of updating rows in an Updatable",
        "Result of updating rows in an Updatable",
        "0.7.0",
        "Encapsulates a user defined lambda or function that is\nreturned by\n            \n             UDFRegistration.registerTemporary\n            \n            or by\n            \n             com.snowflake.snowpark.functions.udf\n            \n            .",
        "Encapsulates a user defined lambda or function that is\nreturned by\n              \n               UDFRegistration.registerTemporary\n              \n              or by\n              \n               com.snowflake.snowpark.functions.udf\n              \n              .",
        "Use\n              \n               UserDefinedFunction.apply\n              \n              to generate\n              \n               Column\n              \n              expressions from an instance.",
        "0.1.0",
        "Represents a window frame clause.",
        "Represents a window frame clause.",
        "0.1.0",
        "Represents the results of writing data from a DataFrame to a file in a stage.",
        "Represents the results of writing data from a DataFrame to a file in a stage.",
        "To write the data, the DataFrameWriter effectively executes the\n              \n               COPY INTO <location>\n              \n              command.\nWriteFileResult encapsulates the output returned by the command:",
        "For example, if the DETAILED_OUTPUT option is TRUE, each row contains a\n              \n               file_name\n              \n              ,\n              \n               file_size\n              \n              , and\n              \n               row_count\n              \n              field.\n              \n               schema\n              \n              defines the names and types of these fields.\nIf the DETAILED_OUTPUT option is not specified (meaning that the option is FALSE),\neach row contains a\n              \n               rows_unloaded\n              \n              ,\n              \n               input_bytes\n              \n              , and\n              \n               output_bytes\n              \n              field.",
        "The output rows produced by the\n               \n                COPY INTO <location>\n               \n               command.",
        "The names and types of the fields in the output rows.",
        "1.5.0",
        "Constructors of GroupingSets object.",
        "Constructors of GroupingSets object.",
        "0.4.0",
        "",
        "0.1.0",
        "SaveMode configures the behavior when data is written from\na DataFrame to a data source using a\n            \n             DataFrameWriter\n            \n            instance.",
        "SaveMode configures the behavior when data is written from\na DataFrame to a data source using a\n              \n               DataFrameWriter\n              \n              instance.",
        "0.1.0",
        "Companion object to\n            \n             Session\n            \n            that you use to build and create a session.",
        "Companion object to\n              \n               Session\n              \n              that you use to build and create a session.",
        "0.1.0",
        "Contains functions to form\n            \n             WindowSpec\n            \n            .",
        "Contains functions to form\n              \n               WindowSpec\n              \n              .",
        "0.1.0",
        "Provides utility functions that generate\n            \n             Column\n            \n            expressions that you can pass to\n            \n             DataFrame\n            \n            transformation methods.",
        "Provides utility functions that generate\n              \n               Column\n              \n              expressions that you can pass to\n              \n               DataFrame\n              \n              transformation methods. These functions generate references to columns,\nliterals, and SQL expressions (e.g. \"c + 1\").",
        "This object also provides functions that correspond to Snowflake\n              \n               system-defined functions\n              \n              (built-in functions), including functions for aggregation and window functions.",
        "The following examples demonstrate the use of some of these functions:",
        "For functions that accept scala types, e.g. callUdf, callBuiltin, lit(),\nthe mapping from scala types to Snowflake types is as follows:",
        "0.1.0",
        "Provides utility functions that generate table function expressions that can be\npassed to DataFrame join method and Session tableFunction method.",
        "Provides utility functions that generate table function expressions that can be\npassed to DataFrame join method and Session tableFunction method.",
        "This object also provides functions that correspond to Snowflake\n              \n               system-defined table functions\n              \n              .",
        "The following examples demonstrate the use of some of these functions:",
        "0.4.0"
    ]
}