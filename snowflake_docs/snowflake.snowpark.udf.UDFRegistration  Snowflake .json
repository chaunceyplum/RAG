{
    "url": "https://docs.snowflake.com/en/developer-guide/snowpark/reference/python/1.26.0/snowpark/api/snowflake.snowpark.udf.UDFRegistration",
    "title": "snowflake.snowpark.udf.UDFRegistration | Snowflake Documentation",
    "paragraphs": [
        "Bases: object",
        "Provides methods to register lambdas and functions as UDFs in the Snowflake database.\nFor more information about Snowflake Python UDFs, see Python UDFs.",
        "session.udf returns an object of this class.\nYou can use this object to register UDFs that you plan to use in the current session or\npermanently. The methods that register a UDF return a UserDefinedFunction object,\nwhich you can also use in Column expressions.",
        "There are two ways to register a UDF with Snowpark:",
        "Use udf() or register(). By pointing to a\nruntime Python function, Snowpark uses cloudpickle\nto serialize this function to bytecode, and deserialize the bytecode to a Python\nfunction on the Snowflake server during UDF creation. During the serialization, the\nglobal variables used in the Python function will be serialized into the bytecode,\nbut only the name of the module object or any objects from a module that are used in the\nPython function will be serialized. If the size of the serialized bytecode is over 8K bytes, it will be uploaded to a stage location as a Python file.\nIf it\u2019s under 8K, it will be added to the UDF in-line code.\nDuring the deserialization, Python will look up the corresponding modules and objects by names. For example:",
        "Here the variable a and function f will be serialized into the bytecode, but\nonly the name of numpy and mod5 will be included in the bytecode. Therefore,\nin order to have these modules on the server side, you can use\nadd_import() and add_packages()\nto add your first-party and third-party libraries.",
        "After deserialization, this function will be executed and applied to every row of your\ndataframe or table during UDF execution. This approach is very flexible because you can\neither create a UDF from a function in your current file/notebook, and you can also import\nthe function from elsewhere. However, the limitations of this approach are:",
        "All code inside the function will be executed on every row, so you are not able to\nperform some initializations before executing this function. For example, if you want\nto read a file from a stage in a UDF, this file will be read on every row. However,\nwe still have a workaround for this scenario, which can be found in Example 8 here.",
        "If the runtime function references some very large global variables (e.g., a machine\nlearning model with a large number of parameters), they will also be serialized and\nthe size of bytecode can be very large, which will take more time for uploading files.\nAlso, the UDF creation will fail if the referenced global variables cannot be pickled\n(e.g., weakref object). In this case, you usually have to save such objects in the\nlocal environment first, add it to the UDF using  add_import(),\nand read it from the UDF (see Example 8 here).",
        "Use register_from_file(). By pointing to a Python file or a zip file containing\nPython source code and the target function name, Snowpark uploads this file to a stage\n(which can also be customized), and load the corresponding function from this file to\nthe Python runtime on the Snowflake server during UDF creation. Then this function will be\nexecuted and applied to every row of your dataframe or table when executing this UDF.\nThis approach can address the deficiency of the previous approach that uses cloudpickle,\nbecause the source code in this file other than the target function will be loaded\nduring UDF creation, and will not be executed on every row during UDF execution.\nTherefore, this approach is useful and efficient when all your Python code is already in\nsource files.",
        "You can use udf(), register() or\npandas_udf() to create a vectorized UDF by providing\nappropriate return and input types. If you would like to use register_from_file() to\ncreate a vectorized UDF, you need to explicitly mark the handler function as vectorized using\neither the vectorized Decorator or a function attribute.",
        "Snowflake supports the following data types for the parameters for a UDF:",
        "Python Type",
        "Snowpark Type",
        "SQL Type",
        "int",
        "LongType",
        "NUMBER",
        "decimal.Decimal",
        "DecimalType",
        "NUMBER",
        "float",
        "FloatType",
        "FLOAT",
        "str",
        "StringType",
        "STRING",
        "bool",
        "BooleanType",
        "BOOL",
        "datetime.time",
        "TimeType",
        "TIME",
        "datetime.date",
        "DateType",
        "DATE",
        "datetime.datetime",
        "TimestampType",
        "TIMESTAMP",
        "bytes or bytearray",
        "BinaryType",
        "BINARY",
        "list",
        "ArrayType",
        "ARRAY",
        "dict",
        "MapType",
        "OBJECT",
        "Dynamically mapped to the native Python type",
        "VariantType",
        "VARIANT",
        "dict",
        "GeographyType",
        "GEOGRAPHY",
        "pandas.Series",
        "PandasSeriesType",
        "No SQL type",
        "pandas.DataFrame",
        "PandasDataFrameType",
        "No SQL type",
        "Note",
        "1. Data with the VARIANT SQL type will be converted to a Python type\ndynamically inside a UDF. The following SQL types are converted to str\nin UDFs rather than native Python types: TIME, DATE, TIMESTAMP and BINARY.",
        "2. Data returned as ArrayType (list),\nMapType (dict) or\nVariantType (Variant)\nby a UDF will be represented as a json string. You can call eval() or json.loads()\nto convert the result to a native Python object. Data returned as\nGeographyType (Geography)\nby a UDF will be represented as a GeoJSON\nstring.",
        "3. PandasSeriesType and\nPandasDataFrameType are used when creating a pandas\n(vectorized) UDF, so they are not mapped to any SQL types. element_type in\nPandasSeriesType and col_types in\nPandasDataFrameType indicate the SQL types\nin a pandas Series and a pandas DataFrame.",
        "4. To annotate the Snowflake specific Timestamp type (TIMESTAMP_NTZ, TIMESTAMP_LTZ and\nTIMESTAMP_TZ), use Timestamp with\nNTZ, LTZ,\nTZ (e.g., Timestamp[NTZ]).",
        "Create a temporary UDF from a lambda and apply it to a dataframe:",
        "Create a UDF with type hints and @udf decorator and apply it to a dataframe:",
        "Create a permanent UDF with a name and call it in SQL:",
        "Create a UDF with UDF-level imports and apply it to a dataframe:",
        "Create a UDF with UDF-level packages and apply it to a dataframe:",
        "Creating a UDF from a local Python file:",
        "Creating a UDF from a Python file on an internal stage:",
        "Use cache to read a file once from a stage in a UDF:",
        "In this example, the file will only be read once during UDF creation, and will not\nbe read again during UDF execution. This is achieved with a third-party library\ncachetools. You can also use LRUCache\nand TTLCache in this package to avoid the cache growing too large. Note that Python\nbuilt-in cache decorators\nare not working when registering UDFs using Snowpark, due to the limitation of cloudpickle.",
        "Create a vectorized UDF from a lambda with a max batch size and apply it to a dataframe:",
        "Create a vectorized UDF with type hints and apply it to a dataframe:",
        "Create a vectorized UDF with original pandas types and Snowpark types and apply it to a dataframe:",
        "See also",
        "udf()",
        "register()",
        "register_from_file()",
        "add_import()",
        "add_packages()",
        "Methods",
        "describe(udf_obj)",
        "Returns a DataFrame that describes the properties of a UDF.",
        "register(func[,\u00a0return_type,\u00a0input_types,\u00a0...])",
        "Registers a Python function as a Snowflake Python UDF and returns the UDF.",
        "register_from_file(file_path,\u00a0func_name[,\u00a0...])",
        "Registers a Python function as a Snowflake Python UDF from a Python or zip file, and returns the UDF.",
        "Was this page helpful?"
    ]
}