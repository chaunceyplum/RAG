{
    "url": "https://docs.snowflake.com/en/user-guide/table-considerations",
    "title": "Table Design Considerations | Snowflake Documentation",
    "paragraphs": [
        "This topic provides best practices, general guidelines, and important considerations when designing and managing tables.",
        "When defining columns to contain dates or timestamps, Snowflake recommends choosing a\ndate or timestamp data type rather than a character data type. Snowflake stores DATE and\nTIMESTAMP data more efficiently than VARCHAR, resulting in better query performance. Choose an appropriate date or timestamp data type,\ndepending on the level of granularity required.",
        "When they are created on standard tables, referential integrity constraints, as defined by primary-key/foreign-key relationships, are informational; they are not enforced. NOT NULL constraints are enforced, but other constraints are not. However, constraints on\nhybrid tables are enforced; see Overview of Constraints.",
        "In general, constraints provide valuable metadata. Primary and foreign keys enable your project team to understand the schema design and see the relationships between the tables and their columns.",
        "Additionally, most business intelligence (BI) and visualization tools import the foreign key definitions with the tables and build the\nproper join conditions. This approach saves time and is potentially less prone to error than someone having to guess how to join\nthe tables and manually configure the tool. Basing joins on primary and foreign keys also brings integrity to the design,\nbecause the joins are not left to different developers to interpret. Some BI and visualization tools also take advantage of constraint\ninformation to rewrite queries more efficiently, for example, by using join elimination.",
        "Specify a constraint when creating or modifying a table using the CREATE | ALTER TABLE \u2026 CONSTRAINT commands.",
        "In the following example, the CREATE TABLE statement for the second table (salesorders) defines an out-of-line foreign key constraint that references a column in the first table (salespeople):",
        "Query the GET_DDL function to retrieve a DDL statement that could be executed to recreate the specified\ntable. The statement includes the constraints currently set on a table.",
        "For example:",
        "Alternatively, retrieve a list of all table constraints by schema (or across all schemas in a database) by querying the\nTABLE_CONSTRAINTS view in the Information Schema.",
        "For example:",
        "Specifying a clustering key is not necessary for most tables. Snowflake performs automatic tuning via the\noptimization engine and micro-partitioning. In many cases, data is loaded and organized into micro-partitions by date or timestamp, and\nis queried along the same dimension.",
        "When should you specify a clustering key for a table? First, note that clustering a small table typically doesn\u2019t improve query performance\nsignificantly.",
        "For larger data sets, you might consider specifying a clustering key for a table when:",
        "The order in which the data is loaded does not match the dimension by which it is most commonly queried (e.g. the data is loaded by\ndate, but reports filter the data by ID). If your existing scripts or reports query the data by both date and ID (and potentially\na third or fourth column), you may see some performance improvement by creating a multi-column clustering key.",
        "Query Profile indicates that a significant percentage of the total duration time for typical\nqueries against the table is spent scanning. This applies to queries that filter on one or more specific columns.",
        "Note that reclustering rewrites existing data with a different order. The previous ordering is stored for 7 days to provide Fail-safe\nprotection. Reclustering a table incurs compute costs that correlate to the size of the data that is reordered.",
        "For more information, see Automatic Clustering.",
        "Snowflake compresses column data effectively; therefore, creating columns larger than necessary has minimal impact on the size of data\ntables. Likewise, there is no query performance difference between a column with a maximum length declaration (e.g. VARCHAR(16777216)),\nand a smaller precision.",
        "However, when the size of your column data is predictable, Snowflake recommends defining an appropriate column length, for the following\nreasons:",
        "Data loading operations are more likely to detect issues such as columns loaded out of order, e.g. a 50-character string loaded\nerroneously into a VARCHAR(10) column. Such issues produce errors.",
        "When the column length is unspecified, some third-party tools may anticipate consuming the maximum size value, which can translate into\nincreased client-side memory usage or unusual behavior.",
        "If you are not sure yet what types of operations you want perform on your semi-structured data, Snowflake recommends storing the data in a\nVARIANT column for now. For data that is mostly regular and uses only native types (strings and integers), the storage requirements and\nquery performance for operations on relational data and data in a VARIANT column is very similar.",
        "For better pruning and less storage consumption, Snowflake recommends flattening your object and key data into separate relational columns\nif your semi-structured data includes:",
        "Dates and timestamps, especially non-ISO 8601 dates and timestamps, as string values",
        "Numbers within strings",
        "Arrays",
        "Non-native values such as dates and timestamps are stored as strings when loaded into a VARIANT column, so operations on these values\ncould be slower and also consume more space than when stored in a relational column with the corresponding data type.",
        "If you know your use cases for the data, perform tests on a typical data set. Load the data set into a VARIANT column in a table. Use the\nFLATTEN function to extract the objects and keys you plan to query into a separate table. Run a typical set of queries against both tables\nto see which structure provides the best performance.",
        "Currently, it is not possible to change a permanent table to a transient table using the\nALTER TABLE command. The TRANSIENT property is set at table creation and cannot be modified.",
        "Similarly, it is not possible to directly change a transient table to a permanent table.",
        "To convert an existing permanent table to a transient table (or vice versa) while preserving data and other\ncharacteristics such as column defaults and granted privileges, you can create a new table using one of the interfaces as described in the\nfollowing examples:",
        "Use the COPY GRANTS clause of the CREATE TABLE command:",
        "Use the like_table and copy_grants arguments of the TableCollection.create method:",
        "Then use the INSERT command to copy the data:",
        "If you want to preserve all of the data, but not the granted privileges and other characteristics, you can use one of the following\ninterfaces:",
        "Use a CREATE TABLE AS SELECT (CTAS) statement:",
        "Use the as_select argument of the TableCollection.create method:",
        "Another way to make a copy of a table (but change the lifecycle from permanent to transient) is to clone the table using one of the\nfollowing interfaces:",
        "Use the CLONE clause of the CREATE TABLE command:",
        "Use the clone_table argument of the TableCollection.create method:",
        "Old partitions are not affected (they do not become transient), but new partitions added to the clone\nwill follow the transient lifecycle.",
        "You cannot clone a transient table to a permanent table.",
        "Was this page helpful?",
        "On this page",
        "Related content"
    ]
}