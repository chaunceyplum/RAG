{
    "url": "https://docs.snowflake.com/en/developer-guide/udf/python/udf-python-designing",
    "title": "Designing Python UDFs | Snowflake Documentation",
    "paragraphs": [
        "This topic helps you design Python UDFs.",
        "Note",
        "Vectorized Python UDFs let you define Python functions that receive batches of input rows\nas Pandas DataFrames and\nreturn batches of results as Pandas arrays\nor Series.\nThe batch interface results in much better performance with machine learning inference scenarios.\nFor more information, see Vectorized Python UDFs.",
        "Before you write your code:",
        "Choose the data types your function should accept as arguments and the data\ntype your function should return.",
        "Take into account time-zone related issues.",
        "Decide how to handle NULL values.",
        "For more information about how Snowflake maps Python and SQL data types, see SQL-Python Data Type Mappings.",
        "A Python UDF is largely isolated from the environment in which it is called. However, the timezone is inherited from\nthe calling environment. If the caller\u2019s session set a default time zone before calling the Python UDF, then the Python\nUDF has the same default time zone. For more information about timezones, see TIMEZONE.",
        "For all Snowflake types except Variant, a SQL NULL argument to a Python UDF translates to the\nPython None value and a returned Python None value translates back to SQL NULL.",
        "A Variant type value can be: SQL NULL or a VARIANT JSON null. For information about Snowflake\nVARIANT NULL, see NULL Values.",
        "A VARIANT JSON null is translated to Python None.",
        "A SQL NULL is translated to a Python object, which has the is_sql_null attribute.",
        "For an example, see NULL Handling in Python UDFs.",
        "To ensure stability within the Snowflake environment, Snowflake places the following constraints on Python UDFs.\nUnless stated otherwise, these limitations are enforced when the UDF is executed, not when it is created.",
        "Training machine learning (ML) models can sometimes be very resource intensive.\nSnowpark-optimized warehouses are a type of Snowflake virtual warehouse that can be used for workloads\nthat require a large amount of memory and compute resources.\nFor information on machine learning models and Snowpark Python, see Training Machine Learning Models with Snowpark Python.",
        "Avoid consuming too much memory.",
        "Large data values can consume a large amount of memory.",
        "Excessive stack depth can consume a large amount of memory.",
        "UDFs return an error if they consume too much memory. The specific limit is subject to change.",
        "If UDFs fail due to consuming too much memory, consider using Snowpark-optimized warehouses.",
        "Avoid algorithms that take a large amount of time per call.",
        "If a UDF takes too long to complete, Snowflake kills the SQL statement and returns an error to the user. This limits\nthe impact and cost of errors such as infinite loops.",
        "When a SQL statement calls your Python UDF, Snowflake calls a Python function you have written. Your Python function is called a\n\u201chandler function\u201d, or \u201chandler\u201d for short. The handler is a function implemented inside a user-supplied module.",
        "As with any Python function, your function must be declared as part of a module.",
        "The handler is called once for each row passed to the Python UDF.\nThe module that contains the function is not re-imported for each row. Snowflake can call the same module\u2019s handler function more than once.",
        "To optimize execution of your code, Snowflake assumes that initialization might be slow, while execution of the handler function\nis fast. Snowflake sets a longer timeout for executing initialization (including the time to load your UDF and the time\nto initialize the module) than for executing the handler\n(the time to call your handler with one row of input).",
        "Additional information about designing the module is in Creating Python UDFs.",
        "Most scalar UDFs should follow the guidelines below:",
        "If you need to initialize shared state that does not change across rows, initialize it in the module instead of the handler function.",
        "Write your handler function to be thread safe.",
        "Avoid storing and sharing dynamic state across rows.",
        "If your UDF cannot follow these guidelines, be aware that Snowflake expects scalar UDFs to be processed independently. Relying on state\nshared between invocations can result in unexpected behavior, as the system can process rows in any order and spread those invocations\nacross several instances. In addition, there can be multiple executions of the same handler function within the same Python\ninterpreter on multiple threads.",
        "UDFs should avoid relying on shared state across calls to the handler function. However, there are two situations in which you might want a\nUDF to store shared state:",
        "Code that contains expensive initialization logic that you do not want to repeat for each row.",
        "Code that leverages shared state across rows, such as a cache.",
        "When it\u2019s necessary to maintain global state that will be shared across handler invocations, you must protect global state against\ndata races by using the synchronization primitives described in\nthreading - Thread-based parallelism.",
        "When your code will use machine learning or data science libraries, use vectorized Python UDFs to\ndefine Python functions that receive input rows in batches on which these libraries are optimized to operate.",
        "For more information, see Vectorized Python UDFs.",
        "Write UDF handlers that are single-threaded. Snowflake will handle partitioning the data and scaling the UDF across the virtual warehouse\ncompute resources.",
        "Put expensive initialization code into the module scope. There, it will be performed once when the UDF is initialized.\nAvoid rerunning the expensive initialization code on every UDF handler invocation.",
        "A Python function used as a UDF can use the normal Python exception-handling techniques to catch errors within the\nfunction.",
        "If an exception occurs inside the function and is not caught by the function, Snowflake raises an error that includes the stack trace for the\nexception. When logging of unhandled exceptions is enabled,\nSnowflake logs data about unhandled exceptions in an event table.",
        "You can explicitly throw an exception without catching it in order to end the query and produce a SQL error. For\nexample:",
        "When debugging, you can include values in the SQL error message text. To do so, place an entire Python function body in a\ntry-catch block; append argument values to the caught error\u2019s message; and throw an exception with the extended\nmessage. To avoid revealing sensitive data, remove argument values prior to deploying to a production\nenvironment.",
        "To help ensure that your handler functions in a secure way, see the best practices described in\nSecurity Practices for UDFs and Procedures.",
        "Was this page helpful?",
        "On this page",
        "Related content"
    ]
}