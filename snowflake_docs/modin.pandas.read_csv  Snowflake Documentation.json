{
    "url": "https://docs.snowflake.com/en/developer-guide/snowpark/reference/python/1.26.0/modin/pandas_api/modin.pandas.read_csv",
    "title": "modin.pandas.read_csv | Snowflake Documentation",
    "paragraphs": [
        "Read csv file(s) into a Snowpark pandas DataFrame. This API can read\nfiles stored locally or on a Snowflake stage.",
        "Snowpark pandas stages files (unless they\u2019re already staged)\nand then reads them using Snowflake\u2019s CSV reader.",
        "filepath_or_buffer (str) \u2013 Local file location or staged file location to read from. Staged file locations\nstarts with a \u2018@\u2019 symbol. To read a local file location with a name starting with @,\nescape it using a @. For more info on staged files, read here.",
        "sep (str, default ',') \u2013 Delimiter to use to separate fields in an input file. Delimiters can be\nmultiple characters in Snowpark pandas.",
        "delimiter (str, default ',') \u2013 Alias for sep.",
        "header (int, list of int, None, default 'infer') \u2013 Row number(s) to use as the column names, and the start of the\ndata.  Default behavior is to infer the column names: if no names\nare passed the behavior is identical to header=0 and column\nnames are inferred from the first line of the file, if column\nnames are passed explicitly then the behavior is identical to\nheader=None. Explicitly pass header=0 to be able to\nreplace existing names. If a non-zero integer or a list of integers is passed,\na NotImplementedError will be raised.",
        "names (array-like, optional) \u2013 List of column names to use. If the file contains a header row,\nthen you should explicitly pass header=0 to override the column names.\nDuplicates in this list are not allowed.",
        "index_col (int, str, sequence of int / str, or False, optional, default None) \u2013 Column(s) to use as the row labels of the DataFrame, either given as\nstring name or column index. If a sequence of int / str is given, a\nMultiIndex is used.\nNote: index_col=False can be used to force pandas to not use the first\ncolumn as the index, e.g. when you have a malformed file with delimiters at\nthe end of each line.",
        "usecols (list-like or callable, optional) \u2013",
        "Return a subset of the columns. If list-like, all elements must either\nbe positional (i.e. integer indices into the document columns) or strings\nthat correspond to column names provided either by the user in names or\ninferred from the document header row(s). If names are given, the document\nheader row(s) are not taken into account. For example, a valid list-like\nusecols parameter would be [0, 1, 2] or ['foo', 'bar', 'baz'].\nElement order is ignored, so usecols=[0, 1] is the same as [1, 0].\nTo instantiate a DataFrame from data with element order preserved use\npd.read_csv(data, usecols=['foo', 'bar'])[['foo', 'bar']] for columns\nin ['foo', 'bar'] order or\npd.read_csv(data, usecols=['foo', 'bar'])[['bar', 'foo']]\nfor ['bar', 'foo'] order.",
        "If callable, the callable function will be evaluated against the column\nnames, returning names where the callable function evaluates to True. An\nexample of a valid callable argument would be lambda x: x.upper() in\n['AAA', 'BBB', 'DDD'].",
        "",
        "dtype (Type name or dict of column -> type, optional) \u2013 Data type for data or columns. E.g. {{\u2018a\u2019: np.float64, \u2018b\u2019: np.int32,\n\u2018c\u2019: \u2018Int64\u2019}}\nUse str or object together with suitable na_values settings\nto preserve and not interpret dtype.\nIf converters are specified, they will be applied INSTEAD\nof dtype conversion.",
        "engine ({{'c', 'python', 'pyarrow', 'snowflake'}}, optional) \u2013 Changes the parser for reading CSVs. \u2018snowflake\u2019 will use the parser\nfrom Snowflake itself, which matches the behavior of the COPY INTO\ncommand.",
        "converters (dict, optional) \u2013 This parameter is only supported on local files.",
        "true_values (list, optional) \u2013 This parameter is only supported on local files.",
        "false_values (list, optional) \u2013 This parameter is only supported on local files.",
        "skiprows (list-like, int or callable, optional) \u2013 Line numbers to skip (0-indexed) or number of lines to skip (int)\nat the start of the file.",
        "skipfooter (int, default 0) \u2013 This parameter is only supported on local files.",
        "nrows (int, optional) \u2013 This parameter is only supported on local files.",
        "na_values (scalar, str, list-like, or dict, optional) \u2013 Additional strings to recognize as NA/NaN.",
        "keep_default_na (bool, default True) \u2013 This parameter is only supported on local files.",
        "na_filter (bool, default True) \u2013 This parameter is only supported on local files.",
        "verbose (bool, default False) \u2013 This parameter is only supported on local files.",
        "skip_blank_lines (bool, default True) \u2013 If True, skip over blank lines rather than interpreting as NaN values.",
        "parse_dates (bool or list of int or names or list of lists or dict, default False) \u2013 This parameter is only supported on local files.",
        "infer_datetime_format (bool, default False) \u2013 This parameter is only supported on local files.",
        "keep_date_col (bool, default False) \u2013 This parameter is only supported on local files.",
        "date_parser (function, optional) \u2013 This parameter is only supported on local files.",
        "date_format (str or dict of column -> format, optional) \u2013 This parameter is only supported on local files.",
        "dayfirst (bool, default False) \u2013 This parameter is only supported on local files.",
        "cache_dates (bool, default True) \u2013 This parameter is not supported and will be ignored.",
        "iterator (bool, default False) \u2013 This parameter is not supported and will raise an error.",
        "chunksize (int, optional) \u2013 This parameter is not supported and will be ignored.",
        "compression (str, default 'infer') \u2013 String (constant) that specifies the current compression algorithm for the\ndata files to be loaded. Snowflake uses this option to detect how already-compressed\ndata files were compressed so that the compressed data in the files\ncan be extracted for loading.\nList of Snowflake standard compressions .",
        "thousands (str, optional) \u2013 This parameter is only supported on local files.",
        "decimal (str, default '.') \u2013 This parameter is only supported on local files.",
        "lineterminator (str (length 1), optional) \u2013 This parameter is only supported on local files.",
        "quotechar (str (length 1), optional) \u2013 The character used to denote the start and end of a quoted item. Quoted\nitems can include the delimiter and it will be ignored.",
        "quoting (int or csv.QUOTE_* instance, default 0) \u2013 This parameter is only supported on local files.",
        "doublequote (bool, default True) \u2013 This parameter is only supported on local files.",
        "escapechar (str (length 1), optional) \u2013 This parameter is only supported on local files.",
        "comment (str, optional) \u2013 This parameter is only supported on local files.",
        "encoding (str, default 'utf-8') \u2013 Encoding to use for UTF when reading/writing (ex. \u2018utf-8\u2019). List of Snowflake\nstandard encodings .",
        "encoding_errors (str, optional, default \"strict\") \u2013 This parameter is only supported on local files.",
        "dialect (str or csv.Dialect, optional) \u2013 This parameter is only supported on local files.",
        "on_bad_lines ({{'error', 'warn', 'skip'}} or callable, default 'error') \u2013 This parameter is only supported on local files.",
        "delim_whitespace (bool, default False) \u2013 This parameter is only supported on local files, not files which have been\nuploaded to a snowflake stage.",
        "low_memory (bool, default True) \u2013 This parameter is not supported and will be ignored.",
        "memory_map (bool, default False) \u2013 This parameter is not supported and will be ignored.",
        "float_precision (str, optional) \u2013 This parameter is not supported and will be ignored.",
        "dtype_backend ({'numpy_nullable', 'pyarrow'}, default 'numpy_nullable') \u2013 This parameter is not supported and will be ignored.",
        "Snowpark pandas DataFrame",
        "NotImplementedError if a parameter is not supported. \u2013",
        "Notes",
        "Both local files and files staged on Snowflake can be passed into\nfilepath_or_buffer. A single file or a folder that matches\na set of files can be passed into filepath_or_buffer. Local files\nwill be processed locally by default using the stand pandas parser\nbefore they are uploaded to a staging location as parquet files. This\nbehavior can be overriden by explicitly using the snowflake engine\nwith engine=snowflake",
        "If parsing the file using Snowflake, certain parameters may not be supported\nand the order of rows in the dataframe may be different than the order of\nrecords in an input file. When reading multiple files, there is no\ndeterministic order in which the files are read.",
        "Examples",
        "Read local csv file.",
        "Read staged csv file.",
        "Read csv files from a local folder.",
        "Read csv files from a staged location.",
        "Was this page helpful?"
    ]
}