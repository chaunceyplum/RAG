{
    "url": "https://docs.snowflake.com/en/developer-guide/snowpark/reference/python/1.26.0/modin/pandas_api/modin.pandas.read_snowflake",
    "title": "modin.pandas.read_snowflake | Snowflake Documentation",
    "paragraphs": [
        "Read a Snowflake table or SQL Query to a Snowpark pandas DataFrame.",
        "name_or_query \u2013 A table name or fully-qualified object identifier or a SQL SELECT Query. It follows the same syntax in\nhttps://docs.snowflake.com/developer-guide/snowpark/reference/python/api/snowflake.snowpark.Session.table.html",
        "index_col \u2013 A column name or a list of column names to use as index.",
        "columns \u2013 A list of column names to select from the table. If not specified, select all columns.",
        "See also",
        "to_snowflake",
        "Notes",
        "Transformations applied to the returned Snowpark pandas Dataframe do not affect the underlying Snowflake table\n(or object). Use\n- modin.pandas.to_snowpark\nto write the Snowpark pandas DataFrame back to a Snowpark table.",
        "This API supports table names, SELECT queries (including those that use CTEs), CTEs with anonymous stored procedures\nand CALL queries, and is read only. To interact with Snowflake objects, e.g., listing tables, deleting tables or appending columns use the\nSnowflake Python Connector, or Snowpark\u2019s\nSession object which can be retrieved via pd.session.",
        "Snowpark pandas provides the same consistency and isolation guarantees for read_snowflake as if local files were read. Depending on the type of source, pd.read_snowflake will do one of the following\nat the time of calling pd.read_snowflake:",
        "For a table referenced by name_or_query the base table is snapshotted and the snapshot is used to back the resulting DataFrame.",
        "For SELECT queries of the form SELECT * FROM {table_name} the base table is snapshotted as though it were referenced directly from pd.read_snowflake,\nand the snapshot will be used to back the resulting DataFrame as above.",
        "In the following cases, a temporary table is created and snapshotted, and the snapshot of the temporary table is used to back the resulting\nDataFrame.",
        "For VIEWs, SECURE VIEWs, and TEMPORARY VIEWs, a temporary table is created as a materialized copy of the view at\nthe time of calling pd.read_snowflake whether pd.read_snowflake is called as pd.read_snowflake(\u201cSELECT * FROM {view_name}\u201d) or\npd.read_snowflake(view_name).",
        "For more complex SELECT queries, including those with ORDER BY\u2019s or CTEs, the query is evaluated, and a temporary\ntable is created with the result at the time of calling pd.read_snowflake.",
        "For CTEs with anonymous stored procedures and CALL queries, the procedure is evaluated at the time of calling pd.read_snowflake,\nand a temporary table is created with the result.",
        "Any changes to the base table(s) or view(s) of the queries (whether the query is a SELECT query or a CTE with an anonymous stored procedure) that\nhappen after calling pd.read_snowflake will not be reflected in the DataFrame object returned by pd.read_snowflake.",
        "Examples",
        "Let\u2019s create a Snowflake table using SQL first for demonstrating the behavior of\nindex_col and columns:",
        "When index_col and columns are both not specified, a Snowpark pandas DataFrame\nwill have a default index from 0 to n-1, where n is the number of rows in the table,\nand have all columns in the Snowflake table as data columns.",
        "When index_col is specified and columns is not specified, index_col\nwill be used as index columns in Snowpark pandas DataFrame and rest of columns in the\nSnowflake table will be data columns. Note that duplication is allowed and\nduplicate pandas labels are maintained.",
        "When index_col is not specified and columns is specified, a Snowpark pandas DataFrame\nwill have a default index from 0 to n-1 and columns as data columns.",
        "When index_col and columns are specified, index_col\nwill be used as index columns and columns will be used as data columns.\nindex_col doesn\u2019t need to be a part of columns.",
        "Examples of pd.read_snowflake using SQL queries:",
        "When index_col is not specified, a Snowpark pandas DataFrame\nwill have a default index from 0 to n-1, where n is the number of rows in the table.",
        "When index_col is specified, it\nwill be used as index columns in Snowpark pandas DataFrame and rest of columns in the\nSnowflake table will be data columns. Note that duplication is allowed and\nduplicate pandas labels are maintained.",
        "More complex queries can also be passed in.",
        "SQL comments can also be included, and will be ignored.",
        "Note that in the next example, sort_values is called to impose an ordering on the DataFrame.",
        "Anonymous Stored Procedures (using CTEs) may also be used (although special care must be taken with respect to indentation of the code block,\nsince the entire string encapsulated by the $$ will be passed directly to a Python interpreter. In the example below, the lines within\nthe function are indented, but not the import statement or function definition). The output schema must be specified when defining\nan anonymous stored procedure.",
        "An example using an anonymous stored procedure defined in Scala.",
        "An example using a stored procedure defined via SQL using Snowpark\u2019s Session object.",
        "Note",
        "The names/labels used for the parameters of the Snowpark pandas IO functions such as index_col, columns are normalized\nSnowflake Identifiers (The Snowflake stored and resolved Identifiers). The Normalized Snowflake Identifiers\nare also used as default pandas label after constructing a Snowpark pandas DataFrame out of the Snowflake\ntable or Snowpark DataFrame. Following are the rules about how Normalized Snowflake Identifiers are generated:",
        "When the column identifier in Snowflake/Snowpark DataFrame is an unquoted object identifier,\nit is stored and resolved as uppercase characters (e.g. id is stored and resolved as ID),\nthe valid input is an uppercase string. For example, for the column identifier A or a, the\nstored and resolved identifier is A, and the valid input for the parameters can only be A,\nand the corresponding pandas label in Snowpark pandas DataFrame is A. a and \"A\" are both invalid.",
        "When the column identifier in Snowflake/Snowpark DataFrame is a quoted object identifier, the case\nof the identifier is preserved when storing and resolving the identifier\n(e.g. \u201cid\u201d is stored and resolved as id), the valid input is case-sensitive string.\nFor example, for the column identifier \"a\", the valid input for the parameter can only be\na, and the corresponding pandas label in Snowpark pandas DataFrame is a.\n\"a\" is invalid. For the column identifier \"A\", the valid input for the parameter can only be\nA, and the corresponding pandas label in Snowpark pandas DataFrame is A, and``\u201dA\u201d`` is invalid.",
        "See Snowflake Identifier Requirements for\nmore details about Snowflake Identifiers.",
        "To see what are the Normalized Snowflake Identifiers for columns of a Snowpark DataFrame, you can call\ndataframe.show() to see all column names, which is the Normalized identifier.",
        "To see what are the Normalized Snowflake Identifiers for columns of a Snowflake table, you can call SQL query\nSELECT * FROM TABLE or DESCRIBE TABLE to see the column names.",
        "Was this page helpful?"
    ]
}