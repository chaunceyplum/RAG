{
    "url": "https://docs.snowflake.com/en/developer-guide/native-apps/connector-sdk/tutorials/native_sdk_tutorial",
    "title": "Tutorial: Native SDK for Connectors Java Template | Snowflake Documentation",
    "paragraphs": [
        "Preview Feature \u2014 Open",
        "Available to accounts in all regions in all cloud providers (including government regions). For details, contact your Snowflake representative.",
        "Welcome to our tutorial on using a connector template utilizing Snowflake Native SDK for Connectors. This guide will help you setup a simple Connector Native Application.",
        "In this tutorial you will learn how to:",
        "Deploy a Connector Native Application",
        "Configure a template connector to ingest data",
        "Customize a template connector to your own needs",
        "The template contains various helpful comments in the code to make it easier for you to find specific files that need to be modified.\nLook for the comments with the following keywords, they will guide you and help implement your own connector:",
        "TODO",
        "TODO: HINT",
        "TODO: IMPLEMENT ME",
        "Before you begin this tutorial, you should prepare yourself by reviewing the following recommended content:",
        "Snowflake Native SDK for Connectors",
        "The Snowflake Labs quickstart for building and deploying a connector using Native Apps framework in Snowflake and Native Connectors SDK Java.",
        "Before getting started please make sure that you meet the following requirements:",
        "Java 11 installed",
        "access to Snowflake account with ACCOUNTADMIN role",
        "SnowSQL (CLI client) tool with variable_substitution and exit_on_error configured in your local machine",
        "Review this documentation page: Snowflake Native SDK for Connectors and keep it opened online or printed from your browser\nReview this quickstart: Connector Native Java SDK (optional, but recommended)\nThe quickstart uses an example connector based on a template and it can be referenced to check out example implementations of various components.",
        "To initialize a project, clone the Native SDK for Connectors repository from GitHub\nand copy the /templates/native-sdk-connectors-java-template directory to the desired project location.\nThis template contains all the code required to deploy a working Connector Native Application.\nOnce this is done the template is ready to be deployed.",
        "The template is ready to be deployed out of the box and provides a convenience script that handles the whole process for you.\nBefore deploying the Connector, a snowsql connection must be specified. To do so, open the Makefile and put the name of the connection into the CONNECTION environmental variable.",
        "To quickly deploy the application go into the main directory of the template and execute the following command:",
        "This command does the following things:",
        "Removes previously existing APPLICATION and APPLICATION PACKAGE from the Snowflake account.",
        "Copies the SDK jar and sql files extracted from the jar to the target sf_build directory.",
        "Copies the custom streamlit and java components of the application to sf_build directory.",
        "Creates a new APPLICATION PACKAGE from the files in sf_build directory inside a Snowflake account.",
        "Creates a new APPLICATION instance inside a Snowflake account.",
        "This process takes around 2-3 minutes to complete. After it is finished, navigate to the Data Products -> Apps tab inside Snowflake,\nyour Connector should be visible there. If you have a lot of applications and have trouble finding it, try typing NATIVE_SDK_CONNECTOR_TEMPLATE in the search bar,\nor in the case of a custom APPLICATION name use the custom name instead.\nThis Connector is ready to be configured. The following steps guide you through the process and explain how to customize each of the steps along the way.",
        "If you need to redeploy your connector during any steps of this tutorial, for example to test your changes, then just rerun the above command.",
        "Right after deployment the Connector is in its Wizard phase. This phase consists of a few steps that guide the end user through all the necessary configurations.\nThe first step is the Prerequisites step. It is optional and might not be necessary for every connector.\nPrerequisites are usually actions required from the user outside of the application, for example running queries through the worksheet, doing some configurations on the source system side, etc.",
        "Read more about prerequisites:",
        "Prerequisites",
        "The contents of each prerequisite are retrieved directly from the internal table (STATE.PREREQUISITES) inside the connector.\nThey can be customized through the setup.sql script.\nHowever, keep in mind that the setup.sql script is executed on every installation, upgrade and downgrade of the application.\nThe inserts must be idempotent, because of this it is recommended to use merge query as in the example below:",
        "The next step of the Wizard Phase is the connector configuration step. During this step you can configure database objects and permissions required by the connector.\nThis step allows for the following configuration properties to be specified:",
        "warehouse",
        "destination_database",
        "destination_schema",
        "operational_warehouse",
        "global_schedule",
        "data_owner_role",
        "agent_username",
        "agent_role",
        "If you need any other custom properties, they can be configured in one of the next steps of the Wizard phase. For more information on each of the properties see:",
        "Connector configuration",
        "Additionally, the streamlit component (streamlit/wizard/connector_config.py) provided in the template shows how to trigger permissions-sdk and requests some grants from the end-user.\nAs long as the available properties satisfy the needs of the connector then there is no need to overwrite any of the backend classes,\nalthough this is still possible the same way as for the components in the further steps of the configuration.",
        "For more information on internal procedures and Java objects see:",
        "Connector configuration reference",
        "The provided streamlit example allows for requesting account level grants like create database and execute tasks.\nIt also allows the user to specify a warehouse reference through the permissions-sdk popup.",
        "In the template, the user is asked to only provide the destination_database and destination_schema.\nHowever, a TODO comment in streamlit/wizard/connector_configuration.py contains commented code that can be reused to display more input boxes in the streamlit UI.",
        "The next step of the Wizard Phase is the connection configuration step.\nThis step allows the end-user to configure external connectivity parameters for the connector.\nThis configuration may include identifiers of objects like secrets, integrations, etc.\nBecause this varies depending on the source system for the data ingested by the connector,\nthis is the first place where bigger customizations have to be made in the source code.",
        "For more information on connection configuration see:",
        "Connection configuration",
        "Connection configuration reference",
        "Starting with the streamlit UI side (streamlit/wizard/connection_config.py file) you need to add text boxes for all needed parameters.\nAn example text box is implemented for you and if you search the code in this file, you can find a TODO with commented code for a new field.",
        "After the properties are added to the form, they need to be passed to the backend layer of the connector. To do so, two additional places must be modified in the streamlit files.\nThe first one is the finish_config function in the streamlit/wizard/connection_config.py file. The state of the newly added text boxes must be read here. Additionally, it can be validated if needed, and then passed to the set_connection_configuration function.\nFor example if additional_connection_property was added it would look like this after the edits:",
        "Then the set_connection_configuration function must be edited, it can be found in the streamlit/native_sdk_api/connection_config.py file.\nThis function is a proxy between streamlit UI and the underlying SQL procedure, which is an entry points to the backend of the connector.",
        "After doing this the new property is saved in the internal connector table, which contains configuration. However, this is not the end of the possible customisations.\nSome backend components can be customized too, look for the following comments in the code to find them:",
        "TODO: IMPLEMENT ME connection configuration validate",
        "TODO: IMPLEMENT ME connection callback",
        "TODO: IMPLEMENT ME test connection",
        "The validate part allows for any additional validation on the data received from the UI. It can also transform the data for example like making them lower case,\ntrimming or checking that objects with provided names actually exist inside Snowflake.",
        "Connection callback is a part that lets you perform any additional operation based on the config, for example alter procedures that need to use external access integrations.",
        "Test connection is a final component of the connection configuration, it checks whether the connection can be established between the connector and the source system.",
        "For more information on those internal components see:",
        "Connection configuration",
        "Connection configuration reference",
        "Example implementations might look like this:",
        "Thr finalize connector configuration step is the final step of the Wizard Phase. This step has multiple responsibilities.\nFirst, it allows user to specify any additional configuration needed by the connector.\nSecond, it creates sink database, schema and if needed some tables and views for the ingested data.\nLastly, it initializes internal components such as scheduler and task reactor.",
        "For more information on configuration finalization please see:",
        "Finalize configuration",
        "Finalize configuration reference",
        "For more information on task reactor and scheduling please see:",
        "Task reactor",
        "Task reactor SQL reference",
        "Ingestion scheduler",
        "Ingestion scheduler reference",
        "Similarly to the connection configuration step, customisation can be started with the streamlit UI. streamlit/wizard/finalize_config.py contains a form with an example property.\nMore properties can be added according to the connector needs. To add another property look for a TODO comment, that contains example code of adding a new property in the mentioned file.",
        "After adding the text box for a new property it needs to be passed to the backend. To do so, modify the finalize_configuration function in the same file:",
        "Next, open streamlit/native_sdk_api/finalize_config.py and add it to the following function:",
        "Again, similarly to the connection configuration step, this step also allows for the customisation of various backend components, they can be found using the following phrases in code:",
        "TODO: IMPLEMENT ME validate source",
        "TODO: IMPLEMENT ME finalize internal",
        "The validate source part is responsible for performing more sophisticated validations on the source systems.\nIf the previous test connection only checked that a connection can be established,\nthen validate source could check access to specific data in the system, for example, extracting a single record of data.",
        "Finalize internal is an internal procedure responsible for initializing task reactor and scheduler, creating a sink database and necessary nested objects.\nIt can also be used to save the configuration provided during the finalize step (this configuration is not saved by default).",
        "More information on the internal components can be found in:",
        "Finalize configuration",
        "Finalize configuration reference",
        "Additionally, input can be validated using FinalizeConnectorInputValidator interface and providing it to the finalize handler (check the TemplateFinalizeConnectorConfigurationCustomHandler).\nMore information on using builders can be found in:",
        "Stored procedures and handlers customization",
        "Example implementation of the validate source might look like this:",
        "After the Wizard Phase is completed, the connector is ready to start ingesting data. But first, resources must be implemented and configured.\nA resource is an abstraction describing a specific set of data in the source system, for example a table, an endpoint, a file, etc.",
        "Various source systems might need various information about a resource,\nfor that reason, a resource definition needs to be customized according to the specific needs.\nTo do so, go to the streamlit/daily_use/data_sync_page.py file. There you can find a TODO about adding text boxes for resource parameters.\nThe resource parameters should allow for the identification and retrieval of data from the source system.\nThose parameters can be then extracted during the ingestion:",
        "Once all necessary properties are added to the form, they can be passed to the backend.\nFirst, the state of the text fields has to be extracted and passed to the API level queue_resource method in streamlit/daily_use/data_sync_page.py:",
        "Then create_resource function from the streamlit/native_sdk_api/resource_management.py needs to be updated:",
        "The PUBLIC.CREATE_RESOURCE() procedure allows the developer to customize its\u2019 execution by implementing an own logic\nthat is plugged in to several places of the main execution flow. The SDK allows the developer to:",
        "Validate the resource before it\u2019s created. The logic should be implemented in PUBLIC.CREATE_RESOURCE_VALIDATE() procedure.",
        "Do some custom operations before the resource is created. The logic should be implemented in PUBLIC.PRE_CREATE_RESOURCE() procedure.",
        "Do some custom operations after the resource is created. The logic should be implemented in PUBLIC.POST_CREATE_RESOURCE() procedure.",
        "More information about PUBLIC.CREATE_RESOURCE() procedure customization can be found here:",
        "Create resource",
        "Create resource reference",
        "This class is a handler for the PUBLIC.CREATE_RESOURCE() procedure. Here, you can inject the Java implementations\nof handlers for callback procedures mentioned before. By default, the Template provides mocked Java implementations of\ncallback handlers in order to get rid of calling SQL procedures that extend whole procedure execution time. Java\nimplementations make the execution faster. These mocked implementations do nothing apart from returning a success response.\nYou can either provide the custom implementation to the callback classes prepared by the template or create these callbacks\nfrom scratch and inject them to the main procedure execution flow in the handler builder.",
        "In order to implement the custom logic to callback methods that are called by default, look for the following phrases\nin the code:",
        "TODO: IMPLEMENT ME create resource validate",
        "TODO: IMPLEMENT ME pre create resource callback",
        "TODO: IMPLEMENT ME post create resource callback",
        "To perform ingestion of data you need to implement a class that will handle the connection with the source system and retrieve data, based on the resource configuration.\nScheduler and Task Reactor modules will take care of triggering and queueing of ingestion tasks.",
        "Ingestion logic is invoked from the TemplateIngestion class, look for TODO: IMPLEMENT ME ingestion in the code\nand replace the random data generation with the data retrieval from the source system.\nIf you added some custom properties to the resource definition, they can be fetched from the internal connectors tables using ResourceIngestionDefinitionRepository and properties available in the TemplateWorkItem:",
        "resourceIngestionDefinitionId",
        "ingestionConfigurationId",
        "For example retrieving data from some webservice MIGHT look like this:",
        "Once the logic of creating resources and the their ingestion is implemented, you can manage their lifecycle by the following\nprocedures:",
        "PUBLIC.ENABLE_RESOURCE() - this procedure enables a particular resource, meaning that it will be scheduled for ingestion",
        "PUBLIC.DISABLE_RESOURCE() - this procedure disables a particular resource, meaning that its\u2019 ingestion scheduling will be stopped",
        "PUBLIC.UPDATE_RESOURCE() - this procedure allows to update the ingestion configurations of a particular resource. It isn\u2019t implemented in the Streamlit UI by default because sometimes it may be undesirable by the developer to allow the connector user to customize the ingestion configuration (revoke grants on this procedure to application role ACCOUNTADMIN in order to disallow its\u2019 usage completly).",
        "All these procedures have Java handlers and are extended with callbacks that allow to customize their execution. You can inject\ncustom implementations of callbacks using builder of these handlers. By default, the Template provides mocked Java implementations of\ncallback handlers in order to get rid of calling SQL procedures that extend whole execution time of mentioned procedures.\nThese mocked implementations do nothing apart from returning a success response. You can either provide the custom implementation\nto the callback classes prepared by the template or create these callbacks from scratch and inject them to the main procedure\nexecution flow in the handler builders.",
        "This class is a handler for the PUBLIC.ENABLE_RESOURCE() procedure, which can be extended with the callbacks that are\ndedicated to:",
        "Validate the resource before it\u2019s enabled. Look for TODO: IMPLEMENT ME enable resource validate phrase in the code in order to provide the custom implementation.",
        "Do some custom operations before the resource is enabled. Look for TODO: IMPLEMENT ME pre enable resource phrase in the code in order to provide the custom implementation.",
        "Do some custom operations after the resource is enabled. Look for TODO: IMPLEMENT ME post enable resource phrase in the code in order to provide the custom implementation.",
        "Learn more from the PUBLIC.ENABLE_RESOURCE() procedure detailed documentations:",
        "Enable resource",
        "Enable resource reference",
        "This class is a handler for the PUBLIC.DISABLE_RESOURCE() procedure, which can be extended with the callbacks that are\ndedicated to:",
        "Validate the resource before it\u2019s disabled. Look for TODO: IMPLEMENT ME disable resource validate phrase in the code in order to provide the custom implementation.",
        "Do some custom operations before the resource is disabled. Look for TODO: IMPLEMENT ME pre disable resource phrase in the code in order to provide the custom implementation.",
        "Learn more from the PUBLIC.DISABLE_RESOURCE() procedure detailed documentations:",
        "Disable resource",
        "Disable resource reference",
        "This class is a handler for the PUBLIC.UPDATE_RESOURCE() procedure, which can be extended with the callbacks that are\ndedicated to:",
        "Validate the resource before it\u2019s updated. Look for TODO: IMPLEMENT ME update resource validate phrase in the code in order to provide the custom implementation.",
        "Do some custom operations before the resource is updated. Look for TODO: IMPLEMENT ME pre update resource phrase in the code in order to provide the custom implementation.",
        "Do some custom operations after the resource is updated. Look for TODO: IMPLEMENT ME post update resource phrase in the code in order to provide the custom implementation.",
        "Learn more from the PUBLIC.UPDATE_RESOURCE() procedure detailed documentations:",
        "Update resource",
        "Update resource reference",
        "The template contains a settings tab that lets you view all the configuration made before.\nHowever, if configuration properties were customized, then this view also needs some customisations.\nSettings tab code can be found in the streamlit/daily_use/settings_page.py file.\nTo customize it, simply extract the values from the configuration for the keys that were added in the respective configurations.",
        "For example, if earlier additional_connection_property was added in the connection configuration step, then it could be added like this:",
        "Was this page helpful?"
    ]
}