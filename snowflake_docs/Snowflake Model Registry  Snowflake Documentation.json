{
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-ml/model-registry/overview",
    "title": "Snowflake Model Registry | Snowflake Documentation",
    "paragraphs": [
        "Note",
        "The model registry API described in this topic is generally available as of package version 1.5.0.",
        "The Snowflake Model Registry lets you securely manage models and their metadata in Snowflake, regardless of origin. The\nmodel registry stores machine learning models as first-class schema-level objects in Snowflake so they can easily be\nfound and used by others in your organization. You can create registries and store models in them using Python classes in the\nSnowpark ML library. Models can have multiple versions, and you can designate a version as the default.",
        "After you have stored a model, you can invoke its methods (equivalent to functions or stored procedures) to perform\nmodel operations, such as inference, in a Snowflake virtual warehouse.",
        "Tip",
        "For an example of an end-to-end workflow in Snowpark ML, including the Snowflake Model Registry, see Introduction to Machine Learning with Snowpark ML.",
        "If you have models in Microsoft Azure Machine Learning or in Amazon SageMaker, see Deploying Models from Azure ML and SageMaker to Snowpark ML.",
        "The most important classes in the Snowflake Model Registry Python API are:",
        "snowflake.ml.registry.Registry:\nManages models within a schema.",
        "snowflake.ml.model.Model:\nRepresents a model.",
        "snowflake.ml.model.ModelVersion:\nRepresents a version of a model.",
        "The Snowflake Model Registry supports the following types of models:",
        "Snowpark ML Modeling",
        "scikit-learn",
        "XGBoost",
        "LightGBM",
        "CatBoost",
        "PyTorch",
        "TensorFlow",
        "MLFlow PyFunc",
        "Sentence Transformer",
        "Hugging Face pipeline",
        "Other types of models via the snowflake.ml.model.CustomModel class (see Storing Custom Models in the Snowflake Model Registry)",
        "This topic describes how to perform registry operations in Python using Snowpark ML. You can also perform many registry\noperations in SQL; see Model commands.",
        "To create a model, you must either own the schema where the model is created or have the CREATE MODEL privilege on it.\nTo use a model, you must either own the model or have the USAGE privilege on it. The USAGE privilege allows grantees to\nuse the model for inference without being able to see any of its internals.",
        "If a user\u2019s role has USAGE on a model, it appears in Snowsight\u2019s model registry page.\nFor details, see Access control privileges.",
        "Note",
        "Models currently do not support replication.",
        "The Snowflake Model Registry currently has the following limitations:",
        "The registry cannot be used in Snowflake Native Apps.",
        "Models cannot be shared or cloned and are skipped during replication.",
        "Versions 1.5.0 and 1.5.1 of the snowflake-ml-python package have the following known issues. Until these are\naddressed, use the provided workaround.",
        "In Snowflake release 8.23 and earlier, the library does not work in\nowner\u2019s rights stored procedures.\nUse caller\u2019s rights stored procedures instead.",
        "In stored procedures, logging a model requires embedding a copy of the local Snowpark ML\nlibrary in the model. Specify the embed_local_ml_library option in the log_model call as shown:",
        "The following limits apply to models and model versions:",
        "Models",
        "Maximum of 1000 versions",
        "Model versions",
        "Maximum of 10 methods",
        "Maximum of 10 imports",
        "Maximum of 500 arguments per method",
        "Maximum metadata (including metrics) of 100 KB",
        "Maximum total model size of 5 GB",
        "Maximum config file size of 250 KB, including conda.yml and other manifest files that log_model generates internally.\n(If a model has many functions and all of them have many arguments, for example, this limit might be exceeded.)",
        "Models are first-class Snowflake objects and can be organized within a database and schema along with other Snowflake\nobjects. The Snowflake Model Registry provides a Python class for managing models within a schema. Thus, any Snowflake schema\ncan be used as a registry. It is not necessary to initialize or otherwise prepare a schema for this purpose. Snowflake\nrecommends creating one or more dedicated schemas for this purpose, such as ML.REGISTRY. You can create the schema using\nCREATE SCHEMA.",
        "Before you can create or modify models in the registry, you must open the registry. Opening the registry returns a\nreference to it, which you can then use to add new models and obtain references to existing models.",
        "Adding a model to the registry is called logging the model. Log a model by calling the registry\u2019s log_model\nmethod. This method serializes the model \u2014 a Python object \u2014 and creates a Snowflake model object from it. This method also adds metadata, such as a description, to the model as specified in the log_model call.",
        "Each model can have unlimited versions. To log additional versions of the model, call log_model again with\nthe same model_name but a different version_name.",
        "You cannot add tags to a model when it is added to the registry, because tags are attributes of the model, and\nlog_model adds a specific model version, only creating a model when adding its first version. You can update\nthe model\u2019s tags after logging the first version of the model.",
        "In the following example, clf, short for \u201cclassifier,\u201d is the Python model object, which was already\ncreated elsewhere in your code. You can add a comment at registration time, as shown here. The combination of\nname and version must be unique in the schema. You may specify conda_dependencies lists; the\nspecified packages will be deployed with the model.",
        "The arguments of log_model are described here.",
        "Required arguments",
        "Argument",
        "Description",
        "model",
        "The Python model object of a supported model type. Must be serializable (\u201cpickleable\u201d).",
        "model_name",
        "The model\u2019s name, used with version_name to identify the model in the registry. The name cannot be\nchanged after the model is logged. Must be a valid Snowflake identifier.",
        "Note",
        "The combination of model name and version must be unique in the schema.",
        "Optional arguments",
        "Argument",
        "Description",
        "version_name",
        "String specifying the model\u2019s version, used with model_name to identify the model in the registry.\nMust be a valid Snowflake identifier. If missing, a human-readable\nversion name is generated automatically.",
        "code_paths",
        "List of paths to directories of code to import when loading or deploying the model.",
        "comment",
        "Comment, for example a description of the model.",
        "conda_dependencies",
        "List of Conda packages required by your model. This argument specifies package names\nand optional versions in Conda format,\nthat is, \"[channel::]package [operator version]\". If you do not specify a channel, the Snowflake channel is assumed.",
        "ext_modules",
        "List of external modules to pickle with the model. Supported with scikit-learn, Snowpark ML, PyTorch, TorchScript, and custom models.",
        "metrics",
        "Dictionary that contains metrics linked to the model version.",
        "options",
        "Dictionary that contains options for model creation. The following options are available for all model types:",
        "embed_local_ml_library: whether to embed a copy of the local Snowpark ML library into the model. Default: False.",
        "relax_version: whether to relax the version constraints of the dependencies. This replaces version specifiers like\n==x.y.z with specifiers like <=x.y, <(x+1). Default: True.",
        "method_options: A dictionary of per-method options, where the key is the name of a method and the value is a dictionary\nthat contains one or more of the options described here. The available options are:",
        "case_sensitive: Indicates whether the method and its signature are case-sensitive. Case-sensitive methods must be double-quoted\nwhen used in SQL. This option also allows non-alphabetic characters in method names. Default: False.",
        "max_batch_size: Maximum batch size that the method will accept when called in the warehouse. Default: None (the batch\nsize is automatically determined).",
        "Individual model types may support additional options. See Notes on specific model types.",
        "pip_requirements",
        "List of package specs for PyPI packages required by your model.",
        "python_version",
        "The version of Python in which the model will run. Defaults to None, which designates the latest version\navailable in the warehouse.",
        "sample_input_data",
        "A DataFrame that contains sample input data. The feature names required by the model and their types are\nextracted from this DataFrame. Either this argument or signatures must be provided for all models except Snowpark ML\nand MLFlow models and Hugging Face pipelines.",
        "signatures",
        "Model method signatures as a mapping from target method name to signatures of input and output. Either this argument or\nsample_input_data must be provided for all models except Snowpark ML and MLFlow models and Hugging Face pipelines.",
        "task",
        "The task defining the problem the model is meant to solve. If unspecified, best effort is made to infer the model task from\nthe model class or it is set to type_hints.Task.UNKNOWN. Check snowflake.ml.model.type_hints for all task options.",
        "log_model returns a snowflake.ml.model.ModelVersion object, which represents the version of the model\nthat was added to the registry.",
        "After registration, the model itself cannot be modified (although you can change its metadata). To delete a model and all\nits versions, use the registry\u2019s delete_model method.",
        "After a model has been logged, its artifacts (the files backing the model, including its serialized Python objects and\nvarious metadata files such as its manifest) are available on an internal stage. Artifacts cannot be modified, but you\ncan view or download the artifacts of models you own.",
        "Note",
        "Having the USAGE privilege on a model does not allow you to access its artifacts; ownership is required.",
        "You can access model artifacts from a stage using, for example, the GET command\nor its equivalent in Snowpark Python,\nFileOperation.get.",
        "However, you cannot address model artifacts using the usual stage path syntax. Instead, use a snow:// URL, a more\ngeneral way to specify the location of objects in Snowflake. For example, a version inside a model can be specified by a\nURL of the form snow://model/<model_name>/versions/<version_name>/.",
        "Knowing the of name of the model and the version you want, you can use the\nLIST command to view the artifacts of the model as follows:",
        "The output resembles:",
        "To retrieve one of these artifacts, use the SQL GET command:",
        "Or the equivalent with Snowpark Python:",
        "Note",
        "The names and organization of a model\u2019s artifacts can vary depending on the type of the model and might change.\nThe preceding example artifact list is intended to be illustrative, not authoritative.",
        "Use the registry\u2019s delete_model method to delete a model and all its versions:",
        "Tip",
        "You can also delete models in SQL using DROP MODEL.",
        "To get information about each model, use the show_models method:",
        "Tip",
        "In SQL, use SHOW MODELS to get a list of models.",
        "The result of show_models is a pandas DataFrame. The available columns are listed here:",
        "Column",
        "Description",
        "created_on",
        "Date and time when the model was created.",
        "name",
        "Name of the model.",
        "database_name",
        "Database in which the model is stored.",
        "schema_name",
        "Schema in which the model is stored.",
        "owner",
        "Role that owns the model.",
        "comment",
        "Comment for the model.",
        "versions",
        "JSON array listing versions of the model.",
        "default_version_name",
        "Version of the model used when referring to the model without a version.",
        "To get a list of the models in the registry instead, each as a Model instance, use the models method:",
        "To get a reference to a specific model from the registry by name, use the registry\u2019s get_model method:",
        "Note",
        "Model instances are not copies of the original logged Python model object; they are references to the underlying\nmodel object in the registry.",
        "After you have a reference to a model, either one from the list returned by the models method or one retrieved using\nget_model, you can work with its metadata and\nits versions.",
        "You can view and update a model\u2019s metadata attributes in the registry, including its name, comment, tags, and metrics.",
        "Use the model\u2019s comment attribute to retrieve and update the model\u2019s comment:",
        "Note",
        "The description attribute is a synonym for comment. The previous code can also be written this way:",
        "Tip",
        "You can also set a model\u2019s comment in SQL by using ALTER MODEL.",
        "Tags are metadata used to record a model\u2019s purpose, algorithm, training data set, lifecycle stage, or other information\nyou choose. You can set tags when the model is registered or at any time afterward. You can also update the values of\nexisting tags or remove tags entirely.",
        "Note",
        "You must define the names of all tags (and potentially their possible values) first by using CREATE TAG. See\nObject Tagging.",
        "To get all of a model\u2019s tags as a Python dictionary, use show_tags:",
        "To add a new tag or change the value of an existing tag, use set_tag:",
        "To retrieve the value of a tag, use get_tag:",
        "To remove a tag, use unset_tag:",
        "Tip",
        "You can also set a model\u2019s comment in SQL by using ALTER MODEL.",
        "Use the rename method to rename or move a model. Specify a fully qualified name as the new name to move the model to\na different database or schema.",
        "Tip",
        "You can also rename a model in SQL using ALTER MODEL.",
        "A model can have unlimited versions, each identified by a string. You can use any version naming convention that you\nlike. Logging a model actually logs a specific version of the model. To log additional versions of a model, call\nlog_model again with the same model_name but a different version_name.",
        "Tip",
        "In SQL, use SHOW VERSIONS IN MODEL to see the versions of a model.",
        "A version of a model is represented by an instance of the snowflake.ml.model.ModelVersion class.",
        "To get a list of all the versions of a model, call the model object\u2019s versions method. The result is a list of\nModelVersion instances:",
        "To get information about each model as a DataFrame instead, call the model\u2019s show_versions method:",
        "The resulting DataFrame contains the following columns:",
        "Column",
        "Description",
        "created_on",
        "Date and time when the model version was created.",
        "name",
        "Name of the version.",
        "database_name",
        "Database in which the version is stored.",
        "schema_name",
        "Schema in which the version is stored.",
        "model_name",
        "Name of the model that this version belongs to.",
        "is_default_version",
        "Boolean value indicating whether this version is the model\u2019s default version.",
        "functions",
        "JSON array of the names of the functions available in this version.",
        "metadata",
        "JSON object containing metadata as key-value pairs ({} if no metadata is specified).",
        "user_data",
        "JSON object from the user_data section of the model definition manifest ({} if no user data is specified).",
        "You can delete a model version by using the model\u2019s delete_version method:",
        "Tip",
        "You can also delete a model version in SQL by using ALTER MODEL \u2026 DROP VERSION.",
        "A version of a model can be designated as the default model. Retrieve or set the model\u2019s default attribute to obtain\nthe current default version (as a ModelVersion object) or to change it (using a string):",
        "Tip",
        "In SQL, use ALTER MODEL to set the default version.",
        "You can assign an alias to a model version by using the SQL ALTER MODEL command.\nYou can use an alias wherever a version name is required, such as when getting a reference to a model version, in Python\nor in SQL. A given alias can be assigned to only one model version at a time.",
        "In addition to aliases you create, the following system aliases are available in all models:",
        "DEFAULT refers to the default version of the model.",
        "FIRST refers to the oldest version of the model by creation time.",
        "LAST refers to the newest version of the model by creation time.",
        "Alias names you create must not be the same as any existing version name or alias in the model, including system aliases.",
        "To get a reference to a specific version of a model as a ModelVersion instance, use the model\u2019s version method.\nUse the model\u2019s default attribute to get the default version of the model:",
        "After you have a reference to a specific version of a model (such as the variable mv in this example), you can\nretrieve or update its comments or metrics and call the model\u2019s methods (or functions) as shown in the following sections.",
        "As with models, model versions can have comments, which can be accessed and set via the model version\u2019s comment or\ndescription attribute:",
        "Tip",
        "You can also change a model version\u2019s comment in SQL by using ALTER MODEL \u2026 MODIFY VERSION.",
        "Metrics are key-value pairs used to track prediction accuracy and other model version characteristics. You can set\nmetrics when creating a model version or set them using the set_metric method. A metric value can be any Python\nobject that can be serialized to JSON, including numbers, strings, lists, and dictionaries. Unlike tags, metric names\nand possible values do not need to be defined in advance.",
        "A test accuracy metric might be generated using sklearn\u2019s accuracy_score:",
        "The confusion matrix can be generated similarly using sklearn:",
        "Then you can set these values as metrics:",
        "To retrieve a model version\u2019s metrics as a Python dictionary, use show_metrics:",
        "To delete a metric, call delete_metric:",
        "Tip",
        "You can also modify a model version\u2019s metrics (which are stored in as metadata) in SQL by using\nALTER MODEL \u2026 MODIFY VERSION.",
        "The model registry can explain a model\u2019s results, telling you which input features contribute most to predictions, by calculating\nShapley values. This preview feature is available by default in all\nmodel views created in Snowflake 8.31 and later through the underlying model\u2019s explain method. You can call explain from SQL or via a model view\u2019s\nrun method in Python.",
        "For details on this feature, see Model Explainability.",
        "Use mv.export to export a model\u2019s files to a local directory; the directory is created if it does not exist:",
        "By default, the exported files include the code, the environment to load the model, and model weights. To also\nexport the files needed to run the model in a warehouse, specify export_mode = ExportMode.FULL:",
        "Use mv.load to load the original Python model object that was originally added to the registry. You can then\nuse the model for inference just as though you had defined it in your Python code:",
        "To ensure proper functionality of a model loaded from the registry, the target Python environment (that is, the\nversions of the Python interpreter and of all libraries) should be identical to the environment from which the model\nwas logged. Specify force=True in the load call to force the model to be loaded even if the environment is\ndifferent.",
        "Tip",
        "To make sure your environment is the same as the one where the model is hosted, download a copy of the conda environment\nfrom the model registry:",
        "Then create a new conda environment from this file:",
        "The optional options argument is a dictionary of options for loading the model. Currently, the argument supports\nonly the use_gpu option.",
        "Option",
        "Type",
        "Description",
        "Default",
        "use_gpu",
        "bool",
        "Enables GPU-specific loading logic.",
        "False",
        "The following example illustrates the use of the options argument:",
        "Model versions can have methods, which are attached functions that can be executed to perform inference or other model\noperations. The versions of a model can have different methods, and the signatures of these methods can also differ.",
        "To call a method of a model version, use mv.run, where mv is a ModelVersion object. Specify the name of the\nfunction to be called and pass a Snowpark or pandas DataFrame that contains the inference data, along with any required\nparameters. The method is executed in a Snowflake warehouse.",
        "The return value of the method is a Snowpark or pandas DataFrame, matching the type of DataFrame passed in.\nSnowpark DataFrames are evaluated lazily, so the method is run only when the DataFrame\u2019s collect, show,\nor to_pandas method is called.",
        "Note",
        "Invoking a method runs it in the warehouse specified in the session you\u2019re using to connect to the registry.\nSee Specifying a Warehouse.",
        "The following example illustrates running the predict method of a model. This model\u2019s predict method does not\nrequire any parameters besides the inference data (test_features here). If it did, they would be passed as\nadditional arguments after the inference data:",
        "To see what methods can be called on a given model, call mv.show_functions. The return value of this method is a\nlist of ModelFunctionInfo objects. Each of these objects includes the following attributes:",
        "name: The name of the function that can be called from Python or SQL.",
        "target_method: The name of the Python method in the original logged model.",
        "Tip",
        "You can also call model methods in SQL. See Model methods.",
        "Preview Feature \u2014 Open",
        "Available to all accounts.",
        "The model registry can store two types of models. You can distinguish them using the MODEL_TYPE column in the output of\nSHOW MODELS.",
        "CORTEX_FINETUNED: Models generated with Cortex Fine-tuning,\nwhich do not contain user code. To share this type of model, use Data Sharing.",
        "USER_MODEL: Models that contain user code, such as models developed using\nSnowpark ML modeling classes. These models cannot currently be shared.\nThe ability to share models that contain user code will be available in a future release.",
        "Using the Snowflake Model Registry incurs standard Snowflake consumption-based costs. These include:",
        "Cost of storing model artifacts, metadata, and functions. For general information about storage costs, see Exploring storage cost.",
        "Cost of copying files between stages to Snowflake. See COPY FILES.",
        "Cost of serverless model object operations through the Snowsight UI or the SQL or Python interface, such as\nshowing models and model versions and altering model comments, tags, and metrics.",
        "Warehouse compute costs, which vary depending on the type of model and the quantity of data used in inference.\nFor general information about Snowflake compute costs, see Understanding compute cost.\nWarehouse compute costs are incurred for:",
        "Model and version creation operations",
        "Invoking a model\u2019s methods",
        "This section provides additional information on logging specific types of models into the Snowflake Model Registry.",
        "The registry supports models created using Snowpark ML modeling APIs (models derived from\nsnowpark.ml.modeling.framework.base.BaseEstimator). The following additional options can be used in the options dictionary\nwhen you call log_model:",
        "Option",
        "Description",
        "target_methods",
        "A list of the names of the methods available on the model object. Snowpark ML models have the following target methods by default, assuming the method exists:\npredict, transform, predict_proba, predict_log_proba, decision_function.",
        "You do not need to specify sample_input_data or signatures when logging a Snowpark ML model;\nthese are automatically inferred during fitting.",
        "The registry supports models created using scikit-learn (models derived from sklearn.base.BaseEstimator or\nsklearn.pipeline.Pipeline). The following additional options can be used in the options dictionary\nwhen you call log_model:",
        "Option",
        "Description",
        "target_methods",
        "A list of the names of the methods available on the model object. scikit-learn models have the following target methods by default, assuming the method exists:\npredict, transform, predict_proba, predict_log_proba, decision_function.",
        "You must specify either the sample_input_data or signatures parameter when logging a scikit-learn model\nso that the registry knows the signatures of the target methods.",
        "The registry supports models created using XGBoost (models derived from xgboost.XGBModel or xgboost.Booster).\nThe following additional options can be used in the options dictionary when you call log_model:",
        "Option",
        "Description",
        "target_methods",
        "A list of the names of the methods available on the model object. Models derived from XGBModel have the following target methods by default, assuming the method exists:\npredict, predict_proba. (Before v1.4.0, apply was also included.) Models derived from Booster have the predict method by default.",
        "cuda_version",
        "The version of the CUDA runtime to be used when deploying to a platform with GPU; defaults to 11.7. If manually set\nto None, the model cannot be deployed to a platform having a GPU.",
        "You must specify either the sample_input_data or signatures parameter when logging an XGBoost model so\nthat the registry knows the signatures of the target methods.",
        "The registry supports PyTorch models (classes derived from torch.nn.Module or torch.jit.ModuleScript) if the\nmodel\u2019s forward method accepts one or more torch.Tensor instances as input and returns a torch.Tensor or a\ntuple of them. The registry converts between pandas DataFrames and tensors when calling the model and returning the results.\nTensors correspond to columns in the dataframe.",
        "For example, suppose your model accepts two tensors like this:",
        "If you want to pass torch.Tensor([[1,2],[3,4]]) as tensor_1 and torch.Tensor([[5,6], [7,8]]) as\ntensor_2, create a DataFrame like this to pass to the model:",
        "Then the tensors DataFrame looks like this:",
        "Similarly, if your model returns two tensors, such as (torch.Tensor([[1,2],[3,4]]), torch.Tensor([[5,6], [7,8]])),\nthe result is a DataFrame like the one above.",
        "When providing sample input data for a PyTorch model, you must provide either a list of tensors (which will be\nconverted to a pandas DataFrame) or a DataFrame. A list may contain a single tensor, but a tensor on its own is not\naccepted.",
        "The following additional options can be used in the options dictionary when you call log_model:",
        "Option",
        "Description",
        "target_methods",
        "A list of the names of the methods available on the model object. PyTorch models default to forward.",
        "cuda_version",
        "The version of the CUDA runtime to be used when deploying to a platform with GPU; defaults to 11.7. If manually set\nto None, the model cannot be deployed to a platform having a GPU.",
        "You must specify either the sample_input_data or signatures parameter when logging a PyTorch model\nso that the registry knows the signatures of the target methods.",
        "Models that extend tensorflow.Module or tensorflow.keras.Model are supported when they accept and return tensors\nand are compilable or compiled.",
        "The __call__ method for a tensorflow.Module or the call method for a tensorflow.keras.Model accepts one\nor more tensorflow.Tensor or tensorflow.Variable as input and returns a tensorflow.Tensor or\ntensorflow.Variable or a tuple of one of these types.",
        "If your model extends Module, it must be compilable, meaning the __call__ method is decorated with\n@tensorflow.function; see tf.function documentation. If it extends\nModel, it must be compiled; see compile documentation.",
        "The registry converts between pandas DataFrames and tensors when calling the model and returning the results.\nTensors correspond to columns in the dataframe.",
        "For example, suppose your model accepts two tensors like this:",
        "If you want to pass tf.Tensor([[1,2],[3,4]]) as tensor_1 and tf.Tensor([[5,6], [7,8]]) as\ntensor_2, create a DataFrame like this to pass to the model:",
        "Then the tensors DataFrame looks like this:",
        "Similarly, if your model returns two tensors, such as (tf.Tensor([[1,2],[3,4]]), tf.Tensor([[5,6], [7,8]])),\nthe result is a DataFrame like the one above.",
        "When providing sample input data for a TensorFlow model, you must provide either a list of tensors (which will be\nconverted to a pandas DataFrame) or a DataFrame. A list may contain a single tensor, but a tensor on its own is not\naccepted.",
        "The following additional options can be used in the options dictionary when you call log_model:",
        "Option",
        "Description",
        "target_methods",
        "A list of the names of the methods available on the model object. TensorFlow models default to forward.",
        "cuda_version",
        "The version of the CUDA runtime to be used when deploying to a platform with GPU; defaults to 11.7. If manually set\nto None, the model cannot be deployed to a platform having a GPU.",
        "You must specify either the sample_input_data or signatures parameter when logging a TensorFlow model\nso that the registry knows the signatures of the target methods.",
        "MLFlow models that provide a PyFunc flavor are supported. If your MLFlow model has a signature, the signature\nargument is inferred from the model. Otherwise, you must provide either signature or sample_input_data.",
        "The following additional options can be used in the options dictionary when you call log_model:",
        "Option",
        "Description",
        "model_uri",
        "The URI of the artifacts of the MLFlow model. Must be provided if it is not available in the model\u2019s metadata as\nmodel.metadata.get_model_info().model_uri.",
        "ignore_mlflow_metadata",
        "If True, the model\u2019s metadata is not imported to the model object in the registry. Default: False",
        "ignore_mlflow_dependencies",
        "If True, the dependencies in the model\u2019s metadata are ignored, which is useful due to package available\nlimitations in Snowflake warehouses. Default: False",
        "Note",
        "For details on the expected input and output of specific types of Hugging Face pipelines, see\nInferred signatures for Hugging Face pipelines.",
        "The registry supports Hugging Face model classes defined as transformers that derive from transformers.Pipeline.\nThe following code is an example of logging a compatible model:",
        "Important",
        "A model based on huggingface_pipeline.HuggingFacePipelineModel contains only configuration data; the model\nweights are downloaded from the Hugging Face Hub each time the model is used.",
        "Currently, the model registry supports only self-contained models that are ready to run without\nexternal network access configuration.\nTherefore, the best practice is to instead use transformers.Pipeline as shown in the example above. This downloads\nmodel weights to your local system, and log_model then uploads a self-contained model object that does not\nneed internet access.",
        "The registry infers the signatures argument only if the pipeline contains one task from the following list:",
        "conversational",
        "fill-mask",
        "question-answering",
        "summarization",
        "table-question-answering",
        "text2text-generation",
        "text-classification (also called sentiment-analysis)",
        "text-generation",
        "token-classification (also called ner)",
        "translation",
        "translation_xx_to_yy",
        "zero-shot-classification",
        "The sample_input_data argument is completely ignored for Hugging Face models. Specify the signatures argument\nwhen logging a Hugging Face model that is not in the above list so that the registry knows the signatures of the target\nmethods.",
        "To see the inferred signature, use the show_functions method. The following dictionary, for example, is the result of\nlmv.show_functions() where lmv is the model logged above:",
        "With this information, you can call the model as follows:",
        "Many Hugging Face models are large and do not fit in a standard warehouse. Use a Snowpark-optimized warehouse or choose\na smaller version of the model. For example, instead of using the Llama-2-70b-chat-hf model, try\nLlama-2-7b-chat-hf.",
        "Snowflake warehouses do not have GPUs. Use only CPU-optimized Hugging Face models.",
        "Some Hugging Face transformers return an array of dictionaries per input row. The registry converts such output to a\nstring containing a JSON representation of the array. For example, multi-output Question Answering output looks like this:",
        "You must specify either the sample_input_data or signatures parameter when logging a Hugging Face model\nso that the registry knows the signatures of the target methods.",
        "Result:",
        "Was this page helpful?",
        "On this page",
        "Related content"
    ]
}