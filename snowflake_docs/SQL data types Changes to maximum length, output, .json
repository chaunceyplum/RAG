{
    "url": "https://docs.snowflake.com/en/release-notes/bcr-bundles/2024_08/bcr-1779",
    "title": "SQL data types: Changes to maximum length, output, and error messages (Pending) | Snowflake Documentation",
    "paragraphs": [
        "Attention",
        "This behavior change is in the 2024_08 bundle.",
        "For the current status of the bundle, refer to Bundle History.",
        "With this behavior change, compiled SQL expressions and some error messages behave as follows:",
        "In compiled SQL expressions and error messages, Snowflake explicitly specified the length of the data type (for example,\nVARCHAR(16777216)).",
        "When loading objects larger than 16 MB, an error related to parsing or processing a large string or file is returned (for example,\n100069 (22P02): Error parsing JSON: document is too large, max size 16777216 bytes).",
        "In compiled SQL expressions and error messages, Snowflake omits the length of the data type (for example, VARCHAR).",
        "When loading objects larger than 16 MB, an error related to storing a large object is returned (for example,\n100082 (22000): Max LOB size (16777216) exceeded, actual size of parsed column is <actual_size>).",
        "In the past, an error occurred when you attempted to query an object larger than 16 MB (8 MB for BINARY,\nGEOMETRY, and GEOGRAPHY) on a stage. You can now read and process objects up to 128 MB in size. Although\nyou still can\u2019t load objects larger than 16 MB in size in a column or output them in a result set, you\ncan query objects up to 128 MB in size (64 MB for BINARY, GEOMETRY, and GEOGRAPHY) in files on a stage\nand reduce the size of the objects before storing the objects in columns.",
        "For more information, see Reducing the size of objects larger than 16 MB before loading.",
        "The new size limit isn\u2019t explicitly exposed in SQL query output or metadata. However, you can implicitly\nobserve the new increased length by creating or reading objects of a larger size, but not storing them.\nEnabling this feature introduces the following behavior changes:",
        "VARCHAR and BINARY types appear without length in the output of GET_DDL, SHOW, and DESCRIBE commands\nfor column expressions, UDFs, and stored procedures.",
        "For example, VARCHAR is shown instead of VARCHAR(16777216). This change applies only to newly\ncreated objects where you haven\u2019t explicitly specified the length in the DDL statement. The change doesn\u2019t apply\nto existing objects.",
        "Some statements that failed before with a maximum size exceeded (or similar) error will now succeed.",
        "Statements that only load or create, but never store or return, a large value will succeed now.",
        "Some statements that before failed with a maximum size exceeded (or similar) error will keep failing,\nhowever, with a different error code or message.",
        "The new error code and message are still related to exceeding the 16 MB limit, but the error can originate from a\ndifferent part of the execution plan. For example, cannot load value might change to cannot store value\nor cannot output value.",
        "The first change affects all customers. The second and third changes affect customers who try to load or generate\nobjects larger than 16 MB.",
        "Important",
        "We strongly advise against creating logic that depends on error messages associated with objects larger than 16 MB.\nInstead, you can build logic that uses the BIT_LENGTH function to check the size of\nthe value.",
        "There are behavior changes that affect the following types of operations:",
        "Returning metadata for UDFs",
        "Returning metadata for tables with column expressions",
        "Returning metadata for SYSTEM$TYPEOF",
        "Returning metadata for SHOW COLUMNS",
        "For these types of operations, there are changes in metadata in the results set.",
        "Note",
        "This list is not exhaustive.",
        "For new user-defined functions (UDFs) that use VARCHAR or BINARY values as input or output, changes in the metadata for\nDDL statements related to UDFs affect the output returned when you call the GET_DDL\nfunction, run the DESCRIBE FUNCTION statement, or query the\nevent table. The following example creates a UDF:",
        "The metadata returned from a GET_DDL function call changes in the following way:",
        "The metadata returned for a DESCRIBE FUNCTION statement changes in the following way:",
        "For new user-defined functions that return VARCHAR or BINARY values as output, the snow.executable.name attribute in\nthe RESOURCE_ATTRIBUTES column of the\nevent table changes as follows:",
        "For new tables that use VARCHAR or BINARY in column expressions, changes in the metadata for DDL statements related\nto these columns affect the output returned when you call the GET_DDL function.",
        "The following example creates a table with column expression:",
        "The metadata returned from a GET_DDL function call changes in the following way:",
        "The following example creates an external table:",
        "The metadata returned from a GET_DDL function call changes in the following way:",
        "The metadata returned for a call to the SYSTEM$TYPEOF function changes\nin the following way:",
        "This change affects both existing and new tables. The metadata returned for a\nSHOW COLUMNS statement changes in the following way:",
        "There are behavior changes that affect cases when you try to load or process objects larger than 16 MB\nusing the following types of operations:",
        "Loading data by scanning files on a stage",
        "Querying a whole large object from a source file",
        "Including large objects in query results",
        "Creating a large object using aggregation",
        "Note",
        "This list is not exhaustive.",
        "When you attempt to load data larger than 16 MB by scanning files on a stage, an error message is returned.",
        "Loading a whole large object using CREATE TABLE AS SELECT",
        "Loading a whole large object using COPY INTO <table_name> \u2026 FROM SELECT",
        "Loading a whole large object using COPY INTO <table_name> \u2026 FROM <stage_or_location>",
        "A different error message appears when you try to use a CREATE TABLE AS SELECT statement to load objects that\nare larger than 16 MB for VARCHAR, VARIANT, OBJECT, and ARRAY (or larger than 8 MB for BINARY, GEOMETRY, or GEOGRAPHY).\nThe error depends on the type of the source. The same message change applies when an INSERT INTO SELECT statement is\nused for this scenario.",
        "Loading a whole large object from a JSON source",
        "Loading a whole large object from an XML source",
        "The following example tries to load a whole object larger than 16 MB from a JSON source using CREATE TABLE AS SELECT:",
        "The following example tries to load a whole object larger than 16 MB from an XML source using CREATE TABLE AS SELECT:",
        "A different error message appears when you try to use a COPY INTO <table_name> \u2026 FROM SELECT statement to load objects that\nare larger than 16 MB for VARCHAR, VARIANT, OBJECT, and ARRAY (or larger than 8 MB for BINARY, GEOMETRY, or GEOGRAPHY).\nThe error depends on the type of the source.",
        "Loading a whole large object from a JSON source",
        "Loading large nested objects from a JSON source",
        "Loading a whole large object from an XML source",
        "Important",
        "If you attempt to load data that contains objects larger than 16 MB using the COPY INTO command with ON_ERROR=CONTINUE\nand rely on the error messages written in the error log, the change in the error message could cause problems in logic that\ndepends on the error message.",
        "The following example tries to load a whole object larger than 16 MB from a JSON source using COPY INTO <table_name> \u2026 FROM SELECT:",
        "The following example tries to load JSON data when accessing large nested objects:",
        "The following example tries to load a whole object larger than 16 MB from an XML source using COPY INTO <table_name> \u2026 FROM SELECT:",
        "A different error message appears when you try to use a COPY INTO <table_name> \u2026 FROM <stage_or_location> statement to load objects that\nare larger than 16 MB for VARCHAR, VARIANT, OBJECT, and ARRAY (or larger than 8 MB for BINARY, GEOMETRY,\nor GEOGRAPHY). The error depends on the type of the source.",
        "If you use the COPY command with large objects, queries might fail even when the ON_ERROR parameter is\nset to CONTINUE. For more information, see the usage notes for the COPY command.",
        "Loading a whole large object from a JSON source",
        "Loading a whole large object from an XML source",
        "Important",
        "If you attempt to load data that contains objects larger than 16 MB using the COPY INTO command with\nON_ERROR=CONTINUE and rely on the error messages written in the error log, the change in the error\nmessage could cause problems in logic that depends on the message.",
        "The following example tries to load a whole object larger than 16 MB from a JSON source using COPY INTO <table_name> \u2026 FROM <stage_or_location>:",
        "The following example tries to load a whole object larger than 16 MB from an XML source using COPY INTO <table_name> \u2026 FROM <stage_or_location>:",
        "Because objects larger than 16 MB currently are not allowed in a result set, a different error message\nappears when you try to query objects from a source file that are larger than 16 MB for VARCHAR, VARIANT,\nOBJECT, and ARRAY (or larger than 8 MB for BINARY, GEOMETRY, or GEOGRAPHY). The error depends on the type\nof the source.",
        "Querying a whole large object from a JSON source",
        "Querying a whole large object from an XML source",
        "Querying a whole large object from a CSV source",
        "Querying a whole large object from a Parquet source",
        "The following example tries to query a whole object larger than 16 MB from a JSON source:",
        "The following example tries to query a whole object larger than 16 MB from an XML source:",
        "The following example tries to query a whole object larger than 16 MB from a CSV source:",
        "The following example tries to query a whole object larger than 16 MB from a Parquet source:",
        "You can now create objects larger than 16 MB in memory. However, you cannot include these objects in query\nresults or store them in a table. When you attempt to do so, an error message is returned.",
        "Attempting to include an object larger than 16 MB in query results",
        "Attempting to store an object larger than 16 MB in a table",
        "The following query attempts to concatenate two large strings:",
        "The following CREATE TABLE AS SELECT statement attempts to concatenate two large strings:",
        "When you try to create an object larger than 16 MB and return output for it, an error message is returned.",
        "The following example uses the ARRAY_AGG function in a query of a large object column:",
        "Ref: 1779",
        "Was this page helpful?",
        "On this page"
    ]
}