{
    "url": "https://docs.snowflake.com/en//developer-guide/snowpark-ml/overview",
    "title": "Snowflake ML: End-to-End Machine Learning | Snowflake Documentation",
    "paragraphs": [
        "Snowflake ML is an integrated set of capabilities for end-to-end machine learning in a single platform on top of your\ngoverned data.",
        "For out-of-the-box ML workflows in SQL, the ready-to-use ML Functions can help\nshorten development time and democratize ML across your organization. These functions let you train models for business\nuse cases such as forecasting and anomaly detection without writing any code.",
        "For custom ML workflows in Python, data scientists and ML engineers can easily and securely develop and productionize\nscalable features and models without any data movement, silos, or governance tradeoffs. The snowflake-ml-python library\nprovides APIs for developing and deploying your Snowflake ML pipelines.",
        "To build and operationalize models, data scientists and ML engineers can leverage a suite of Snowflake ML features. For\nmodel development, Snowflake ML Modeling APIs offer scalable data loading, feature engineering, and\nmodel training with distributed processing using CPUs or GPUs. For ML Operations (ML Ops), Snowflake ML includes the\nFeature Store and  Model Registry for centralized\nmanagement of features and models in production.",
        "You can use Python APIs from the Snowpark ML library in Snowflake Notebooks,\nSnowsight worksheets. or your local Python IDE of choice.",
        "Snowflake ML components help to streamline the ML lifecycle, as shown here.",
        "The Snowflake Model Registry allows secure deployment and management of models in\nSnowflake, supporting models trained both inside and outside of Snowflake.",
        "The Snowflake Feature Store is an integrated solution for defining, managing, storing\nand discovering ML features derived from your data. The Snowflake Feature Store supports automated, incremental refresh\nfrom batch and streaming data sources, so that feature pipelines need be defined only once to be continuously updated\nwith new data.",
        "Snowflake Datasets provide an immutable, versioned snapshot of your data suitable for ingestion by\nyour machine learning models.",
        "Snowflake Notebooks provide a familiar experience, similar to Jupyter\nnotebooks, for working with Python inside Snowflake. They\u2019re ideal for building custom ML workflows and models using\ntools you already know how to use. Notebooks that run on Snowpark Container Services (SPCS) execute on the\nContainer Runtime for ML, a purpose-built environment for machine learning workflows.",
        "Preview Feature \u2014 Open",
        "Available to all accounts.",
        "Snowflake offers a pre-configured, customizable environment built for a variety of ML development workloads. With a\ncomprehensive set of pre-installed ML packages and frameworks that can be easily extended, data scientists and ML\nengineers can leverage the best of open source directly over their Snowflake data.",
        "WIth easy access to GPUs in the form of Snowpark Container Service (SPCS) compute pools, the flexibility to use any\nopen-source package, and distributed data loading and modeling APIs, Container Runtime for ML is well-suited for\nlarge-scale ML development. Because these notebooks run on Snowpark Container Services, they provide a flexible and\nscalable compute infrastructure optimized for price-performance.",
        "For more information, see Notebooks on Container Runtime for ML and Container Runtime for ML.",
        "The snowflake-ml-python Python package provides Python APIs for the various Snowflake ML workflow components,\nincluding the Snowflake Feature Store, the Snowflake Model Registry, and Dataset versioned data objects. It also\nincludes APIs, based on popular Python ML libraries such as scikit-learn, for building and training your own models at\nscale completely inside the Snowflake cloud. You can use Snowflake ML features in your local Python development environment, in\nSnowsight worksheets, or in Snowflake Notebooks.",
        "Tip",
        "See Introduction to Machine Learning\nfor an example of an end-to-end Snowflake ML workflow.",
        "The snowflake-ml-python Python package also includes the ML Modeling APIs, which support data\npreprocessing, feature engineering, and model training in Snowflake using popular machine learning frameworks, such as\nscikit-learn, xgboost, lightgbm, and pytorch. All processing is performed without the need for any infrastructure\nconfiguration or data movement.",
        "When run from a notebook on Container Runtime for ML, these modeling APIs can run\ndistributed over all available CPU cores or GPUs, depending on the compute pool you\u2019re using. In other cases, the\nprocess is performed in a Snowflake virtual warehouse, where preprocessing and hyperarameter optimization can be\nperformed in distributed fashion over multiple nodes.",
        "Note",
        "Container Runtime for ML is currently in private preview.",
        "See the following resources for information about the Snowflake ML APIs.",
        "End-to-End ML Workflows",
        "Quickstart",
        "Contact your Snowflake representative for early access to documentation on other features currently under development.",
        "Was this page helpful?",
        "On this page"
    ]
}