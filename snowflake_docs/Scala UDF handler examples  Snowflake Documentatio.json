{
    "url": "https://docs.snowflake.com/en/developer-guide/udf/scala/udf-scala-examples",
    "title": "Scala UDF handler examples | Snowflake Documentation",
    "paragraphs": [
        "Preview Feature \u2014 Open",
        "Available to all accounts.",
        "This topic includes simple examples of UDF handler code written in Scala.",
        "For information on using Scala to create a scalar UDF handler, refer to Writing a scalar UDF in Scala. For general\ncoding guidelines, refer to General Scala UDF handler coding guidelines.",
        "The following statements create and call an in-line Scala UDF. This code returns the VARCHAR passed to it.",
        "This function is declared with the optional CALLED ON NULL INPUT clause to indicate that the function is\ncalled even if the value of the input is NULL. (This function would return NULL with or without this clause, but\nyou could modify the code to handle NULL another way, for example, to return an empty string.)",
        "This uses the echo_varchar() UDF defined above. The SQL NULL value is implicitly converted to\nScala Null, and that Scala Null is returned and implicitly converted\nback to SQL NULL:",
        "Call the UDF:",
        "The following code shows how to return a NULL value explicitly. The Scala value Null is converted to\nSQL NULL.",
        "The following example uses the SQL OBJECT data type and the corresponding Scala\ndata type (Map[String, String]), and extracts a value from the OBJECT. This example also shows that you\ncan pass multiple parameters to a Scala UDF.",
        "Create and load a table that contains a column of type OBJECT:",
        "The following example uses the SQL ARRAY data type.",
        "You can read the contents of a file with handler code. For example, you might want to read a file to process unstructured data with the\nhandler.",
        "The file must be on a Snowflake stage that\u2019s available to your handler.",
        "To read the contents of staged files, your handler can read a dynamically-specified file by calling methods of either the\nSnowflakeFile class or the InputStream class.",
        "You might do this if you need to access a file specified by the caller. For more information, see the following in this topic:",
        "Reading a dynamically-specified file with SnowflakeFile",
        "Reading a dynamically-specified file with InputStream",
        "SnowflakeFile provides features not available with InputStream, as described in the following table.",
        "Class",
        "Input",
        "Notes",
        "SnowflakeFile",
        "URL formats:",
        "Scoped URL to reduce the risk of file injection attacks when the function\u2019s caller is not also its owner.",
        "File URL or string path for files that the UDF owner has access to.",
        "The file must be located in a named internal stage or an external stage.",
        "Easily access additional file attributes, such as file size.",
        "InputStream",
        "URL formats:",
        "Scoped URL to reduce the risk of file injection attacks when the function\u2019s caller is not also its owner.",
        "The file must be located in a named internal stage or an external stage.",
        "Note",
        "The UDF owner must have access to any files whose locations are not scoped URLs. You can read these staged files by having the handler\ncode call the SnowflakeFile.newInstance method with a boolean value for a new requireScopedUrl parameter.",
        "The following example uses SnowflakeFile.newInstance while specifying that a scoped URL is not required.",
        "Using methods of the SnowflakeFile class, you can read files from a stage with your handler code. The SnowflakeFile\nclass is included on the classpath available to Scala UDF handlers on Snowflake.",
        "Note",
        "To make your code resilient to file injection attacks, always use a scoped URL when passing a file\u2019s location to a UDF, particularly\nwhen the function\u2019s caller is not also its owner. You can create a scoped URL in SQL using the built-in function\nBUILD_SCOPED_FILE_URL. For more information about what the BUILD_SCOPED_FILE_URL does, see\nIntroduction to unstructured data.",
        "To develop your UDF code locally, add the Snowpark JAR containing SnowflakeFile to your code\u2019s class path. For information about\nsnowpark.jar, see  Setting Up Your Development Environment for Snowpark Scala. Note that Snowpark client applications cannot use this class.",
        "When you use SnowflakeFile, it isn\u2019t necessary to also specify either the staged file or the JAR containing\nSnowflakeFile with an IMPORTS clause when you create the UDF, as in SQL with a CREATE FUNCTION statement.",
        "Code in the following example uses SnowflakeFile to read a file from a specified stage location. Using an\nInputStream from the getInputStream method, it reads the file\u2019s contents into a String variable.",
        "You can read file contents directly into a java.io.InputStream by making your handler function\u2019s argument an InputStream\nvariable. This can be useful when the function\u2019s caller will want to pass a file path as an argument.",
        "Note",
        "To make your code resilient to file injection attacks scoped URLs are required when passing a file\u2019s location to a UDF. You can create a\nscoped URL in SQL using the built-in function BUILD_SCOPED_FILE_URL. For more information about what the BUILD_SCOPED_FILE_URL does,\nsee Introduction to unstructured data.",
        "Code in the following example has a handler function sumTotalSales that takes an InputStream and returns an Int.\nAt run time, Snowflake automatically assigns the contents of the file at the file variable\u2019s path to the stream\nargument variable.",
        "Was this page helpful?",
        "On this page",
        "Related content"
    ]
}