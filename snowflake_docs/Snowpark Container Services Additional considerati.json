{
    "url": "https://docs.snowflake.com/en/developer-guide/snowpark-container-services/additional-considerations-services-jobs",
    "title": "Snowpark Container Services: Additional considerations for services | Snowflake Documentation",
    "paragraphs": [
        "Feature \u2014 Generally Available",
        "Available to accounts in AWS and Microsoft Azure commercial regions, with some exceptions. For more information, see Available regions.",
        "When you start a service (including job services), Snowflake provides credentials to the running containers, enabling your container code to use\ndrivers for connecting to Snowflake and executing SQL (similar to any other code on your computer connecting to Snowflake).\nThe provided credentials authenticate as the owner role (the role that created the service). Snowflake provides some of the information as environment variables\nin your containers.",
        "Every object in Snowflake has an owner role. The service\u2019s owner role determines what capabilities your service is allowed to perform\nwhen interacting with Snowflake. This includes executing SQL, accessing stages, and service-to-service networking.",
        "Note",
        "A service\u2019s owner role refers to the role that created the service. You can also define one or more service roles to manage access to the endpoints the service exposes. For more information, see Managing access to service endpoints.",
        "When you create a service, Snowflake also creates a service user specific to that service. When the service runs a query, it runs the query as the service user, using the service\u2019s owner role. What the service user can do is determined by this owner role.",
        "The service\u2019s owner role cannot be any of the privileged roles, such as ACCOUNTADMIN, SECURITYADMIN, and ORGADMIN. This is to limit what a misbehaving service can do, requiring customers to be more intentional to enable a service to perform administrative operations.",
        "To view the queries issued by a specific service user, you can use the ACCOUNTADMIN role to view the\nquery history.\nThe user name of the service user appears in the following forms:",
        "For a service created before the 8.35 server release, the service user name is of the format SF$SERVICE$unique-id.",
        "For a service created after the 8.35 server release, the service user name is the same as the service name.",
        "Snowflake provides the following environment variables for you to configure a Snowflake client in your service code:",
        "SNOWFLAKE_ACCOUNT: Provides the account locator for the Snowflake account the service is currently running under.",
        "SNOWFLAKE_HOST: Provides the hostname used to connect to Snowflake.",
        "Snowflake also provides an OAuth token in the container in a file named /snowflake/session/token. When creating a\nconnection, you provide this token to the connector.",
        "When creating a connection to Snowflake from a container, you must use SNOWFLAKE_HOST, SNOWFLAKE_ACCOUNT, and the OAuth token.\nYou cannot use the OAuth token without also using SNOWFLAKE_HOST, and you cannot use the OAuth token outside Snowpark Container\nServices. For more information, see  Using an OAuth token to execute SQL.",
        "Note",
        "Using external access integrations to access Snowflake can mean sending potentially sensitive information over the internet.\nWhenever possible, services should use the provided OAuth token to access the SNOWFLAKE_HOST hostname. This avoids the need to access\nSnowflake from the Internet.",
        "For sample code using various Snowflake drivers, see\nSnowflake Connection Samples.",
        "Examples",
        "In Tutorial 2 (see main.py), the code reads the environment variables as follows:",
        "The code passes these variables to a connection creation code for the Snowflake client of choice. The container uses these\ncredentials to create a new session, with the owner role as the primary role, to execute queries. The following example code\nis the minimum needed to create a Snowflake connection in Python:",
        "When you use the default host (that is, you don\u2019t include the host argument when creating a connection), connecting to\nSnowflake using other forms of authentication (such as username and password) is supported. For example, the following\nconnection specifies the user name and password to authenticate:",
        "Using a default host requires external access integration with a network rule allowing access from your service to the\nSnowflake hostname for your account. For example, if your account name is MyAccount, the hostname will be\nmyaccount.snowflakecomputing.com. For more information, see Configuring network egress.",
        "Create a network rule that matches your account\u2019s Snowflake API hostname:",
        "Create an integration using the preceding network rule:",
        "This section explains two concepts:",
        "The logic Snowflake uses to determine the database and schema in which to create your service.",
        "The method through which Snowflake conveys this information to your containers, thus enabling the container code to execute\nSQL in the same database and schema context.",
        "Snowflake uses the service name to determine the database and schema in which to create a service:",
        "Example 1: In the following CREATE SERVICE and EXECUTE JOB SERVICE commands, the service name does not explicitly specify a database and schema name. Snowflake creates the service and the job service in the current database and schema.",
        "Example 2: In the following CREATE SERVICE and EXECUTE JOB SERVICE commands, the service name includes a database and schema name. Snowflake creates the service and job service in the specified database (test_db) and schema (test_schema), regardless of the current schema.",
        "When Snowflake starts a service, it provides the database and schema information to the running containers using the\nfollowing environment variables:",
        "SNOWFLAKE_DATABASE",
        "SNOWFLAKE_SCHEMA",
        "Your container code can use environment variables in the connection code to determine which database and schema to use, as\nshown in this example:",
        "Example",
        "In Tutorial 2, you create a Snowflake job service that connects with Snowflake and executes SQL statements.\nThe following steps summarize how the tutorial code uses the environment variables:",
        "In the common setup (see the Common Setup section), you create resources, including a\ndatabase and a schema. You also set the current database and schema for the session:",
        "After you create a job service (by running EXECUTE JOB SERVICE), Snowflake starts the container and sets the following environment variables in\nthe container to the current database and schema of the session:",
        "SNOWFLAKE_DATABASE is set to \u201cTUTORIAL_DB\u201d",
        "SNOWFLAKE_SCHEMA is set to \u201cDATA_SCHEMA\u201d",
        "The job code (see main.py in Tutorial 2) reads these environment variables:",
        "The job code sets the database and schema as the context in which to execute the SQL statements (run_job() function\nin main.py):",
        "Note",
        "SNOWFLAKE_ACCOUNT, SNOWFLAKE_HOST, SNOWFLAKE_DATABASE, SNOWFLAKE_SCHEMA are environment variables that Snowflake generates for the application container, but SNOWFLAKE_WAREHOUSE is not (the Tutorial 2 application code created this variable because Snowflake does not pass a warehouse name to a container).",
        "If your service connects to Snowflake to execute a query in a Snowflake warehouse, you have the following options to specify a warehouse:",
        "Specify a warehouse in your application code. Specify a warehouse as part of the connection configuration when starting a Snowflake session to run queries in your code. For an example, see Tutorial 2.",
        "Specify a default warehouse when creating a service. Specify the optional QUERY_WAREHOUSE parameter in the CREATE SERVICE (or EXECUTE JOB SERVICE) command to provide a default\nwarehouse. If your application code does not provide a warehouse as part of connection configuration, Snowflake uses the default warehouse. Use the ALTER SERVICE command to change the default warehouse.",
        "If you specify a warehouse using both methods, the warehouse specified in the application code is used.",
        "All Snowflake-provided clients support OAuth as a way to authenticate. Service containers also use the OAuth mechanism to\nauthenticate with Snowflake. For example, when a container wants to execute SQL, the container creates a connection to Snowflake,\nsimilar to any other Snowflake client:",
        "When you create a service, Snowflake runs the containers and provides an Oauth token for containers to use at the following\nlocation within the container: /snowflake/session/token.",
        "Note the following details about this OAuth token:",
        "You should read the contents of the /snowflake/session/token file immediately before use because the content expires\nin 10 minutes, and Snowflake refreshes this file every few minutes. After a container connects to Snowflake successfully, the\nexpiration time does not apply to the connection (as with any sessions that users create directly).",
        "This OAuth token is valid only within the specific Snowflake service. You cannot copy the OAuth token and use it outside\nthe service.",
        "Using the OAuth token, the containers connect with Snowflake as the service user and use the service\u2019s owner role.",
        "Using the OAuth token to connect will create a new session. The OAuth token is not associated with any existing SQL session.",
        "Note",
        "A significant difference between executing stored procedures and executing a service is that stored procedures run in\nthe same session as the SQL that runs them. But every time a container establishes a new connection, you are creating a new\nsession.",
        "Preview Feature \u2014 Open",
        "Configuring caller\u2019s rights for your service is a preview feature.",
        "Containers execute queries by connecting to Snowflake as the service user and using the service\u2019s owner role that grants privileges to the service. In certain application scenarios, you might need to execute queries using the context of the end user rather than the service user. The caller\u2019s right feature is used in this context.",
        "For example, suppose you create a service that exposes a public endpoint to provide a web application that displays a dashboard using data stored in Snowflake. You grant other users in your Snowflake account access to the dashboard (by granting the  service role to those users). When any of these end users log in to the dashboard, you want the dashboard to display only the data the user has access to.",
        "However, because containers by default execute queries using service user and service\u2019s owner role, the dashboard shows the data the service\u2019s owner role has access to, regardless of which end user connected to the endpoint. As a result, the data in the user\u2019s dashboard is not limited to what the end user has access to, which allows the user to access data that they should not be allowed to access.",
        "To limit the dashboard to show only data accessible to the logged in user, the application containers need to execute SQL using privileges granted to the end user. You can enable this by using caller\u2019s rights in the application.",
        "Note",
        "The caller\u2019s rights feature is supported only when accessing a service using network ingress. The feature is not available when using a service function to access the service.",
        "The caller\u2019s rights feature is currently not supported in a Snowflake Native App (apps with containers).",
        "Configuring caller\u2019s rights for your application is a two-step process.",
        "Set executeAsCaller to true in the service specification as shown in the following specification fragment:",
        "This explicitly tells Snowflake that the application intends to use caller\u2019s rights and causes Snowflake to insert the Sf-Context-Current-User-Token header in every incoming request before sending the request to the application container. This user token facilitates query execution as the calling user. If not specified, executeAsCaller defaults to false.",
        "Specifying the executeAsCaller option does not affect the service\u2019s ability to execute queries as the service user and service\u2019s owner role. With executeAsCaller enabled, the service has the option to connect to Snowflake both as a calling user and as a service user.",
        "Update your application code. To establish a Snowflake connection on behalf of the calling user, update your code to create a login token that includes both the OAuth token that Snowflake provided to the service and the user token from  the Sf-Context-Current-User-Token header. The login token should follow this format: <service-oauth-token>.<Sf-Context-Current-User-Token>.",
        "This is demonstrated in the following Python code fragment:",
        "In the example above:",
        "The get_login_token function reads the file where Snowflake copied the OAuth token for the container to use.",
        "The get_connection_params function constructs a token by  concatenating of the OAuth token and the user token from the Sf-Context-Current-User-Token header. The function includes this token in a dictionary of parameters that the application uses to connect to Snowflake.",
        "For an example with step-by-step instructions, see Create a service with caller\u2019s rights enabled.",
        "Configuring caller\u2019s rights is about your service establishing a Snowflake connection on behalf of the caller. How you log in to the\nservice\u2019s ingress endpoints (programmatically or using a browser) remains the same. After login, the following apply:",
        "Accessing a public endpoint using a browser: After you log into an endpoint, the service establishes a connection to Snowflake on behalf\nof the calling user using the default role of the user. If there is no default role configured for the user, the PUBLIC role is used.",
        "Accessing a public endpoint programmatically: When logging into an endpoint programmatically using JWT token, you can optionally set the scope parameter to specify the role to activate",
        "Currently, after a service establishes a caller\u2019s right connection to Snowflake on behalf of the caller, switching roles is not supported. If your application needs to use different roles to access different objects, set up the user to have all secondary roles active by default. To do this, use the ALTER USER command to set the DEFAULT_SECONDARY_ROLES property of the user to (\u2018ALL\u2019):",
        "When a service creates a caller\u2019s rights session, the session operates as the calling user (not as the service user). When an operation is performed using this session, Snowflake applies two permissions checks:",
        "The first permissions check is as if the user created the session directly. These are the normal permission checks that Snowflake performs\nfor the user.",
        "The second permissions check verifies the service is allowed to perform the operation on behalf of a user. Snowflake verifies this by\nensuring that the service owner role has been granted the necessary caller grants.",
        "In a caller\u2019s rights session, both the normal permission check and the service owner role\u2019s caller grants check must allow the\noperation; this is referred to as restricted caller\u2019s rights. By default the service has no permission to do anything on behalf of a user. You must explicitly grant caller grants to\nthe service so it can run with the caller\u2019s privileges.",
        "For example, suppose a user U1 uses a role R1, that has the SELECT privilege on the table T1. When U1 logs into the public endpoint of your\nservice (example_service), which is configured to use the caller\u2019s rights, the service then establishes a connection with Snowflake on\nbehalf of U1.",
        "To allow the service to query table T1 on behalf of U1, you need to grant the service\u2019s owner role the following privileges:",
        "Privileges to resolve the table\u2019s name, by granting a caller grant that allows the service to run with the USAGE privilege on the database and schema for that table.",
        "Privileges to use a warehouse to execute queries by granting a caller grant that allows the service to run with the USAGE privilege on a warehouse.",
        "Privileges to query the table by granting a caller grant that allows the service to run with the SELECT privilege on table T1.",
        "Any role in your account that has the global MANAGE CALLER GRANT privilege can grant caller grants. For more information about caller grants, see GRANT CALLER and Restricted caller\u2019s rights.",
        "An example of a service that uses the caller\u2019s rights feature when executing SQL queries on behalf of the users is provided. For more information, see Create a service with caller\u2019s rights enabled.",
        "To allow anything to interact with your service from the internet, you declare the network ports on which your service is\nlistening as endpoints in the service specification file. These endpoints control ingress.",
        "By default, service endpoints are private. Only\nservice functions and\nservice-to-service communications\ncan make requests to the private endpoints. You can declare an endpoint as public to allow   requests to an endpoint from the\ninternet. The service\u2019s owner role must have the BIND SERVICE ENDPOINT privilege on the\naccount.",
        "For an example, see Tutorial 1.",
        "Note",
        "Currently only services, not job services, support network ingress.",
        "You can create a Snowpark Container Services service for web hosting using the public endpoint support (network ingress). For added\nsecurity, Snowflake employs a proxy service to monitor incoming requests from clients to your service and outgoing responses from your\nservice to the clients. This section explains what the proxy does and how it impacts a service deployed to Snowpark Container Services.",
        "Note",
        "When you test a service locally, you are not using the Snowflake proxy and therefore there will be  differences between your experience running\na service locally as opposed to when deployed in Snowpark Container Services. Review this section and update your local setup for better\ntesting.",
        "For example:",
        "The proxy does not forward an incoming HTTP request if the request uses a banned HTTP method.",
        "The proxy sends a 403 response to the client if the Content-Type header in the response indicates that the response contains an executable.",
        "Additionally, the proxy can also inject new headers and alter existing headers in the request and the response, with your container and data security in\nmind.",
        "For example, upon receiving a request, your service might send HTML, JavaScript, CSS, and other content for a web page to the client browser\nin the response. The web page in the browser is part of your service, acting as the user interface. For security reasons, if your service has restrictions (such as a restriction on making network connections to other sites), you might also want the web page for your service to have the same restrictions.",
        "By default, services have limited permissions to access the internet. The browser should also restrict the client app from accessing the internet and potentially sharing data in most cases. If you set up an External Access Integration (EAI) to allow your service to access example.com (see Configuring network egress), the web page for your service should also be able to access example.com through your browser.",
        "The Snowflake proxy applies the same network restrictions on the service and the web page by adding a Content-Security-Policy (CSP) header in the response. By default, the proxy adds a baseline CSP in the\nresponse to protect against common security threats. Browser security is a best effort to balance functionality with security, it is a shared responsibility to ensure this baseline is appropriate for your use case. In addition, if your service is configured to use an EAI, the proxy\napplies the same network rules from the EAI to the CSP for the web page. This CSP enables the web page in the browser to access the same sites that the service can access.",
        "The following sections explain how the Snowflake proxy handles incoming requests for your service and modifies the outgoing responses from your service to the clients.",
        "When a request arrives, the proxy does the following before forwarding the request to the service:",
        "Incoming requests with banned HTTP methods: If an incoming HTTP request uses any of the following banned HTTP methods, the proxy does not forward the request to your service:",
        "TRACE",
        "OPTIONS",
        "CONNECT",
        "The Snowflake proxy applies these modifications to the response sent by your service before forwarding the response to the client.",
        "Header Scrubbing: Snowflake proxy removes these response headers, if present:",
        "X-XSS-Protection",
        "Server",
        "X-Powered-By",
        "Public-Key-Pins",
        "Content-Type response header: If your service response includes the Content-Type header with any of the following MIME type values\n(that indicate an executable), Snowflake proxy does not forward that response to the client. Instead, the proxy  sends a 403 Forbidden\nresponse.",
        "application/x-msdownload: Microsoft executable.",
        "application/exe: Generic executable.",
        "application/x-exe: Another generic executable.",
        "application/dos-exe: DOS executable.",
        "application/x-winexe: Windows executable.",
        "application/msdos-windows: MS-DOS Windows executable.",
        "application/x-msdos-program: MS-DOS executable.",
        "application/x-sh: Unix shell script.",
        "application/x-bsh: Bourne shell script.",
        "application/x-csh: C shell script.",
        "application/x-tcsh: Tcsh shell script.",
        "application/batch: Windows batch file.",
        "X-Frame-Options response header: To prevent clickjacking attacks, the Snowflake proxy sets this response header to DENY,  preventing other web pages from using an iframe to the web page for your service.",
        "Cross-Origin-Opener-Policy (COOP) response header: Snowflake sets the COOP response header  to same-origin to prevent referring cross-origin windows from accessing your service tab.",
        "Cross-Origin-Resource-Policy (CORP) response header: Snowflake sets the CORP header to same-origin to prevent external sites from loading resources exposed by the ingress endpoint (for example, in an iframe).",
        "X-Content-Type-Options response header: Snowflake proxy sets this header to nosniff to ensure the clients do not change the MIME\ntype stated in the response by your service.",
        "Cross-Origin-Embedder-Policy (COEP) response header: Snowflake proxy sets the COEP response header to credentialless, which means\nwhen loading a cross-origin object such as an image or a script, if the remote object does not support Cross-Origin Resource Sharing (CORS) protocol, Snowflake does not send the credentials when loading it.",
        "Content-Security-Policy-Report-Only response header: Snowflake proxy replaces this response header with a new value directing\nthe client to send the CSP reports to Snowflake.",
        "Content-Security-Policy (CSP) response header: By default the Snowflake proxy adds the following baseline CSP to protect against common\nweb attacks.",
        "There are two content security policy considerations:",
        "In addition to the baseline content security policy that proxy adds, the service itself can explicitly add a CSP in the response. A\nservice might choose to enhance security by adding a stricter CSP. For example, a service might add the following CSP to allow scripts only from self.",
        "In the resulting response sent to the client, there will be two CSP headers. Upon receiving the response, the client browsers then apply\nthe strictest content security policy that includes the additional restrictions specified by each policy.",
        "If you configure an External Access Integration (EAI) to allow your service to access an external site\n(Configuring network egress), the Snowflake proxy creates a CSP that allows your web page to access that site. For example, suppose a\nnetwork rule associated with an EAI allows your service egress access to example.com. Then, Snowflake proxy adds this CSP response header:",
        "Browsers honor the content access policy received in the response. In this example, browsers allow the app access to example.com but not other sites.",
        "When accessing the public endpoint from the internet, you might find that username/password authentication works, but SSO results in a blank page or the error: \u201cOAuth client integration with the given client ID is not found.\u201d",
        "This happens when you\u2019re using the old style of federated authentication (SSO) with Snowflake instead of the newer security integration version as explained in Configuring Snowflake to use federated authentication. Do the following to verify:",
        "Run the following query:",
        "If you have this parameter set, then at some point you were using the old-style federated authentication.",
        "If the preceding parameter was set, run the following queries\nto see if you have a SAML security integration:",
        "If you don\u2019t have any integrations of the SAML2 type, then you\u2019re using the old style federated authentication.",
        "In this case, the solution is to migrate from the old-style federated authentication to the new integration-style federated authentication. For more information, see Migrating to a SAML2 security integration.",
        "Your application code might require access to the internet. By default, application containers don\u2019t have\npermission to access the internet. You need to enable internet access using\nExternal Access Integrations (EAIs).",
        "Typically, you want an account administrator to create EAIs to manage external access allowed from services (including job services). Account\nadministrators can then grant EAI usage to specific roles that developers use to run services.",
        "The following example outlines the steps in creating an EAI that allows egress traffic to specific destinations specified using\nnetwork rules. You then refer to the EAI when creating a service to allow requests to specific internet destinations.",
        "Example",
        "Suppose you want your application code to send requests to the following destinations:",
        "HTTPS requests to translation.googleapis.com",
        "HTTP and HTTPS requests to google.com",
        "Follow these steps to enable your service to access these domains on the internet:",
        "Create an External Access Integration (EAI). This requires appropriate permissions. For example, you can use ACCOUNTADMIN role\nto create an EAI. This is a two-step process:",
        "Use the CREATE NETWORK RULE command to create one or more egress network rules listing external\ndestinations you want to allow access to. You can accomplish this example with one network rule, but for illustration, we\ncreate two network rules:",
        "Create a network rule named translate_network_rule:",
        "This rule allows TCP connections to the translation.googleapis.com destination. The domain in the VALUE_LIST\nproperty does not specify the optional port number, so the default port 443 (HTTPS) is assumed. This allows your\napplication to connect to any URL that starts with https://translation.googleapis.com/.",
        "Create a network rule named google_network_rule:",
        "This allows your application to connect to any URL that starts with  http://google.com/ or\nhttps://google.com/.",
        "Note",
        "For the VALUE_LIST parameter, you must provide a full host name. Wildcards (for example, *.googleapis.com) are not supported.",
        "Snowpark Container Services supports only the network rules that allow ports 22, 80, 443, and 1024+. If a network rule\nreferenced allows access to other ports, creation of the service will fail. Contact your account representative if you\nrequire use of additional ports.",
        "Note",
        "To allow your service to send HTTP or HTTPS requests to any destination on the internet, you specify \u201c0.0.0.0\u201d\nas the domain in the VALUE_LIST property. The following network rule allows sending both \u201cHTTP\u201d and \u201cHTTPS\u201d requests\nanywhere on the internet. Only ports 80 or 443 are supported with \u201c0.0.0.0\u201d.",
        "Create an external access integration (EAI)\nthat specifies that the preceding two egress network rules are allowed:",
        "Now the account admin can grant usage of the integration to developers to allow them to run a service that can access\nspecific destinations on the internet.",
        "Create the service by providing the EAI as shown in the following examples. The owner role that is creating the service needs the USAGE privilege on the EAI and READ privilege on the secrets referenced. Note that you cannot use the\nACCOUNTADMIN role to create a service.",
        "Create a service:",
        "This example CREATE SERVICE request uses an inline service specification and specifies the optional\nEXTERNAL_ACCESS_INTEGRATIONS property to include the EAI. The EAI specifies the network rules that allow egress traffic\nfrom the service to the specific destinations.",
        "Execute a job service:",
        "This example EXECUTE JOB SERVICE command specifies inline specification and the optional EXTERNAL_ACCESS_INTEGRATIONS property\nto include the EAI. This allows egress traffic from the job to destinations specified in the network rules the EAI allows.",
        "Instead of routing network egress via the public internet, you might opt to direct your service\u2019s egress traffic through a\nprivate connectivity endpoint.",
        "You first need to create the private connectivity endpoint in your Snowflake account. Then configure a network rule to permit outgoing\ntraffic to use private connectivity. The process for setting up an External Access\nIntegration (EAI) remains the same as described in the preceding section.",
        "Note",
        "Private communication requires that both Snowflake and the customer\u2019s cloud account use the same cloud provider and same region.",
        "For example, if you want to enable your service\u2019s outbound internet access to an Amazon S3 bucket via private connectivity, you do the\nfollowing:",
        "Enable the private link connectivity for the self-maintained endpoint service (Amazon S3). For step-by-step instructions, see\nAWS Private Link for Amazon S3.",
        "Call the SYSTEM$PROVISION_PRIVATELINK_ENDPOINT system function to provision a private connectivity\nendpoint in your Snowflake VNet. This enables Snowflake to connect to the external service (in this example, Amazon S3) using private\nconnectivity.",
        "In the cloud provider account, approve the endpoint. In this example, for Amazon AWS, see\nAccept or reject connection requests\nin the AWS documentation.  Also, to approve the endpoint in Azure, see the\nAzure documentation.",
        "Use the CREATE NETWORK RULE command to create an egress network rule specifying the external destinations\nthat you want to allow access to.",
        "The TYPE parameter value is set to PRIVATE_HOST_PORT. It indicates that the network rule allows outgoing network traffic to use\nprivate connectivity.",
        "The rest of the steps to create an EAI and use it to create a service are the same as explained in the preceding section\n(see Configuring network egress).",
        "For more information about working with private connectivity endpoints, see the following:",
        "Manage private connectivity endpoints: AWS",
        "Manage private connectivity endpoints: Azure",
        "There are two considerations:",
        "Communications between containers of a service instance: If a service instance runs multiple containers, these containers\ncan communicate with each other over localhost (there is no need to define endpoints in the service specification).",
        "Communication between containers across multiple services or multiple service instances: Containers belonging to\ndifferent services (or different instances of the same service) can communicate using endpoints defined in specification files.\nFor more information, see Service-to-service communications.",
        "There are many reasons why you might want to pass Snowflake managed credentials into your container. For example, your service might\ncommunicate with external endpoints (outside Snowflake), in which case you will need to provide credential information in your container\nfor your application code to use.",
        "To provide credentials, first store them in Snowflake secret objects. Then, in the service specification, use containers.secrets to specify which secret objects to use and where to place them inside the container. You can either pass these credentials to environment variables in the containers, or make them available in local files in the containers.",
        "Specify a Snowflake secret by name or reference (reference is applicable only in the Native Application scenario):",
        "Pass Snowflake secret by name: You can pass a secret name as the snowflakeSecret field value.",
        "Note that you can optionally specify <secret-name> directly as the snowflakeSecret value.",
        "Pass Snowflake secret by reference: When using Snowpark Container Services to create a Native App (an app with containers), the app\nproducer and consumers use different Snowflake accounts. In some contexts an installed Snowflake Native App needs to access existing\nsecret objects in the consumer account that exist outside the APPLICATION object. In this case, developers can use the \u201csecrets by\nreference\u201d specification syntax to handle credentials as shown:",
        "Note that the specification uses objectReference instead of the objectName to provide a secret reference name.",
        "You can tell Snowflake to either place the secrets in the containers as environment variables or write them into local container files.",
        "To pass Snowflake secrets to containers as environment variables, include envVarName in the containers.secrets field.",
        "The secretKeyRef value depends on the type of Snowflake secret. Possible values are the following:",
        "username or password if the Snowflake secret is of the password type.",
        "secret_string if the Snowflake secret is of the generic_string type.",
        "Note that Snowflake does not update secrets passed as environment variables after a service is created.",
        "In this example, you create the following Snowflake secret object of the password type:",
        "To provide this Snowflake secret object to the environment variables (for example, LOGIN_USER and LOGIN_PASSWORD)\nin your container, add the following containers.secrets field in the specification file:",
        "In this example, the snowflakeSecret value is a fully qualified object name because secrets can be stored in a different schema than the service that is being created.",
        "The containers.secrets field in this example is a list of two snowflakeSecret objects:",
        "The first object maps username in the Snowflake secret object to the LOGIN_USER environment variable in your\ncontainer.",
        "The second object maps the password in the Snowflake secret object to the LOGIN_PASSWORD environment variable\nin your container.",
        "In this example, you create the following Snowflake secret object of the generic_string type:",
        "To provide this Snowflake secret object to environment variables (for example, GENERIC_SECRET) in your container, you add the\nfollowing containers.secrets field in the specification file:",
        "To make Snowflake secrets available to your application container in local container files, include a containers.secrets\nfield:\nTo make Snowflake secrets available to your application container in local container files, include directoryPath in the containers.secrets:",
        "Snowflake populates necessary files for the secret in this specified directoryPath; specifying the secretKeyRef is not necessary. Depending on the secret type, Snowflake creates the following files in the container under the directory path you provided:",
        "username and password if the Snowflake secret is of the password type.",
        "secret_string if the Snowflake secret is of the generic_string type.",
        "access_token if the Snowflake secret is of the oauth2 type.",
        "Note",
        "After a service is created, if the Snowflake secret object is updated, Snowflake will update the corresponding secret\nfiles in the running containers.",
        "In this example, you create the following Snowflake secret object of the password type:",
        "To make these credentials available in local container files, add the following containers.secrets field in the\nspecification file:",
        "When you start your service, Snowflake creates two files inside the container:  /usr/local/creds/username and\n/usr/local/creds/password. Your application code can then read these files.",
        "In this example, you create the following Snowflake secret object of the generic_string type:",
        "To provide this Snowflake secret object in local container files, you add the\nfollowing containers.secrets field in the specification file:",
        "When you start your service, Snowflake creates this file inside the containers: /usr/local/creds/secret_string.",
        "In this example, you create the following Snowflake secret object of the oauth2 type:",
        "To make these credentials available in local container files, add the following containers.secrets field in the\nspecification file:",
        "Snowflake fetches the access token from the OAuth secret object and creates /usr/local/creds/access_token in the\ncontainers.",
        "When a service uses secrets of the oauth2 type, the service is expected to use that secret to access an internet\ndestination. An oauth secret must be allowed by\nExternal Access Integration (EAI);\notherwise CREATE SERVICE or EXECUTE JOB SERVICE will fail. This extra EAI requirement only applies to secrets of the oauth2 type and\nnot to other types of secrets.",
        "In summary, the typical steps in creating such a service are:",
        "Create a secret of the oauth2 type (shown earlier).",
        "Create an EAI to allow use of the secret by a service. For example:",
        "Create a service that includes a containers.secrets field in the specification. That also specifies the optional\nEXTERNAL_ACCESS_INTEGRATIONS property to include an EAI to allow use of the oauth2 secret.",
        "An example CREATE SERVICE (with inline specification) command:",
        "For more information about egress, see Configuring network egress.",
        "General limitations: If you encounter any issues with these limitations, contact your account representative.",
        "You can create up to 200 services in your Snowflake account.",
        "Each service can expose up to 100 endpoints.",
        "The following limitations apply when you enable internet access (see Configuring network egress) using external access integrations (EAIs).",
        "Each service can support up to 10 EAIs (see CREATE SERVICE and ALTER SERVICE).",
        "Each EAI can have up to 100 host names.",
        "Snowpark Container Services supports outbound private connectivity on both AWS and Azure. Inbound private connectivity is in preview for AWS. Contact your account representative if you require inbound private connectivity on Azure.",
        "When accessing the public endpoint from the internet, you might find that username/password authentication works, but SSO results in a blank page or the error: \u201cOAuth client integration with the given client ID is not found.\u201d. For information about addressing this issue, see Ingress and SSO considerations.",
        "Image plaform requirements: Currently, Snowpark Container Services requires linux/amd64 platform images.",
        "Service containers are not privileged: Service containers do not run as privileged, and therefore cannot change\nthe configuration of the hardware on the host and can change only limited OS configurations. Service containers can only\nperform operating system configurations that a normal user (that is, a user who doesn\u2019t require root) can do.",
        "Renaming the database and schema:",
        "Do not rename databases and schemas where you already created a service. Renaming is effectively moving a service to another\ndatabase and schema, which is not supported. For example:",
        "The service DNS name will continue to reflect the old database and schema name.",
        "Database and schema information that Snowflake provided to the running service containers will continue to refer to the\nold names.",
        "New logs that services ingest in the event table will continue to refer to the old database and schema names.",
        "The service function will continue to reference the service in the old database and schema, and when you invoke the service\nfunction, it will fail.",
        "A service specification can reference objects such as Snowflake stages and image repositories. If you rename database or\nschema names where these objects reside, you need to manually update the database and schema names of the referenced objects\nin the service specification.",
        "Dropping and un-dropping a database and schema:",
        "When you drop the parent database or schema, services are deleted asynchronously. This means that a service might continue\nto run for some time before internal processes remove it.",
        "If you attempt to un-drop a previously deleted database or schema, there is no guarantee that services will be restored.",
        "Ownership transfer: Ownership transfer for services (including job services) is not supported.",
        "Replication: When dealing with replication in Snowflake, note the following:",
        "Snowpark Container Services objects, such as services, compute pools, and repositories, cannot be replicated.",
        "If you create a repository within a database, the entire database cannot be replicated. In cases where the database contains\nother resources, such as services or compute pools, the database replication process will succeed, but these\nindividual objects within the database will not be replicated.",
        "Job services timeout: Snowpark Container Services job services runs synchronously. If a statement  times out, the job service is canceled. The\ndefault statement timeout is two days. Customers can change the timeout by setting the parameter STATEMENT_TIMEOUT_IN_SECONDS\nusing ALTER SESSION.",
        "Set it before running the EXECUTE JOB SERVICE command.",
        "Was this page helpful?",
        "On this page",
        "Related content"
    ]
}