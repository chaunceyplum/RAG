{
    "url": "https://docs.snowflake.com/en/sql-reference/sql/create-external-volume",
    "title": "CREATE EXTERNAL VOLUME | Snowflake Documentation",
    "paragraphs": [
        "Creates a new external volume for Apache Iceberg\u2122 tables\nin the account or replaces an existing external volume.",
        "ALTER EXTERNAL VOLUME , DROP EXTERNAL VOLUME , SHOW EXTERNAL VOLUMES, DESCRIBE EXTERNAL VOLUME",
        "Where:",
        "String that specifies the identifier (the name) for the external volume; must be unique in your account.",
        "The identifier must start with an alphabetic character and cannot contain spaces or special characters unless the entire\nidentifier string is enclosed in double quotes (for example, \"My object\"). Identifiers enclosed in double quotes are also\ncase-sensitive.",
        "For more details, see Identifier requirements.",
        "Set of named cloud storage locations in different regions and, optionally, cloud platforms.",
        "Note",
        "Each external volume that you create supports a single\nactive storage location.",
        "Cross-cloud and cross-region tables are not currently supported when you use Snowflake as the Iceberg catalog.",
        "Specifies whether write operations are allowed for the external volume; must be set to TRUE for\nIceberg tables that use Snowflake as the catalog.",
        "The value of this parameter must also match the permissions that you\nset on the cloud storage account for each specified storage location.",
        "Note",
        "If you plan to use the external volume for externally managed Iceberg tables, you can set this parameter to FALSE.\nSnowflake doesn\u2019t write data or Iceberg metadata files to your cloud storage when you use an external Iceberg catalog.",
        "Default: TRUE",
        "String (literal) that specifies a comment for the external volume.",
        "Default: No value",
        "Note",
        "The KMS keys are managed by the storage owner in Amazon S3 or Google Cloud Storage instances. The service principals (IAM role and\nGCS service account) must be granted privileges to use KMS keys.\nFor more information, see Encrypting table files.",
        "Amazon S3",
        "Specifies the cloud storage provider that stores your data files.",
        "'S3': S3 storage in public AWS regions outside of China.",
        "'S3GOV': S3 storage in AWS government regions.",
        "Specifies the case-sensitive Amazon Resource Name (ARN) of the AWS identity and access management (IAM) role that grants privileges on the S3 bucket\ncontaining your data files. For more information, see Configure an external volume for Amazon S3.",
        "Specifies the base URL for your cloud storage location, where:",
        "protocol is one of the following:",
        "s3 refers to S3 storage in public AWS regions outside of China.",
        "s3gov refers to S3 storage in government regions.",
        "bucket is the name of an S3 bucket that stores your data files.",
        "path is an optional path that can be used to provide granular control over objects in the bucket.",
        "Important",
        "To create an Iceberg table that uses an external catalog, your Parquet data files\nand Iceberg metadata files must be within the STORAGE_BASE_URL location.",
        "Optionally specifies an external ID that Snowflake uses to establish a trust relationship with AWS.\nYou must specify the same external ID in the trust policy of the IAM role\nthat you configured for this external volume. For more information,\nsee\nHow to use an external ID when granting access to your AWS resources to a third party.",
        "If you don\u2019t specify a value for this parameter, Snowflake automatically generates an external ID when you create the external volume.",
        "Specifies the properties needed to encrypt data on the external volume.",
        "Specifies the encryption type used. Possible values are:",
        "'AWS_SSE_S3' : Server-side encryption using S3-managed encryption keys. For more information, see Using server-side encryption with Amazon S3-managed encryption keys (SSE-S3).",
        "'AWS_SSE_KMS' : Server-side encryption using keys stored in KMS. For more information, see Using server-side encryption with AWS Key Management Service (SSE-KMS).",
        "'NONE': No encryption.",
        "Optionally specifies the ID for the AWS KMS-managed key used to encrypt files written to the bucket. If no value is provided, your default KMS key is used to encrypt files for writing data.",
        "Note that this value is ignored when reading data.",
        "Google Cloud Storage",
        "Specifies the cloud storage provider that stores your data files.",
        "Specifies the base URL for your cloud storage location, where:",
        "bucket is the name of a Cloud Storage bucket that stores your data files.",
        "path is an optional path that can be used to provide granular control over objects in the bucket.",
        "Important",
        "To create an Iceberg table that uses an external catalog, your Parquet data files\nand Iceberg metadata files must be within the STORAGE_BASE_URL location.",
        "Specifies the properties needed to encrypt data on the external volume.",
        "Specifies the encryption type used. Possible values are:",
        "'GCS_SSE_KMS': Server-side encryption using keys stored in KMS. For more information, see customer-managed encryption keys.",
        "'NONE': No encryption.",
        "Specifies the ID for the Cloud KMS-managed key used to encrypt files written to the bucket.",
        "Note that this value is ignored when reading data. The read operation should succeed if the service account has sufficient\npermissions to the data and any specified KMS keys.",
        "Microsoft Azure",
        "Specifies the cloud storage provider that stores your data files.",
        "Specifies the ID for your Office 365 tenant that the storage location belongs to. An external volume can\nauthenticate to only one tenant, so the storage location must refer to a storage account\nthat belongs to this tenant.",
        "To find your tenant ID, log into the Azure portal and select Azure Active Directory \u00bb Properties. The tenant ID is\ndisplayed in the Tenant ID field.",
        "Specifies the base URL for your cloud storage location (case-sensitive).",
        "For Azure Blob Storage, specify azure://account.blob.core.windows.net/container[/path/], where:",
        "account is the name of your Azure account; for example, myaccount.",
        "container is the name of an Azure container that stores your data files.",
        "path is an optional path that can be used to provide granular control over logical directories in the container.",
        "For Fabric OneLake, specify azure://[region-]onelake.dfs | blob.fabric.microsoft.com/workspace/lakehouse/Files/path/, where:",
        "region optionally specifies the endpoint region; for example, westus. If specified, this must be the same region used\nby your Microsoft Fabric capacity, and the same region in which your Snowflake account is hosted.",
        "dfs | blob specifies the endpoint type.",
        "workspace is either your Fabric workspace ID or workspace name; for example, cfafbeb1-8037-4d0c-896e-a46fb27ff227 or my_workspace.\nYou must use the same type of identifier (ID or name) for both your workspace and Lakehouse.",
        "lakehouse is either your Lakehouse ID or Lakehouse name. You must use the same type of identifier (ID or name)\nfor both your workspace and Lakehouse; for example, 5b218778-e7a5-4d73-8187-f10824047715 or my_lakehouse.Lakehouse.",
        "path is a path to your storage location in the specified Lakehouse and Workspace.",
        "Preview Feature \u2014 Open",
        "Available to all accounts.",
        "Note",
        "Use the azure:// prefix and not https://.",
        "Important",
        "To create an Iceberg table that uses an external catalog, your Parquet data files\nand Iceberg metadata files must be within the STORAGE_BASE_URL location.",
        "Specifies whether to use outbound private connectivity. For information about using this parameter, see\nPrivate connectivity to external volumes for Microsoft Azure.",
        "Specifies S3-compatible storage as your storage provider.",
        "Specifies the URL for the external location used to store data files (an existing bucket accessed using an S3-compatible API endpoint), where:",
        "bucket is the name of the bucket.",
        "path is an optional case-sensitive path (or prefix in S3 terminology) for files in the cloud storage location\n(files with names that begin with a common string).",
        "Specifies the security credentials for connecting to and accessing your S3-compatible storage location.",
        "Specifies a fully qualified domain that points to your S3-compatible API endpoint.",
        "Note",
        "The storage endpoint should not include a bucket name; for example, specify mystorage.com instead of my_bucket.mystorage.com.",
        "A role used to execute this SQL command must have the following\nprivileges at a minimum:",
        "Privilege",
        "Object",
        "Notes",
        "CREATE EXTERNAL VOLUME",
        "Account",
        "Only the ACCOUNTADMIN role has this privilege by default. The privilege can be granted to additional roles as needed.",
        "For instructions on creating a custom role with a specified set of privileges, see Creating custom roles.",
        "For general information about roles and privilege grants for performing SQL actions on\nsecurable objects, see Overview of Access Control.",
        "Important",
        "External volumes in Amazon S3 storage only: If you recreate an external volume (using the CREATE OR REPLACE EXTERNAL VOLUME syntax)\nwithout specifying an external ID, you must repeat the steps to grant the AWS identity and access management (IAM) user\nfor your Snowflake account the access permissions required on the S3 storage location.\nFor more information, see the instructions for retrieving the AWS IAM user for your Snowflake\naccount in Configure an external volume for Amazon S3.",
        "You can\u2019t drop or replace an external volume if one or more Iceberg tables\nare associated with the external volume.",
        "To view the tables that depend on an external volume,\nyou can use the SHOW ICEBERG TABLES command and\na query using RESULT_SCAN that filters on the external_volume_name column.",
        "Note",
        "The column identifier (external_volume_name) is case-sensitive.\nSpecify the column identifier exactly as it appears in the SHOW ICEBERG TABLES output.",
        "For example:",
        "If you use a regional endpoint for a Microsoft Fabric OneLake storage location,\nuse the same region as your Microsoft Fabric capacity. This must also be the same region that hosts your Snowflake account.",
        "Regarding metadata:",
        "Attention",
        "Customers should ensure that no personal data (other than for a User object), sensitive data, export-controlled data, or other regulated data is entered as metadata when using the Snowflake service. For more information, see Metadata fields in Snowflake.",
        "CREATE OR REPLACE <object> statements are atomic. That is, when an object is replaced, the old object is deleted and the new object is created in a single transaction.",
        "The following examples create external volumes that define writable storage locations with different cloud providers:",
        "Amazon S3",
        "The following example creates an external volume that defines an Amazon S3 storage location with encryption:",
        "Google Cloud Storage",
        "The following example creates an external volume that defines a GCS storage location with encryption:",
        "Microsoft Azure",
        "The following example creates an external volume that defines an Azure storage location with encryption:",
        "S3-compatible storage",
        "Create an external volume that defines an S3-compatible storage location. For more information, see\nConfigure an external volume for S3-compatible storage.",
        "Was this page helpful?",
        "On this page",
        "Related content"
    ]
}