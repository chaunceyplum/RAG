{
    "url": "https://docs.snowflake.com/en/user-guide/snowflake-cortex/cortex-llm-rest-api",
    "title": "Cortex LLM REST API | Snowflake Documentation",
    "paragraphs": [
        "Supported regions",
        "Available to all accounts in select regions.",
        "Snowflake Cortex LLM Functions provide natural language processing features powered by a variety of large language\nmodels (LLMs) using SQL or Python. For more information, see Large Language Model (LLM) Functions (Snowflake Cortex).",
        "The Snowflake Cortex LLM REST API gives you access to the\nCOMPLETE function from any programming language that can\nmake HTTP POST requests, allowing you to bring state-of-the-art AI functionality to your applications.\nUsing this API does not require a warehouse.",
        "The Cortex LLM REST API streams generated tokens back to the user as\nserver-sent events.",
        "Snowflake Cortex LLM REST API requests incur compute costs based on the number of tokens processed. Refer to the\nSnowflake Service Consumption Table for each function\u2019s cost\nin credits per million tokens. A token is the smallest unit of text processed by Snowflake Cortex LLM functions,\napproximately equal to four characters of text. The equivalence of raw input or output text to tokens can vary by model.",
        "The COMPLETE function generates new text given an input prompt. Both input and output tokens incur compute cost.  If\nyou use COMPLETE to provide a conversational or chat user experience, all previous prompts and responses are processed\nto generate each new response, with corresponding costs.",
        "The following table contains the models that are available in the Cortex LLM REST API.",
        "\u2714",
        "\u2714",
        "\u2714",
        "\u2714",
        "\u2714",
        "\u2714",
        "\u2714",
        "\u2714",
        "\u2714",
        "\u2714",
        "\u2714",
        "\u2714",
        "\u2714",
        "\u2714",
        "\u2714",
        "\u2714",
        "\u2714",
        "\u2714",
        "\u2714",
        "\u2714",
        "\u2714",
        "\u2714",
        "\u2714",
        "\u2714",
        "\u2714",
        "\u2714",
        "\u2714",
        "\u2714",
        "\u2714",
        "\u2714",
        "\u2714",
        "\u2714",
        "\u2714",
        "\u2714",
        "\u2714",
        "\u2714",
        "\u2714",
        "\u2714",
        "\u2714",
        "You can also use any fine-tuned model in any supported region.",
        "To ensure a high standard of performance for all Snowflake customers, Snowflake Cortex LLM REST API requests are subject\nto usage quotas beyond which requests may be throttled. Snowflake may adjust these quotas from time to time. The quotas\nin the table below are applied per account and are independently applied for each model.",
        "400,000",
        "200",
        "200,000",
        "100",
        "100,000",
        "50",
        "400,000",
        "200",
        "200,000",
        "100",
        "The /api/v2/cortex/inference:complete endpoint executes the SQL COMPLETE function. It takes the form:",
        "where account_identifier is the account identifier you use to access Snowsight.",
        "Note",
        "Currently, only the COMPLETE function is supported. Additional functions may be supported in a future version of the Cortex LLM REST API.",
        "Authenticating to the Cortex LLM REST API uses key-pair authentication. This\nrequires creating an RSA key pair and assigning its public key to a user, which must be done using the SECURITYADMIN\nrole (or another role that has had SECURITYADMIN granted, such as ACCOUNTADMIN). For step-by-step instructions, see\nConfiguring key-pair authentication.",
        "Tip",
        "Consider creating a dedicated user for Cortex LLM REST API requests.",
        "To make API requests, use the public key to create a JSON Web token (JWT) and pass\nit in the headers of the request.",
        "Once you have created a key pair and assigned its public key to a user, that user\u2019s default role needs to have the\nsnowflake.cortex_user database role, which contains the privileges to use the LLM functions. In most cases, users\nalready have this privilege, because it is granted to the PUBLIC role automatically, and all roles inherit PUBLIC.",
        "If your Snowflake administrator prefers to opt in individual users, he or she might have revoked snowflake.cortex_user from\nPUBLIC, and must grant this role to the users who should be able to use the Cortex LLM REST API as follows.",
        "Important",
        "REST API requests use the user\u2019s default role, so that role must have the necessary privileges.  You can change\na user\u2019s default role with ALTER USER \u2026 SET DEFAULT ROLE.",
        "You make a request to the Cortex LLM REST API by POSTing to the API\u2019s REST endpoint.  The Authorization header must contain a\nJSON Web token generated from your public key, which you can do using snowsql via the following command. The\ngenerated JWT expires after one hour.",
        "The body of the request is a JSON object that specifies the model, the prompt or conversation history, and options. See\nthe following API Reference for details.",
        "Completes a prompt or conversation using the specified large language model. The body of the request is a JSON object\ncontaining the arguments.",
        "This endpoint corresponds to the COMPLETE SQL function.",
        "Defines the type of authorization token.",
        "Authorization for the request. jwt is a valid JSON Web token.",
        "Specifies that the body of the request is in JSON format.",
        "Specifies that the response will either contain JSON (error case) or server-sent events.",
        "Argument",
        "Type",
        "Description",
        "model",
        "string",
        "The identifier of the model to use (see Choosing a model). For possible values, see Model availability.",
        "Alternatively, you may use the fully-qualified name of any fine-tuned\nmodel in the format database.schema.model.",
        "messages",
        "array",
        "The prompt or conversation history to be used to generate a completion. An array of objects representing\na conversation in chronological order. Each object must contain a content key and may also contain a\nrole key.",
        "content: A string containing a system message, a prompt from the user, or a previous response from the model.",
        "role: A string indicating the role of the message, one of 'system', 'user', or 'assistant'.",
        "See the COMPLETE roles table for a more detailed\ndescription of these roles.",
        "For prompts consisting of a single user message, role may be omitted; it is then assumed to be user.",
        "Argument",
        "Type",
        "Default",
        "Description",
        "top_p",
        "number",
        "1.0",
        "A value from 0 to 1 (inclusive) that controls the diversity of the language model by restricting the set of possible\ntokens that the model outputs.",
        "temperature",
        "number",
        "0.0",
        "A value from 0 to 1 (inclusive) that controls the randomness of the output of the language model by influencing which\npossible token is chosen at each step.",
        "max_tokens",
        "integer",
        "4096",
        "The maximum number of tokens to output. Output is truncated after this number of tokens.",
        "Note",
        "You can set max_tokens to a number greater than 4,096, but not greater than the model limit.\nSee Model restrictions for each model\u2019s token limit.",
        "Tokens are sent as they are generated using server-sent events (SSEs). Each SSE event uses the message type\nand contains a JSON object with the following structure.",
        "Key",
        "Value type",
        "Description",
        "'id'",
        "string",
        "Unique ID of the request, the same value for all events sent in response to the request.",
        "'created'",
        "number",
        "UNIX timestamp (seconds since midnight, January 1, 1970) when the response was generated.",
        "'model'",
        "string",
        "Identifier of the model.",
        "'choices'",
        "array",
        "The model\u2019s responses. Each response is an object containing a 'delta' key whose value is an object, whose\n'content' key contains the new tokens generated by the model. Currently, only one response is provided.",
        "The Snowflake Cortex LLM REST API uses the following HTTP status codes to indicate successful completion or various error\nconditions.",
        "Request completed successfully. The body of the response contains the output of the model.",
        "The optional arguments have invalid values.",
        "The specified model does not exist.",
        "The request exceeded the maximum number of tokens supported by the model (see Model restrictions).",
        "The request has been throttled due to a high level of usage. Try again later.",
        "The model consumption budget was exceeded.",
        "Account not enabled for REST API, or the default role for the calling user does not have the snowflake.cortex_user database role.",
        "The request was rejected because the usage quota has been exceeded. Please try your request later.",
        "The request took too long.",
        "The following example uses curl to make a COMPLETE request.  Replace jwt, prompt, and\naccount_identifier with the appropriate values in this command.",
        "To install the Python API, use:",
        "The Python API is included in the snowflake-ml-python package starting with version 1.6.1.",
        "To use the Python API, first create a Snowflake session (see Creating a Session for Snowpark Python). Then call the\nComplete API. The REST back end is used only when stream=True is specified.",
        "Note",
        "The streaming mode of the Python API currently doesn\u2019t work in stored procedures and in Snowsight.",
        "Was this page helpful?",
        "On this page"
    ]
}